{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - NBA Playoffs\n",
    "Kirstin Pruitt, Mahsa Sheikhihafshejani, Larry Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (4 points total)\n",
    "+  [**1 points**] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). \n",
    "+  [**1 points**] Identify groups of features in your data that should be combined into cross-product features. Provide justification for why these features should be crossed (or why some features should not be crossed). \n",
    "+  [**1 points**] Choose and explain what metric(s) you will use to evaluate your algorithm’s performance. You should give a **detailed argument for why this (these) metric(s) are appropriate** on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "+  [**1 points**] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). **Explain why your chosen method is appropriate or use more than one method as appropriate.** Argue why your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "\n",
    "This data was scraped from [basketball-reference.com](https://www.basketball-reference.com/). It includes basic and advanced level game statistics for all teams competing in the 2011 - 2022 NBA seasons (28,396 games total). Most of the feature engineering was done in R (and will be attached as a secondary html for reference). The `rest_days` variable was included as the date of the present game minus the previous game. If the observation is a team's first game of the season, the number of rest days was assigned as 120, since that is the approximate break between seasons. The `points_diff` variable was created to gauge how much a team tends to win or lose by, but is only important for creating the `points_diff_5` and then it is dropped (since it is a linear combination of `team_score` - `opp_score`). The `ppg_5` and `points_diff_5` variables were created as moving averages across the last 5 games for the purpose of prospective modeling. Furthermore, a binary classifier, `avg_comp`, was created to indicate whether a team's average points scored in the last 5 games (`ppg_5`) is above or below the league average at the respective time. Another categorical variable was created based on the value of momentum (`rho_sign`) to indicate whether a teams momentum at a given point is negative, zero, or positive. These variables were created to serve as the wide portion of the network. Lastly, the variables indicating shots made by either team in a game were dropped since the volume of shots taken is captured by the variables whose names end in `a` (for attempted) and the scoring efficiency of respective shots is captured by the variables whose names end in `percent`. \n",
    "\n",
    "There are not very many categorical features in this dataset, but one set that we will combine into a cross-product feature will indicate whether a game was home or away and won or lost. This will result in 4 possible combinations that are meaningful in the context of an NBA game. It is often thought that the Home Team has an advantage in sports, so a home-win could be more likely than an away-win, and vice versa with patterns of losing. Crossing these features will allow our model to account for these circumstances and determine whether they are important for determining whether a team will make the playoffs. Other crossings are broken down in more detail where they occur in the notebook. We ultimately expect to have 59 features being utilized in the network. \n",
    "\n",
    "The prediction task at hand is to accurately determine whether a team will make playoffs at any given point in the season. While we acknowledge that accuracy is typically not the most appropriate metric for evaluating model performance, we believe it will be the most telling in this circumstance. Since we care equally about whether a team makes the playoffs or not, we want our model to correctly predict teams who *do* and *do not* make the playoffs, and we do not value one class's prediction over another. We will also evaluate ROC-AUC in hopes that our model will maximize the area under the curve in the binary playoff prediction task. \n",
    "\n",
    "Given the nature of the propspective modeling, we decided to do a temporal train/test split. The training data consists of all games in the 2011 - 2019 seasons (21,658 total), while the testing data consists of all games from the 2020 - 2022 seasons (6,738 total) which is close to a 76:24 split. We will use 10-fold cross-validation (with no repeats) to train the model since the training set is of moderate size, but 10-fold cross validation ensures we are getting and utilizing adequate information from the training set. We do not need to account for any notable imbalance since 16/30 NBA teams make the playoffs per season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g</th>\n",
       "      <th>date</th>\n",
       "      <th>opp</th>\n",
       "      <th>team_score</th>\n",
       "      <th>opp_score</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg_percent</th>\n",
       "      <th>x3p</th>\n",
       "      <th>x3pa</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>momentum</th>\n",
       "      <th>playoffs</th>\n",
       "      <th>home</th>\n",
       "      <th>win</th>\n",
       "      <th>rest_days</th>\n",
       "      <th>points_diff</th>\n",
       "      <th>ppg_5</th>\n",
       "      <th>diff_pg_5</th>\n",
       "      <th>avg_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10/27/10</td>\n",
       "      <td>NOH</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>77</td>\n",
       "      <td>0.429</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>-4</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>BELOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10/29/10</td>\n",
       "      <td>MIN</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>87</td>\n",
       "      <td>0.356</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-11</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>BELOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10/30/10</td>\n",
       "      <td>CHA</td>\n",
       "      <td>98</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>0.451</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>BELOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11/2/10</td>\n",
       "      <td>POR</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>27</td>\n",
       "      <td>72</td>\n",
       "      <td>0.375</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-14</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>-4.750000</td>\n",
       "      <td>BELOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11/3/10</td>\n",
       "      <td>BOS</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>36</td>\n",
       "      <td>86</td>\n",
       "      <td>0.419</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>-4.400000</td>\n",
       "      <td>BELOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   g      date  opp  team_score  opp_score  fg  fga  fg_percent  x3p  x3pa  \\\n",
       "0  1  10/27/10  NOH          91         95  33   77       0.429    8    23   \n",
       "1  2  10/29/10  MIN          85         96  31   87       0.356    3    20   \n",
       "2  3  10/30/10  CHA          98         88  32   71       0.451   11    22   \n",
       "3  4   11/2/10  POR          76         90  27   72       0.375    3    15   \n",
       "4  5   11/3/10  BOS         102        105  36   86       0.419    5    13   \n",
       "\n",
       "   ...  season  momentum  playoffs  home  win  rest_days  points_diff  \\\n",
       "0  ...    2011        -1         0     0    0        120           -4   \n",
       "1  ...    2011        -2         0     0    0          2          -11   \n",
       "2  ...    2011        -1         0     1    1          1           10   \n",
       "3  ...    2011        -2         0     1    0          3          -14   \n",
       "4  ...    2011        -3         0     0    0          1           -3   \n",
       "\n",
       "       ppg_5  diff_pg_5  avg_comp  \n",
       "0  91.000000  -4.000000     BELOW  \n",
       "1  88.000000  -7.500000     BELOW  \n",
       "2  91.333333  -1.666667     BELOW  \n",
       "3  87.500000  -4.750000     BELOW  \n",
       "4  90.400000  -4.400000     BELOW  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games = pd.read_csv(r'/Users/kirstinpruitt/Desktop/nba_games2.csv')\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games = games.drop(['date', 'fg', 'x3p', 'ft', 'fg_opp', 'x3p_opp', 'ft_opp', 'points_diff'], axis = 1)\n",
    "# will also drop season, but need to keep it for now to do the temporal train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28396, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler # 0 mean, 1 unit SD\n",
    "\n",
    "encoders = dict() # save each encoder in dictionary\n",
    "categorical_headers = ['team','opp', 'avg_comp'] # win, home, and playoffs are already binaries\n",
    "\n",
    "# train all encoders (special case the target 'income')\n",
    "for col in categorical_headers:\n",
    "    games[col] = games[col].str.strip()\n",
    "    # integer encode strings that are features\n",
    "    encoders[col] = LabelEncoder() # save the encoder\n",
    "    games[col+'_int'] = encoders[col].fit_transform(games[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output {\n",
       "    flex-direction: row;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>team_int</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>0</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRK</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHA</td>\n",
       "      <td>3</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHI</td>\n",
       "      <td>4</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHO</td>\n",
       "      <td>5</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CLE</td>\n",
       "      <td>6</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DAL</td>\n",
       "      <td>7</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEN</td>\n",
       "      <td>8</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DET</td>\n",
       "      <td>9</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GSW</td>\n",
       "      <td>10</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOU</td>\n",
       "      <td>11</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IND</td>\n",
       "      <td>12</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LAC</td>\n",
       "      <td>13</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LAL</td>\n",
       "      <td>14</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MEM</td>\n",
       "      <td>15</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MIA</td>\n",
       "      <td>16</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MIL</td>\n",
       "      <td>17</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MIN</td>\n",
       "      <td>18</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NJN</td>\n",
       "      <td>19</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NOH</td>\n",
       "      <td>20</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NOP</td>\n",
       "      <td>21</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NYK</td>\n",
       "      <td>22</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OKC</td>\n",
       "      <td>23</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ORL</td>\n",
       "      <td>24</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PHI</td>\n",
       "      <td>25</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PHO</td>\n",
       "      <td>26</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>POR</td>\n",
       "      <td>27</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SAC</td>\n",
       "      <td>28</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SAS</td>\n",
       "      <td>29</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TOR</td>\n",
       "      <td>30</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>UTA</td>\n",
       "      <td>31</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>WAS</td>\n",
       "      <td>32</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team  team_int  count\n",
       "0   ATL         0    943\n",
       "1   BOS         1    947\n",
       "2   BRK         2    800\n",
       "3   CHA         3    312\n",
       "4   CHI         4    941\n",
       "5   CHO         5    629\n",
       "6   CLE         6    941\n",
       "7   DAL         7    951\n",
       "8   DEN         8    949\n",
       "9   DET         9    942\n",
       "10  GSW        10    941\n",
       "11  HOU        11    948\n",
       "12  IND        12    948\n",
       "13  LAC        13    948\n",
       "14  LAL        14    947\n",
       "15  MEM        15    949\n",
       "16  MIA        16    949\n",
       "17  MIL        17    949\n",
       "18  MIN        18    940\n",
       "19  NJN        19    148\n",
       "20  NOH        20    230\n",
       "21  NOP        21    718\n",
       "22  NYK        22    942\n",
       "23  OKC        23    948\n",
       "24  ORL        24    949\n",
       "25  PHI        25    949\n",
       "26  PHO        26    949\n",
       "27  POR        27    950\n",
       "28  SAC        28    948\n",
       "29  SAS        29    947\n",
       "30  TOR        30    948\n",
       "31  UTA        31    948\n",
       "32  WAS        32    948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opp</th>\n",
       "      <th>opp_int</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>0</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRK</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHA</td>\n",
       "      <td>3</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHI</td>\n",
       "      <td>4</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHO</td>\n",
       "      <td>5</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CLE</td>\n",
       "      <td>6</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DAL</td>\n",
       "      <td>7</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEN</td>\n",
       "      <td>8</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DET</td>\n",
       "      <td>9</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GSW</td>\n",
       "      <td>10</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOU</td>\n",
       "      <td>11</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IND</td>\n",
       "      <td>12</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LAC</td>\n",
       "      <td>13</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LAL</td>\n",
       "      <td>14</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MEM</td>\n",
       "      <td>15</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MIA</td>\n",
       "      <td>16</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MIL</td>\n",
       "      <td>17</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MIN</td>\n",
       "      <td>18</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NJN</td>\n",
       "      <td>19</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NOH</td>\n",
       "      <td>20</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NOP</td>\n",
       "      <td>21</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NYK</td>\n",
       "      <td>22</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OKC</td>\n",
       "      <td>23</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ORL</td>\n",
       "      <td>24</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PHI</td>\n",
       "      <td>25</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PHO</td>\n",
       "      <td>26</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>POR</td>\n",
       "      <td>27</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SAC</td>\n",
       "      <td>28</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SAS</td>\n",
       "      <td>29</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TOR</td>\n",
       "      <td>30</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>UTA</td>\n",
       "      <td>31</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>WAS</td>\n",
       "      <td>32</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    opp  opp_int  count\n",
       "0   ATL        0    943\n",
       "1   BOS        1    947\n",
       "2   BRK        2    800\n",
       "3   CHA        3    312\n",
       "4   CHI        4    941\n",
       "5   CHO        5    629\n",
       "6   CLE        6    941\n",
       "7   DAL        7    951\n",
       "8   DEN        8    949\n",
       "9   DET        9    942\n",
       "10  GSW       10    941\n",
       "11  HOU       11    948\n",
       "12  IND       12    948\n",
       "13  LAC       13    948\n",
       "14  LAL       14    947\n",
       "15  MEM       15    949\n",
       "16  MIA       16    949\n",
       "17  MIL       17    949\n",
       "18  MIN       18    940\n",
       "19  NJN       19    148\n",
       "20  NOH       20    230\n",
       "21  NOP       21    718\n",
       "22  NYK       22    942\n",
       "23  OKC       23    948\n",
       "24  ORL       24    949\n",
       "25  PHI       25    949\n",
       "26  PHO       26    949\n",
       "27  POR       27    950\n",
       "28  SAC       28    948\n",
       "29  SAS       29    947\n",
       "30  TOR       30    948\n",
       "31  UTA       31    948\n",
       "32  WAS       32    948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "team_tab = games.groupby(['team', 'team_int']).size().reset_index().rename(columns={0:'count'})\n",
    "opp_tab = games.groupby(['opp', 'opp_int']).size().reset_index().rename(columns={0:'count'})\n",
    "display(team_tab)\n",
    "display(opp_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = games.columns.tolist()\n",
    "rem_cols = {\"opp\", \"team\", \"opp_int\", \"team_int\", \"season\", \"playoffs\", \"home\", \"win\", \"avg_comp\", \"avg_comp_int\"}\n",
    "numeric_headers = [x for x in cols if x not in rem_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games.loc[(games['home'] == 1), 'LOCATION'] = \"HOME\"\n",
    "games.loc[(games['home'] == 0), 'LOCATION'] = \"AWAY\"\n",
    "games.loc[(games['win'] == 1), 'OUTCOME'] = \"WIN\"\n",
    "games.loc[(games['win'] == 0), 'OUTCOME'] = \"LOSE\"\n",
    "games.loc[(games['momentum'] > 0), 'rho_sign'] = \"POSITIVE\"\n",
    "games.loc[(games['momentum'] == 0), 'rho_sign'] = \"ZERO\"\n",
    "games.loc[(games['momentum'] < 0), 'rho_sign'] = \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "games[numeric_headers] = ss.fit_transform(games[numeric_headers].to_numpy()) # should be to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_headers = [\"opp_int\", \"team_int\", \"avg_comp_int\", \"home\", \"win\", \"season\"]\n",
    "feature_columns = categorical_headers + numeric_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: `avg_comp_int` is somewhat backwards in thought. Above the league average is 0, and below the league average is 1. Renaming it for clarification below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_headers.remove(\"season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_headers = list(map(lambda x: x.replace('avg_comp_int', 'below_avg_int'), categorical_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opp_int', 'team_int', 'below_avg_int', 'home', 'win']\n",
      "['g', 'team_score', 'opp_score', 'fga', 'fg_percent', 'x3pa', 'x3p_percent', 'fta', 'ft_percent', 'orb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'fga_opp', 'fg_percent_opp', 'x3pa_opp', 'x3p_percent_opp', 'fta_opp', 'ft_percent_opp', 'orb_opp', 'trb_opp', 'ast_opp', 'stl_opp', 'blk_opp', 'tov_opp', 'pf_opp', 'o_rtg', 'd_rtg', 'pace', 'f_tr', 'x3p_ar', 'ts_percent', 'trb_percent', 'ast_percent', 'stl_percent', 'blk_percent', 'e_fg_percent_off', 'tov_percent_off', 'orb_percent', 'ft_fga_off', 'e_fg_percent_def', 'tov_percent_def', 'drb_percent', 'ft_fga_def', 'momentum', 'rest_days', 'ppg_5', 'diff_pg_5']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_headers)\n",
    "print(numeric_headers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Crossing Option 1**: `team` and `opp`\n",
    "  +  1044 combinations \n",
    "  +  probably not a fruitful exercise, but a motivating scenario is to consider the Sacramento Kings (who haven't made the playoffs since the 2006-07 season [1], so not at all in the dataset) and the San Antonio Spurs (who almost always make the playoffs (in the training set)) \n",
    "\n",
    "* **Crossing Option 2**: `home` and `win`, we can apply this to the network to get four unique options:\n",
    "  +  home_win (1_1)\n",
    "  +  home_lose (1_0)\n",
    "  +  away_win (0_1)\n",
    "  +  away_lose (0_0)\n",
    "  \n",
    "* **Crossing Option 3**: `home` + `win` + `avg_comp`\n",
    "  +  8 combinations\n",
    "  +  motivating example: if a team that wins a lot of home and away games also averages more ppg than the league avg, it is plausible for the network to learn this as a scenario that should predict that team making playoffs\n",
    "  \n",
    "* **Crossing Option 4**: `home` + `win` + `rho_sign`\n",
    "  +  12 combinations \n",
    "  +  similar to before, but motivating example: if a team that wins a lot of home and away games also has a positive raw momentum score, it is plausible for the network to learn this as a scenario that should predict that team making playoffs. if the team has a zero momentum score, maybe the network becomes less confident in the outcome. \n",
    "  \n",
    "* **Crossing Option 5**: `avg_comp` + `rho_sign` \n",
    "  +  6 combinations\n",
    "  +  motivating example: if a team averages more ppg than the league avg and has a positive raw momentum score, it is plausible for the network to learn this as a scenario that should predict that team making playoffs. \n",
    "\n",
    "The crossed columns used for this lab were:\n",
    "  1.  Crossing Option 2 $\\times$ Crossing Option 5\n",
    "  2.  Crossing Option 1 $\\times$ Crossing Option 3\n",
    "  3.  Crossing Option 1 $\\times$ Crossing Option 4\n",
    " \n",
    "\n",
    "*Note*: If we were not concerned about prospective modeling, we could do Shuffle Splits and then memorize matchups per season, which would probably be better than just memorizing matchups as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ATL_BOS' 'ATL_BRK' 'ATL_CHA' ... 'WAS_SAS' 'WAS_TOR' 'WAS_UTA']\n",
      "0 1043\n"
     ]
    }
   ],
   "source": [
    "# a quick example of crossing some columns\n",
    "\n",
    "cols_list = ['team','opp']\n",
    "\n",
    "# 1. create crossed labels by string join operation\n",
    "X_crossed_train = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "X_crossed_test = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "# combine together for training\n",
    "all_vals = np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy()))\n",
    "print(np.unique(all_vals))\n",
    "    \n",
    "# 2. encode as integers, stacking all possibilities\n",
    "enc = LabelEncoder()\n",
    "enc.fit(all_vals)\n",
    "\n",
    "encoded_vals_train = enc.transform(X_crossed_train)\n",
    "encoded_vals_test  = enc.transform(X_crossed_test)\n",
    "\n",
    "print(np.min(encoded_vals_train), np.max(encoded_vals_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AWAY_LOSE' 'AWAY_WIN' 'HOME_LOSE' 'HOME_WIN']\n",
      "0 3\n"
     ]
    }
   ],
   "source": [
    "# a quick example of crossing some columns\n",
    "\n",
    "cols_list = ['LOCATION','OUTCOME']\n",
    "\n",
    "# 1. create crossed labels by string join operation\n",
    "X_crossed_train = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "X_crossed_test = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "# combine together for training\n",
    "all_vals = np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy()))\n",
    "print(np.unique(all_vals))\n",
    "    \n",
    "# 2. encode as integers, stacking all possibilities\n",
    "enc = LabelEncoder()\n",
    "enc.fit(all_vals)\n",
    "\n",
    "encoded_vals_train = enc.transform(X_crossed_train)\n",
    "encoded_vals_test  = enc.transform(X_crossed_test)\n",
    "\n",
    "print(np.min(encoded_vals_train), np.max(encoded_vals_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AWAY_LOSE_ABOVE' 'AWAY_LOSE_BELOW' 'AWAY_WIN_ABOVE' 'AWAY_WIN_BELOW'\n",
      " 'HOME_LOSE_ABOVE' 'HOME_LOSE_BELOW' 'HOME_WIN_ABOVE' 'HOME_WIN_BELOW']\n",
      "0 7\n"
     ]
    }
   ],
   "source": [
    "# a quick example of crossing some columns\n",
    "\n",
    "cols_list = ['LOCATION','OUTCOME', 'avg_comp']\n",
    "\n",
    "# 1. create crossed labels by string join operation\n",
    "X_crossed_train = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "X_crossed_test = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "# combine together for training\n",
    "all_vals = np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy()))\n",
    "print(np.unique(all_vals))\n",
    "    \n",
    "# 2. encode as integers, stacking all possibilities\n",
    "enc = LabelEncoder()\n",
    "enc.fit(all_vals)\n",
    "\n",
    "encoded_vals_train = enc.transform(X_crossed_train)\n",
    "encoded_vals_test  = enc.transform(X_crossed_test)\n",
    "\n",
    "print(np.min(encoded_vals_train), np.max(encoded_vals_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AWAY_LOSE_NEGATIVE' 'AWAY_LOSE_POSITIVE' 'AWAY_LOSE_ZERO'\n",
      " 'AWAY_WIN_NEGATIVE' 'AWAY_WIN_POSITIVE' 'AWAY_WIN_ZERO'\n",
      " 'HOME_LOSE_NEGATIVE' 'HOME_LOSE_POSITIVE' 'HOME_LOSE_ZERO'\n",
      " 'HOME_WIN_NEGATIVE' 'HOME_WIN_POSITIVE' 'HOME_WIN_ZERO']\n",
      "0 11\n"
     ]
    }
   ],
   "source": [
    "# a quick example of crossing some columns\n",
    "\n",
    "cols_list = ['LOCATION','OUTCOME', 'rho_sign']\n",
    "\n",
    "# 1. create crossed labels by string join operation\n",
    "X_crossed_train = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "X_crossed_test = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "# combine together for training\n",
    "all_vals = np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy()))\n",
    "print(np.unique(all_vals))\n",
    "    \n",
    "# 2. encode as integers, stacking all possibilities\n",
    "enc = LabelEncoder()\n",
    "enc.fit(all_vals)\n",
    "\n",
    "encoded_vals_train = enc.transform(X_crossed_train)\n",
    "encoded_vals_test  = enc.transform(X_crossed_test)\n",
    "\n",
    "print(np.min(encoded_vals_train), np.max(encoded_vals_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABOVE_NEGATIVE' 'ABOVE_POSITIVE' 'ABOVE_ZERO' 'BELOW_NEGATIVE'\n",
      " 'BELOW_POSITIVE' 'BELOW_ZERO']\n",
      "0 5\n"
     ]
    }
   ],
   "source": [
    "# a quick example of crossing some columns\n",
    "\n",
    "cols_list = ['avg_comp', 'rho_sign']\n",
    "\n",
    "# 1. create crossed labels by string join operation\n",
    "X_crossed_train = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "X_crossed_test = games[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "# combine together for training\n",
    "all_vals = np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy()))\n",
    "print(np.unique(all_vals))\n",
    "    \n",
    "# 2. encode as integers, stacking all possibilities\n",
    "enc = LabelEncoder()\n",
    "enc.fit(all_vals)\n",
    "\n",
    "encoded_vals_train = enc.transform(X_crossed_train)\n",
    "encoded_vals_test  = enc.transform(X_crossed_test)\n",
    "\n",
    "print(np.min(encoded_vals_train), np.max(encoded_vals_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g</th>\n",
       "      <th>opp</th>\n",
       "      <th>team_score</th>\n",
       "      <th>opp_score</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg_percent</th>\n",
       "      <th>x3pa</th>\n",
       "      <th>x3p_percent</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>rest_days</th>\n",
       "      <th>ppg_5</th>\n",
       "      <th>diff_pg_5</th>\n",
       "      <th>avg_comp</th>\n",
       "      <th>team_int</th>\n",
       "      <th>opp_int</th>\n",
       "      <th>avg_comp_int</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>rho_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.695162</td>\n",
       "      <td>NOH</td>\n",
       "      <td>-1.025281</td>\n",
       "      <td>-0.723340</td>\n",
       "      <td>-1.066814</td>\n",
       "      <td>-0.519717</td>\n",
       "      <td>-0.370562</td>\n",
       "      <td>-0.069648</td>\n",
       "      <td>0.705461</td>\n",
       "      <td>-1.515230</td>\n",
       "      <td>...</td>\n",
       "      <td>8.435188</td>\n",
       "      <td>-1.553850</td>\n",
       "      <td>-0.519635</td>\n",
       "      <td>BELOW</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>LOSE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.651851</td>\n",
       "      <td>MIN</td>\n",
       "      <td>-1.478192</td>\n",
       "      <td>-0.647855</td>\n",
       "      <td>0.244434</td>\n",
       "      <td>-1.840023</td>\n",
       "      <td>-0.705914</td>\n",
       "      <td>-2.057502</td>\n",
       "      <td>0.298447</td>\n",
       "      <td>0.347121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122318</td>\n",
       "      <td>-1.898398</td>\n",
       "      <td>-0.973373</td>\n",
       "      <td>BELOW</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>LOSE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.608540</td>\n",
       "      <td>CHA</td>\n",
       "      <td>-0.496885</td>\n",
       "      <td>-1.251736</td>\n",
       "      <td>-1.853562</td>\n",
       "      <td>-0.121817</td>\n",
       "      <td>-0.482346</td>\n",
       "      <td>1.456381</td>\n",
       "      <td>0.569789</td>\n",
       "      <td>0.848894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194839</td>\n",
       "      <td>-1.515566</td>\n",
       "      <td>-0.217143</td>\n",
       "      <td>BELOW</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>WIN</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.565229</td>\n",
       "      <td>POR</td>\n",
       "      <td>-2.157558</td>\n",
       "      <td>-1.100766</td>\n",
       "      <td>-1.722438</td>\n",
       "      <td>-1.496382</td>\n",
       "      <td>-1.264835</td>\n",
       "      <td>-1.555519</td>\n",
       "      <td>0.298447</td>\n",
       "      <td>-0.038859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049796</td>\n",
       "      <td>-1.955823</td>\n",
       "      <td>-0.616865</td>\n",
       "      <td>BELOW</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>HOME</td>\n",
       "      <td>LOSE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.521918</td>\n",
       "      <td>BOS</td>\n",
       "      <td>-0.194944</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>0.113310</td>\n",
       "      <td>-0.700581</td>\n",
       "      <td>-1.488403</td>\n",
       "      <td>0.301820</td>\n",
       "      <td>1.112474</td>\n",
       "      <td>0.405018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194839</td>\n",
       "      <td>-1.622759</td>\n",
       "      <td>-0.571491</td>\n",
       "      <td>BELOW</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AWAY</td>\n",
       "      <td>LOSE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          g  opp  team_score  opp_score       fga  fg_percent      x3pa  \\\n",
       "0 -1.695162  NOH   -1.025281  -0.723340 -1.066814   -0.519717 -0.370562   \n",
       "1 -1.651851  MIN   -1.478192  -0.647855  0.244434   -1.840023 -0.705914   \n",
       "2 -1.608540  CHA   -0.496885  -1.251736 -1.853562   -0.121817 -0.482346   \n",
       "3 -1.565229  POR   -2.157558  -1.100766 -1.722438   -1.496382 -1.264835   \n",
       "4 -1.521918  BOS   -0.194944   0.031512  0.113310   -0.700581 -1.488403   \n",
       "\n",
       "   x3p_percent       fta  ft_percent  ...  rest_days     ppg_5  diff_pg_5  \\\n",
       "0    -0.069648  0.705461   -1.515230  ...   8.435188 -1.553850  -0.519635   \n",
       "1    -2.057502  0.298447    0.347121  ...  -0.122318 -1.898398  -0.973373   \n",
       "2     1.456381  0.569789    0.848894  ...  -0.194839 -1.515566  -0.217143   \n",
       "3    -1.555519  0.298447   -0.038859  ...  -0.049796 -1.955823  -0.616865   \n",
       "4     0.301820  1.112474    0.405018  ...  -0.194839 -1.622759  -0.571491   \n",
       "\n",
       "   avg_comp  team_int  opp_int  avg_comp_int  LOCATION  OUTCOME  rho_sign  \n",
       "0     BELOW        17       20             1      AWAY     LOSE  NEGATIVE  \n",
       "1     BELOW        17       18             1      AWAY     LOSE  NEGATIVE  \n",
       "2     BELOW        17        3             1      HOME      WIN  NEGATIVE  \n",
       "3     BELOW        17       27             1      HOME     LOSE  NEGATIVE  \n",
       "4     BELOW        17        1             1      AWAY     LOSE  NEGATIVE  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = games\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={'avg_comp_int': 'below_avg_int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21658, 63) (6738, 63)\n"
     ]
    }
   ],
   "source": [
    "# temporally split the data into training and testing for predictions to be useful\n",
    "train = data[data['season'] <= 2019]\n",
    "test = data[data['season'] > 2019]\n",
    "\n",
    "X_train = train.drop('season', axis = 1)\n",
    "X_test = test.drop('season', axis = 1)\n",
    "\n",
    "#X_train = train#.to_numpy()\n",
    "#X_test = test#.to_numpy()\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indexes = []\n",
    "test_indexes = []\n",
    "\n",
    "for index, season in enumerate(games.season):\n",
    "    if season <= 2019:\n",
    "        train_indexes.append(index)\n",
    "    else:\n",
    "        test_indexes.append(index)      \n",
    "        \n",
    "y_train = games.loc[train_indexes, ['playoffs']].values.astype(np.int32)\n",
    "y_test = games.loc[test_indexes, ['playoffs']].values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (5 points total)\n",
    "+  [**2 points**] Create at least three combined wide and deep networks to classify your data using Keras. Visualize the performance of the network on the training data and validation data in the same plot versus the training iterations. Note: use the \"history\" return parameter that is part of Keras \"fit\" function to easily access this data.\n",
    "+  [**2 points**] Investigate generalization performance by altering the number of layers in the deep branch of the network. Try at least two different number of layers. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab to select the number of layers that performs superiorly. \n",
    "+ [**1 points**] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP). Alternatively, you can compare to a network without the wide branch (i.e., just the deep network). For classification tasks, compare using the receiver operating characteristic and area under the curve. For regression tasks, use Bland-Altman plots and residual variance calculations.  Use proper statistical methods to compare the performance of different models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Input, Embedding, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Crossed Categories for Wide Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOCATION_OUTCOME', 'avg_comp_rho_sign']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's create some different crossed values\n",
    "# possible crossing options:\n",
    "#   'LOCATION','OUTCOME';\n",
    "#   'team','opp';\n",
    "#   'LOCATION','OUTCOME','avg_comp'\n",
    "#   'LOCATION','OUTCOME','rho_sign'\n",
    "\n",
    "# choose these as a class, what makes sense??\n",
    "cross_columns = [['LOCATION','OUTCOME'],\n",
    "                 ['avg_comp','rho_sign'],\n",
    "                 #['LOCATION','OUTCOME','avg_comp'],\n",
    "                 #['LOCATION','OUTCOME','rho_sign']\n",
    "                ]\n",
    "\n",
    "# cross each set of columns in the list above\n",
    "cross_col_df_names1 = []\n",
    "for cols_list in cross_columns:\n",
    "    # encode as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # 1. create crossed labels by join operation\n",
    "    X_crossed_train = games[games['season'] <= 2019][cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = games[games['season'] > 2019][cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    # get a nice name for this new crossed column\n",
    "    cross_col_name = '_'.join(cols_list)\n",
    "    \n",
    "    # 2. encode as integers, stacking all possibilities\n",
    "    enc.fit(np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy())))\n",
    "    \n",
    "    # 3. Save into dataframe with new name\n",
    "    X_train[cross_col_name] = enc.transform(X_crossed_train)\n",
    "    X_test[cross_col_name] = enc.transform(X_crossed_test)\n",
    "    \n",
    "    # keep track of the new names of the crossed columns\n",
    "    cross_col_df_names1.append(cross_col_name) \n",
    "cross_col_df_names1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team_opp', 'LOCATION_OUTCOME_avg_comp']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's create some different crossed values\n",
    "# possible crossing options:\n",
    "#   'LOCATION','OUTCOME';\n",
    "#   'team','opp';\n",
    "#   'LOCATION','OUTCOME','avg_comp'\n",
    "#   'LOCATION','OUTCOME','rho_sign'\n",
    "\n",
    "# choose these as a class, what makes sense??\n",
    "cross_columns = [#['LOCATION','OUTCOME'],\n",
    "                 ['team','opp'],\n",
    "                 ['LOCATION','OUTCOME','avg_comp'],\n",
    "                 #['LOCATION','OUTCOME','rho_sign']\n",
    "                ]\n",
    "\n",
    "# cross each set of columns in the list above\n",
    "cross_col_df_names2 = []\n",
    "for cols_list in cross_columns:\n",
    "    # encode as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # 1. create crossed labels by join operation\n",
    "    X_crossed_train = games[games['season'] <= 2019][cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = games[games['season'] > 2019][cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    # get a nice name for this new crossed column\n",
    "    cross_col_name = '_'.join(cols_list)\n",
    "    \n",
    "    # 2. encode as integers, stacking all possibilities\n",
    "    enc.fit(np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy())))\n",
    "    \n",
    "    # 3. Save into dataframe with new name\n",
    "    X_train[cross_col_name] = enc.transform(X_crossed_train)\n",
    "    X_test[cross_col_name] = enc.transform(X_crossed_test)\n",
    "    \n",
    "    # keep track of the new names of the crossed columns\n",
    "    cross_col_df_names2.append(cross_col_name) \n",
    "cross_col_df_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team_opp', 'LOCATION_OUTCOME_rho_sign']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's create some different crossed values\n",
    "# possible crossing options:\n",
    "#   'LOCATION','OUTCOME';\n",
    "#   'team','opp';\n",
    "#   'LOCATION','OUTCOME','avg_comp'\n",
    "#   'LOCATION','OUTCOME','rho_sign'\n",
    "\n",
    "# choose these as a class, what makes sense??\n",
    "cross_columns = [#['LOCATION','OUTCOME'],\n",
    "                 ['team','opp'],\n",
    "                 #['LOCATION','OUTCOME','avg_comp'],\n",
    "                 ['LOCATION','OUTCOME','rho_sign']\n",
    "                ]\n",
    "\n",
    "# cross each set of columns in the list above\n",
    "cross_col_df_names3 = []\n",
    "for cols_list in cross_columns:\n",
    "    # encode as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # 1. create crossed labels by join operation\n",
    "    X_crossed_train = games[games['season'] <= 2019][cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = games[games['season'] > 2019][cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    # get a nice name for this new crossed column\n",
    "    cross_col_name = '_'.join(cols_list)\n",
    "    \n",
    "    # 2. encode as integers, stacking all possibilities\n",
    "    enc.fit(np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy())))\n",
    "    \n",
    "    # 3. Save into dataframe with new name\n",
    "    X_train[cross_col_name] = enc.transform(X_crossed_train)\n",
    "    X_test[cross_col_name] = enc.transform(X_crossed_test)\n",
    "    \n",
    "    # keep track of the new names of the crossed columns\n",
    "    cross_col_df_names3.append(cross_col_name) \n",
    "cross_col_df_names3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.2378 - accuracy: 0.6211 - auc: 0.7035\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77424, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2368 - accuracy: 0.6284 - auc: 0.7134 - val_loss: 0.2195 - val_accuracy: 0.7742 - val_auc: 0.8502\n",
      "Epoch 2/15\n",
      "562/610 [==========================>...] - ETA: 0s - loss: 0.2042 - accuracy: 0.7784 - auc: 0.8588\n",
      "Epoch 2: val_accuracy improved from 0.77424 to 0.80840, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2027 - accuracy: 0.7799 - auc: 0.8595 - val_loss: 0.1806 - val_accuracy: 0.8084 - val_auc: 0.8820\n",
      "Epoch 3/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1655 - accuracy: 0.8166 - auc: 0.8835\n",
      "Epoch 3: val_accuracy improved from 0.80840 to 0.82641, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1646 - accuracy: 0.8170 - auc: 0.8838 - val_loss: 0.1472 - val_accuracy: 0.8264 - val_auc: 0.8953\n",
      "Epoch 4/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1389 - accuracy: 0.8335 - auc: 0.8975\n",
      "Epoch 4: val_accuracy improved from 0.82641 to 0.83610, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1387 - accuracy: 0.8329 - auc: 0.8974 - val_loss: 0.1295 - val_accuracy: 0.8361 - val_auc: 0.9050\n",
      "Epoch 5/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.8414 - auc: 0.9063\n",
      "Epoch 5: val_accuracy improved from 0.83610 to 0.84118, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1259 - accuracy: 0.8413 - auc: 0.9061 - val_loss: 0.1217 - val_accuracy: 0.8412 - val_auc: 0.9107\n",
      "Epoch 6/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1199 - accuracy: 0.8438 - auc: 0.9114\n",
      "Epoch 6: val_accuracy improved from 0.84118 to 0.84211, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1199 - accuracy: 0.8438 - auc: 0.9113 - val_loss: 0.1175 - val_accuracy: 0.8421 - val_auc: 0.9146\n",
      "Epoch 7/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1174 - accuracy: 0.8439 - auc: 0.9136\n",
      "Epoch 7: val_accuracy improved from 0.84211 to 0.84395, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.8450 - auc: 0.9146 - val_loss: 0.1151 - val_accuracy: 0.8440 - val_auc: 0.9177\n",
      "Epoch 8/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1146 - accuracy: 0.8463 - auc: 0.9173\n",
      "Epoch 8: val_accuracy improved from 0.84395 to 0.84626, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.8456 - auc: 0.9171 - val_loss: 0.1140 - val_accuracy: 0.8463 - val_auc: 0.9193\n",
      "Epoch 9/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1133 - accuracy: 0.8460 - auc: 0.9195\n",
      "Epoch 9: val_accuracy improved from 0.84626 to 0.84765, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8457 - auc: 0.9189 - val_loss: 0.1127 - val_accuracy: 0.8476 - val_auc: 0.9211\n",
      "Epoch 10/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1130 - accuracy: 0.8463 - auc: 0.9203\n",
      "Epoch 10: val_accuracy improved from 0.84765 to 0.84995, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.8466 - auc: 0.9204 - val_loss: 0.1120 - val_accuracy: 0.8500 - val_auc: 0.9225\n",
      "Epoch 11/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1119 - accuracy: 0.8473 - auc: 0.9219\n",
      "Epoch 11: val_accuracy did not improve from 0.84995\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.8473 - auc: 0.9217 - val_loss: 0.1115 - val_accuracy: 0.8495 - val_auc: 0.9233\n",
      "Epoch 12/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.8474 - auc: 0.9228\n",
      "Epoch 12: val_accuracy improved from 0.84995 to 0.85042, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.8474 - auc: 0.9228 - val_loss: 0.1109 - val_accuracy: 0.8504 - val_auc: 0.9244\n",
      "Epoch 13/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1104 - accuracy: 0.8491 - auc: 0.9242\n",
      "Epoch 13: val_accuracy improved from 0.85042 to 0.85134, saving model to \\saved_models1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.8480 - auc: 0.9238 - val_loss: 0.1106 - val_accuracy: 0.8513 - val_auc: 0.9249\n",
      "Epoch 14/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1106 - accuracy: 0.8476 - auc: 0.9243\n",
      "Epoch 14: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.8481 - auc: 0.9245 - val_loss: 0.1101 - val_accuracy: 0.8509 - val_auc: 0.9257\n",
      "Epoch 15/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.8486 - auc: 0.9254\n",
      "Epoch 15: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.8488 - auc: 0.9255 - val_loss: 0.1100 - val_accuracy: 0.8500 - val_auc: 0.9262\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8513 - auc: 0.9249\n",
      "Epoch 1/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.2413 - accuracy: 0.5995 - auc: 0.6321\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69298, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2405 - accuracy: 0.6046 - auc: 0.6388 - val_loss: 0.2231 - val_accuracy: 0.6930 - val_auc: 0.7623\n",
      "Epoch 2/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2036 - accuracy: 0.7219 - auc: 0.7893\n",
      "Epoch 2: val_accuracy improved from 0.69298 to 0.75162, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2027 - accuracy: 0.7222 - auc: 0.7897 - val_loss: 0.1828 - val_accuracy: 0.7516 - val_auc: 0.8258\n",
      "Epoch 3/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.7602 - auc: 0.8385\n",
      "Epoch 3: val_accuracy improved from 0.75162 to 0.77701, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1684 - accuracy: 0.7609 - auc: 0.8393 - val_loss: 0.1555 - val_accuracy: 0.7770 - val_auc: 0.8637\n",
      "Epoch 4/15\n",
      "562/610 [==========================>...] - ETA: 0s - loss: 0.1488 - accuracy: 0.7848 - auc: 0.8696\n",
      "Epoch 4: val_accuracy improved from 0.77701 to 0.80379, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1479 - accuracy: 0.7867 - auc: 0.8707 - val_loss: 0.1382 - val_accuracy: 0.8038 - val_auc: 0.8901\n",
      "Epoch 5/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1353 - accuracy: 0.8061 - auc: 0.8901\n",
      "Epoch 5: val_accuracy improved from 0.80379 to 0.82041, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1351 - accuracy: 0.8063 - auc: 0.8906 - val_loss: 0.1263 - val_accuracy: 0.8204 - val_auc: 0.9062\n",
      "Epoch 6/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1259 - accuracy: 0.8193 - auc: 0.9043\n",
      "Epoch 6: val_accuracy improved from 0.82041 to 0.83287, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.8185 - auc: 0.9035 - val_loss: 0.1185 - val_accuracy: 0.8329 - val_auc: 0.9165\n",
      "Epoch 7/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1205 - accuracy: 0.8275 - auc: 0.9116\n",
      "Epoch 7: val_accuracy improved from 0.83287 to 0.84303, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.8277 - auc: 0.9124 - val_loss: 0.1129 - val_accuracy: 0.8430 - val_auc: 0.9238\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/610 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.8347 - auc: 0.9190\n",
      "Epoch 8: val_accuracy improved from 0.84303 to 0.84488, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.8343 - auc: 0.9189 - val_loss: 0.1095 - val_accuracy: 0.8449 - val_auc: 0.9283\n",
      "Epoch 9/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.8385 - auc: 0.9234\n",
      "Epoch 9: val_accuracy improved from 0.84488 to 0.85088, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.8386 - auc: 0.9237 - val_loss: 0.1061 - val_accuracy: 0.8509 - val_auc: 0.9319\n",
      "Epoch 10/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.8453 - auc: 0.9274\n",
      "Epoch 10: val_accuracy improved from 0.85088 to 0.85180, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8451 - auc: 0.9272 - val_loss: 0.1040 - val_accuracy: 0.8518 - val_auc: 0.9345\n",
      "Epoch 11/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 0.8481 - auc: 0.9302\n",
      "Epoch 11: val_accuracy improved from 0.85180 to 0.85596, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.8480 - auc: 0.9300 - val_loss: 0.1018 - val_accuracy: 0.8560 - val_auc: 0.9371\n",
      "Epoch 12/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1046 - accuracy: 0.8492 - auc: 0.9327\n",
      "Epoch 12: val_accuracy improved from 0.85596 to 0.85642, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.8487 - auc: 0.9325 - val_loss: 0.1000 - val_accuracy: 0.8564 - val_auc: 0.9393\n",
      "Epoch 13/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1030 - accuracy: 0.8522 - auc: 0.9346\n",
      "Epoch 13: val_accuracy improved from 0.85642 to 0.85826, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1029 - accuracy: 0.8523 - auc: 0.9347 - val_loss: 0.0988 - val_accuracy: 0.8583 - val_auc: 0.9406\n",
      "Epoch 14/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.8551 - auc: 0.9373\n",
      "Epoch 14: val_accuracy improved from 0.85826 to 0.86150, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1011 - accuracy: 0.8548 - auc: 0.9370 - val_loss: 0.0969 - val_accuracy: 0.8615 - val_auc: 0.9431\n",
      "Epoch 15/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.0990 - accuracy: 0.8585 - auc: 0.9395\n",
      "Epoch 15: val_accuracy improved from 0.86150 to 0.86196, saving model to \\saved_models1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.8587 - auc: 0.9394 - val_loss: 0.0954 - val_accuracy: 0.8620 - val_auc: 0.9447\n",
      "68/68 [==============================] - 0s 972us/step - loss: 0.0954 - accuracy: 0.8620 - auc: 0.9447\n",
      "Epoch 1/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.6112 - auc: 0.6606\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72992, saving model to \\saved_models1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2431 - accuracy: 0.6132 - auc: 0.6645 - val_loss: 0.2328 - val_accuracy: 0.7299 - val_auc: 0.8155\n",
      "Epoch 2/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.2209 - accuracy: 0.7902 - auc: 0.8555\n",
      "Epoch 2: val_accuracy improved from 0.72992 to 0.81394, saving model to \\saved_models1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2198 - accuracy: 0.7927 - auc: 0.8570 - val_loss: 0.2070 - val_accuracy: 0.8139 - val_auc: 0.8593\n",
      "Epoch 3/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.8352 - auc: 0.8733\n",
      "Epoch 3: val_accuracy improved from 0.81394 to 0.83241, saving model to \\saved_models1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1885 - accuracy: 0.8345 - auc: 0.8730 - val_loss: 0.1752 - val_accuracy: 0.8324 - val_auc: 0.8656\n",
      "Epoch 4/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.8464 - auc: 0.8764\n",
      "Epoch 4: val_accuracy improved from 0.83241 to 0.83703, saving model to \\saved_models1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1579 - accuracy: 0.8466 - auc: 0.8765 - val_loss: 0.1512 - val_accuracy: 0.8370 - val_auc: 0.8689\n",
      "Epoch 5/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.8478 - auc: 0.8821\n",
      "Epoch 5: val_accuracy improved from 0.83703 to 0.83795, saving model to \\saved_models1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1386 - accuracy: 0.8473 - auc: 0.8819 - val_loss: 0.1387 - val_accuracy: 0.8380 - val_auc: 0.8717\n",
      "Epoch 6/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.8476 - auc: 0.8861\n",
      "Epoch 6: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1290 - accuracy: 0.8474 - auc: 0.8859 - val_loss: 0.1331 - val_accuracy: 0.8370 - val_auc: 0.8749\n",
      "Epoch 7/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.8483 - auc: 0.8906\n",
      "Epoch 7: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1245 - accuracy: 0.8478 - auc: 0.8897 - val_loss: 0.1305 - val_accuracy: 0.8366 - val_auc: 0.8779\n",
      "Epoch 8/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1220 - accuracy: 0.8484 - auc: 0.8938\n",
      "Epoch 8: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1221 - accuracy: 0.8481 - auc: 0.8936 - val_loss: 0.1289 - val_accuracy: 0.8361 - val_auc: 0.8810\n",
      "Epoch 9/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1215 - accuracy: 0.8471 - auc: 0.8954\n",
      "Epoch 9: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.8482 - auc: 0.8966 - val_loss: 0.1282 - val_accuracy: 0.8370 - val_auc: 0.8840\n",
      "Epoch 10/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1199 - accuracy: 0.8482 - auc: 0.8993\n",
      "Epoch 10: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.8485 - auc: 0.8995 - val_loss: 0.1276 - val_accuracy: 0.8375 - val_auc: 0.8865\n",
      "Epoch 11/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.8477 - auc: 0.9019\n",
      "Epoch 11: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.8486 - auc: 0.9024 - val_loss: 0.1273 - val_accuracy: 0.8370 - val_auc: 0.8883\n",
      "Epoch 12/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.8483 - auc: 0.9044\n",
      "Epoch 12: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1183 - accuracy: 0.8486 - auc: 0.9044 - val_loss: 0.1269 - val_accuracy: 0.8370 - val_auc: 0.8901\n",
      "Epoch 13/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1180 - accuracy: 0.8481 - auc: 0.9059\n",
      "Epoch 13: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1176 - accuracy: 0.8489 - auc: 0.9065 - val_loss: 0.1265 - val_accuracy: 0.8366 - val_auc: 0.8918\n",
      "Epoch 14/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1169 - accuracy: 0.8485 - auc: 0.9081\n",
      "Epoch 14: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.8482 - auc: 0.9083 - val_loss: 0.1261 - val_accuracy: 0.8370 - val_auc: 0.8932\n",
      "Epoch 15/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.8487 - auc: 0.9096\n",
      "Epoch 15: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1164 - accuracy: 0.8489 - auc: 0.9099 - val_loss: 0.1258 - val_accuracy: 0.8347 - val_auc: 0.8944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 963us/step - loss: 0.1387 - accuracy: 0.8380 - auc: 0.8717\n",
      "Epoch 1/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.2396 - accuracy: 0.5901 - auc: 0.7066\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69760, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2393 - accuracy: 0.5927 - auc: 0.7106 - val_loss: 0.2274 - val_accuracy: 0.6976 - val_auc: 0.8204\n",
      "Epoch 2/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.2077 - accuracy: 0.7890 - auc: 0.8626\n",
      "Epoch 2: val_accuracy improved from 0.69760 to 0.79548, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2075 - accuracy: 0.7897 - auc: 0.8630 - val_loss: 0.1955 - val_accuracy: 0.7955 - val_auc: 0.8486\n",
      "Epoch 3/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1728 - accuracy: 0.8366 - auc: 0.8754\n",
      "Epoch 3: val_accuracy improved from 0.79548 to 0.81302, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1720 - accuracy: 0.8368 - auc: 0.8749 - val_loss: 0.1666 - val_accuracy: 0.8130 - val_auc: 0.8550\n",
      "Epoch 4/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1461 - accuracy: 0.8445 - auc: 0.8804\n",
      "Epoch 4: val_accuracy improved from 0.81302 to 0.81533, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1456 - accuracy: 0.8449 - auc: 0.8810 - val_loss: 0.1504 - val_accuracy: 0.8153 - val_auc: 0.8597\n",
      "Epoch 5/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.8464 - auc: 0.8848\n",
      "Epoch 5: val_accuracy improved from 0.81533 to 0.81810, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1318 - accuracy: 0.8466 - auc: 0.8852 - val_loss: 0.1436 - val_accuracy: 0.8181 - val_auc: 0.8632\n",
      "Epoch 6/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.8482 - auc: 0.8893\n",
      "Epoch 6: val_accuracy improved from 0.81810 to 0.81856, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1254 - accuracy: 0.8476 - auc: 0.8887 - val_loss: 0.1408 - val_accuracy: 0.8186 - val_auc: 0.8661\n",
      "Epoch 7/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.8482 - auc: 0.8917\n",
      "Epoch 7: val_accuracy did not improve from 0.81856\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.8486 - auc: 0.8918 - val_loss: 0.1397 - val_accuracy: 0.8186 - val_auc: 0.8689\n",
      "Epoch 8/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.8493 - auc: 0.8946\n",
      "Epoch 8: val_accuracy did not improve from 0.81856\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.8489 - auc: 0.8945 - val_loss: 0.1391 - val_accuracy: 0.8186 - val_auc: 0.8717\n",
      "Epoch 9/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.8491 - auc: 0.8971\n",
      "Epoch 9: val_accuracy improved from 0.81856 to 0.81902, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1197 - accuracy: 0.8491 - auc: 0.8969 - val_loss: 0.1388 - val_accuracy: 0.8190 - val_auc: 0.8742\n",
      "Epoch 10/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.8491 - auc: 0.8991\n",
      "Epoch 10: val_accuracy did not improve from 0.81902\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.8490 - auc: 0.8989 - val_loss: 0.1384 - val_accuracy: 0.8186 - val_auc: 0.8762\n",
      "Epoch 11/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.8494 - auc: 0.9011\n",
      "Epoch 11: val_accuracy did not improve from 0.81902\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.8493 - auc: 0.9009 - val_loss: 0.1381 - val_accuracy: 0.8190 - val_auc: 0.8786\n",
      "Epoch 12/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1179 - accuracy: 0.8495 - auc: 0.9028\n",
      "Epoch 12: val_accuracy improved from 0.81902 to 0.81948, saving model to \\saved_models1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.8495 - auc: 0.9028 - val_loss: 0.1377 - val_accuracy: 0.8195 - val_auc: 0.8808\n",
      "Epoch 13/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.8485 - auc: 0.9039\n",
      "Epoch 13: val_accuracy did not improve from 0.81948\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1175 - accuracy: 0.8494 - auc: 0.9044 - val_loss: 0.1373 - val_accuracy: 0.8186 - val_auc: 0.8825\n",
      "Epoch 14/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.8493 - auc: 0.9057\n",
      "Epoch 14: val_accuracy did not improve from 0.81948\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.8494 - auc: 0.9059 - val_loss: 0.1368 - val_accuracy: 0.8186 - val_auc: 0.8840\n",
      "Epoch 15/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.8503 - auc: 0.9077\n",
      "Epoch 15: val_accuracy did not improve from 0.81948\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.8499 - auc: 0.9074 - val_loss: 0.1364 - val_accuracy: 0.8181 - val_auc: 0.8855\n",
      "68/68 [==============================] - 0s 938us/step - loss: 0.1377 - accuracy: 0.8195 - auc: 0.8808\n",
      "Epoch 1/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.2368 - accuracy: 0.6108 - auc: 0.6654\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70314, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.6157 - auc: 0.6699 - val_loss: 0.2222 - val_accuracy: 0.7031 - val_auc: 0.7620\n",
      "Epoch 2/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.2100 - accuracy: 0.7211 - auc: 0.7912\n",
      "Epoch 2: val_accuracy improved from 0.70314 to 0.77193, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2093 - accuracy: 0.7232 - auc: 0.7935 - val_loss: 0.1928 - val_accuracy: 0.7719 - val_auc: 0.8315\n",
      "Epoch 3/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.7707 - auc: 0.8456\n",
      "Epoch 3: val_accuracy improved from 0.77193 to 0.80840, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1794 - accuracy: 0.7721 - auc: 0.8468 - val_loss: 0.1611 - val_accuracy: 0.8084 - val_auc: 0.8717\n",
      "Epoch 4/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.8078 - auc: 0.8786\n",
      "Epoch 4: val_accuracy improved from 0.80840 to 0.83241, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1527 - accuracy: 0.8086 - auc: 0.8793 - val_loss: 0.1379 - val_accuracy: 0.8324 - val_auc: 0.8958\n",
      "Epoch 5/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.8307 - auc: 0.8962\n",
      "Epoch 5: val_accuracy improved from 0.83241 to 0.84995, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1352 - accuracy: 0.8307 - auc: 0.8958 - val_loss: 0.1239 - val_accuracy: 0.8500 - val_auc: 0.9081\n",
      "Epoch 6/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.8384 - auc: 0.9042\n",
      "Epoch 6: val_accuracy improved from 0.84995 to 0.85319, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1255 - accuracy: 0.8387 - auc: 0.9045 - val_loss: 0.1171 - val_accuracy: 0.8532 - val_auc: 0.9145\n",
      "Epoch 7/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.8431 - auc: 0.9092\n",
      "Epoch 7: val_accuracy did not improve from 0.85319\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.8436 - auc: 0.9095 - val_loss: 0.1132 - val_accuracy: 0.8527 - val_auc: 0.9180\n",
      "Epoch 8/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1177 - accuracy: 0.8447 - auc: 0.9123\n",
      "Epoch 8: val_accuracy improved from 0.85319 to 0.85365, saving model to \\saved_models1/model_5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.8449 - auc: 0.9128 - val_loss: 0.1112 - val_accuracy: 0.8536 - val_auc: 0.9205\n",
      "Epoch 9/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.8476 - auc: 0.9155\n",
      "Epoch 9: val_accuracy improved from 0.85365 to 0.85457, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1157 - accuracy: 0.8471 - auc: 0.9151 - val_loss: 0.1097 - val_accuracy: 0.8546 - val_auc: 0.9223\n",
      "Epoch 10/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.8472 - auc: 0.9170\n",
      "Epoch 10: val_accuracy improved from 0.85457 to 0.85503, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8474 - auc: 0.9171 - val_loss: 0.1089 - val_accuracy: 0.8550 - val_auc: 0.9237\n",
      "Epoch 11/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.8490 - auc: 0.9189\n",
      "Epoch 11: val_accuracy improved from 0.85503 to 0.85688, saving model to \\saved_models1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8482 - auc: 0.9185 - val_loss: 0.1082 - val_accuracy: 0.8569 - val_auc: 0.9244\n",
      "Epoch 12/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.8487 - auc: 0.9201\n",
      "Epoch 12: val_accuracy did not improve from 0.85688\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.8487 - auc: 0.9198 - val_loss: 0.1077 - val_accuracy: 0.8569 - val_auc: 0.9253\n",
      "Epoch 13/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1120 - accuracy: 0.8492 - auc: 0.9211\n",
      "Epoch 13: val_accuracy did not improve from 0.85688\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.8486 - auc: 0.9208 - val_loss: 0.1074 - val_accuracy: 0.8564 - val_auc: 0.9262\n",
      "Epoch 14/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.8489 - auc: 0.9220\n",
      "Epoch 14: val_accuracy did not improve from 0.85688\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.8489 - auc: 0.9220 - val_loss: 0.1069 - val_accuracy: 0.8569 - val_auc: 0.9267\n",
      "Epoch 15/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.8491 - auc: 0.9230\n",
      "Epoch 15: val_accuracy did not improve from 0.85688\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1112 - accuracy: 0.8490 - auc: 0.9230 - val_loss: 0.1067 - val_accuracy: 0.8569 - val_auc: 0.9276\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8569 - auc: 0.9244\n",
      "Epoch 1/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2253 - accuracy: 0.6549 - auc: 0.7173\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73777, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2248 - accuracy: 0.6562 - auc: 0.7189 - val_loss: 0.1984 - val_accuracy: 0.7378 - val_auc: 0.8117\n",
      "Epoch 2/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.7628 - auc: 0.8407\n",
      "Epoch 2: val_accuracy improved from 0.73777 to 0.77562, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1746 - accuracy: 0.7642 - auc: 0.8420 - val_loss: 0.1593 - val_accuracy: 0.7756 - val_auc: 0.8620\n",
      "Epoch 3/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1457 - accuracy: 0.8017 - auc: 0.8805\n",
      "Epoch 3: val_accuracy improved from 0.77562 to 0.80102, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1457 - accuracy: 0.8013 - auc: 0.8803 - val_loss: 0.1391 - val_accuracy: 0.8010 - val_auc: 0.8875\n",
      "Epoch 4/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1313 - accuracy: 0.8198 - auc: 0.8980\n",
      "Epoch 4: val_accuracy improved from 0.80102 to 0.81117, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1309 - accuracy: 0.8201 - auc: 0.8987 - val_loss: 0.1293 - val_accuracy: 0.8112 - val_auc: 0.8993\n",
      "Epoch 5/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1229 - accuracy: 0.8294 - auc: 0.9085\n",
      "Epoch 5: val_accuracy improved from 0.81117 to 0.82364, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.8295 - auc: 0.9084 - val_loss: 0.1239 - val_accuracy: 0.8236 - val_auc: 0.9062\n",
      "Epoch 6/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.8347 - auc: 0.9148\n",
      "Epoch 6: val_accuracy improved from 0.82364 to 0.82872, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1179 - accuracy: 0.8347 - auc: 0.9148 - val_loss: 0.1205 - val_accuracy: 0.8287 - val_auc: 0.9111\n",
      "Epoch 7/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1143 - accuracy: 0.8408 - auc: 0.9195\n",
      "Epoch 7: val_accuracy improved from 0.82872 to 0.83426, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8401 - auc: 0.9191 - val_loss: 0.1184 - val_accuracy: 0.8343 - val_auc: 0.9145\n",
      "Epoch 8/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1126 - accuracy: 0.8426 - auc: 0.9215\n",
      "Epoch 8: val_accuracy improved from 0.83426 to 0.83657, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.8428 - auc: 0.9222 - val_loss: 0.1161 - val_accuracy: 0.8366 - val_auc: 0.9169\n",
      "Epoch 9/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1104 - accuracy: 0.8441 - auc: 0.9245\n",
      "Epoch 9: val_accuracy did not improve from 0.83657\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.8449 - auc: 0.9247 - val_loss: 0.1150 - val_accuracy: 0.8361 - val_auc: 0.9189\n",
      "Epoch 10/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1081 - accuracy: 0.8480 - auc: 0.9276\n",
      "Epoch 10: val_accuracy improved from 0.83657 to 0.84072, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1087 - accuracy: 0.8472 - auc: 0.9268 - val_loss: 0.1136 - val_accuracy: 0.8407 - val_auc: 0.9208\n",
      "Epoch 11/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1075 - accuracy: 0.8495 - auc: 0.9285\n",
      "Epoch 11: val_accuracy improved from 0.84072 to 0.84164, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1073 - accuracy: 0.8492 - auc: 0.9288 - val_loss: 0.1126 - val_accuracy: 0.8416 - val_auc: 0.9223\n",
      "Epoch 12/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1060 - accuracy: 0.8504 - auc: 0.9303\n",
      "Epoch 12: val_accuracy improved from 0.84164 to 0.84303, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.8504 - auc: 0.9304 - val_loss: 0.1114 - val_accuracy: 0.8430 - val_auc: 0.9239\n",
      "Epoch 13/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1043 - accuracy: 0.8536 - auc: 0.9327\n",
      "Epoch 13: val_accuracy did not improve from 0.84303\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.8527 - auc: 0.9322 - val_loss: 0.1109 - val_accuracy: 0.8416 - val_auc: 0.9254\n",
      "Epoch 14/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1032 - accuracy: 0.8537 - auc: 0.9342\n",
      "Epoch 14: val_accuracy improved from 0.84303 to 0.84395, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.8535 - auc: 0.9338 - val_loss: 0.1093 - val_accuracy: 0.8440 - val_auc: 0.9271\n",
      "Epoch 15/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.8557 - auc: 0.9362\n",
      "Epoch 15: val_accuracy improved from 0.84395 to 0.84534, saving model to \\saved_models1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.8554 - auc: 0.9358 - val_loss: 0.1081 - val_accuracy: 0.8453 - val_auc: 0.9288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8453 - auc: 0.9288\n",
      "Epoch 1/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.2314 - accuracy: 0.6752 - auc: 0.7144\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75115, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2303 - accuracy: 0.6793 - auc: 0.7208 - val_loss: 0.2080 - val_accuracy: 0.7512 - val_auc: 0.8151\n",
      "Epoch 2/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.7648 - auc: 0.8381\n",
      "Epoch 2: val_accuracy improved from 0.75115 to 0.79086, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1876 - accuracy: 0.7651 - auc: 0.8383 - val_loss: 0.1685 - val_accuracy: 0.7909 - val_auc: 0.8652\n",
      "Epoch 3/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.8026 - auc: 0.8729\n",
      "Epoch 3: val_accuracy improved from 0.79086 to 0.81902, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1560 - accuracy: 0.8022 - auc: 0.8726 - val_loss: 0.1429 - val_accuracy: 0.8190 - val_auc: 0.8913\n",
      "Epoch 4/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1367 - accuracy: 0.8258 - auc: 0.8929\n",
      "Epoch 4: val_accuracy improved from 0.81902 to 0.83564, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1367 - accuracy: 0.8249 - auc: 0.8926 - val_loss: 0.1288 - val_accuracy: 0.8356 - val_auc: 0.9030\n",
      "Epoch 5/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1255 - accuracy: 0.8364 - auc: 0.9034\n",
      "Epoch 5: val_accuracy improved from 0.83564 to 0.84072, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1261 - accuracy: 0.8351 - auc: 0.9024 - val_loss: 0.1215 - val_accuracy: 0.8407 - val_auc: 0.9088\n",
      "Epoch 6/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1202 - accuracy: 0.8406 - auc: 0.9085\n",
      "Epoch 6: val_accuracy improved from 0.84072 to 0.84395, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1202 - accuracy: 0.8408 - auc: 0.9082 - val_loss: 0.1178 - val_accuracy: 0.8440 - val_auc: 0.9123\n",
      "Epoch 7/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.8443 - auc: 0.9126\n",
      "Epoch 7: val_accuracy improved from 0.84395 to 0.84718, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.8441 - auc: 0.9124 - val_loss: 0.1154 - val_accuracy: 0.8472 - val_auc: 0.9147\n",
      "Epoch 8/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.8458 - auc: 0.9154\n",
      "Epoch 8: val_accuracy improved from 0.84718 to 0.84903, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.8457 - auc: 0.9153 - val_loss: 0.1142 - val_accuracy: 0.8490 - val_auc: 0.9163\n",
      "Epoch 9/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1135 - accuracy: 0.8460 - auc: 0.9176\n",
      "Epoch 9: val_accuracy did not improve from 0.84903\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1132 - accuracy: 0.8463 - auc: 0.9179 - val_loss: 0.1134 - val_accuracy: 0.8490 - val_auc: 0.9170\n",
      "Epoch 10/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1117 - accuracy: 0.8480 - auc: 0.9200\n",
      "Epoch 10: val_accuracy improved from 0.84903 to 0.84995, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.8475 - auc: 0.9193 - val_loss: 0.1127 - val_accuracy: 0.8500 - val_auc: 0.9183\n",
      "Epoch 11/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1114 - accuracy: 0.8480 - auc: 0.9210\n",
      "Epoch 11: val_accuracy improved from 0.84995 to 0.85272, saving model to \\saved_models1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.8482 - auc: 0.9210 - val_loss: 0.1123 - val_accuracy: 0.8527 - val_auc: 0.9195\n",
      "Epoch 12/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1108 - accuracy: 0.8477 - auc: 0.9221\n",
      "Epoch 12: val_accuracy did not improve from 0.85272\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.8483 - auc: 0.9222 - val_loss: 0.1118 - val_accuracy: 0.8523 - val_auc: 0.9200\n",
      "Epoch 13/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1106 - accuracy: 0.8485 - auc: 0.9226\n",
      "Epoch 13: val_accuracy did not improve from 0.85272\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.8493 - auc: 0.9233 - val_loss: 0.1113 - val_accuracy: 0.8509 - val_auc: 0.9209\n",
      "Epoch 14/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1095 - accuracy: 0.8502 - auc: 0.9242\n",
      "Epoch 14: val_accuracy did not improve from 0.85272\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.8503 - auc: 0.9242 - val_loss: 0.1111 - val_accuracy: 0.8504 - val_auc: 0.9214\n",
      "Epoch 15/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1088 - accuracy: 0.8505 - auc: 0.9253\n",
      "Epoch 15: val_accuracy did not improve from 0.85272\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.8506 - auc: 0.9250 - val_loss: 0.1109 - val_accuracy: 0.8504 - val_auc: 0.9218\n",
      "68/68 [==============================] - 0s 994us/step - loss: 0.1123 - accuracy: 0.8527 - auc: 0.9195\n",
      "Epoch 1/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2446 - accuracy: 0.5759 - auc: 0.6042\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63343, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.5762 - auc: 0.6043 - val_loss: 0.2358 - val_accuracy: 0.6334 - val_auc: 0.6794\n",
      "Epoch 2/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.2249 - accuracy: 0.6710 - auc: 0.7262\n",
      "Epoch 2: val_accuracy improved from 0.63343 to 0.70129, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2240 - accuracy: 0.6734 - auc: 0.7292 - val_loss: 0.2088 - val_accuracy: 0.7013 - val_auc: 0.7662\n",
      "Epoch 3/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1925 - accuracy: 0.7260 - auc: 0.7970\n",
      "Epoch 3: val_accuracy improved from 0.70129 to 0.75485, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1919 - accuracy: 0.7263 - auc: 0.7978 - val_loss: 0.1748 - val_accuracy: 0.7548 - val_auc: 0.8259\n",
      "Epoch 4/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1616 - accuracy: 0.7670 - auc: 0.8490\n",
      "Epoch 4: val_accuracy improved from 0.75485 to 0.78163, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1611 - accuracy: 0.7673 - auc: 0.8499 - val_loss: 0.1496 - val_accuracy: 0.7816 - val_auc: 0.8678\n",
      "Epoch 5/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1410 - accuracy: 0.7954 - auc: 0.8824\n",
      "Epoch 5: val_accuracy improved from 0.78163 to 0.80979, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1404 - accuracy: 0.7962 - auc: 0.8832 - val_loss: 0.1342 - val_accuracy: 0.8098 - val_auc: 0.8918\n",
      "Epoch 6/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1281 - accuracy: 0.8161 - auc: 0.9013\n",
      "Epoch 6: val_accuracy improved from 0.80979 to 0.82548, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1282 - accuracy: 0.8158 - auc: 0.9011 - val_loss: 0.1243 - val_accuracy: 0.8255 - val_auc: 0.9068\n",
      "Epoch 7/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1208 - accuracy: 0.8259 - auc: 0.9116\n",
      "Epoch 7: val_accuracy improved from 0.82548 to 0.83102, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1205 - accuracy: 0.8265 - auc: 0.9119 - val_loss: 0.1171 - val_accuracy: 0.8310 - val_auc: 0.9168\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608/610 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.8348 - auc: 0.9190\n",
      "Epoch 8: val_accuracy improved from 0.83102 to 0.84026, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.8347 - auc: 0.9190 - val_loss: 0.1121 - val_accuracy: 0.8403 - val_auc: 0.9239\n",
      "Epoch 9/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.8382 - auc: 0.9238\n",
      "Epoch 9: val_accuracy improved from 0.84026 to 0.84395, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.8386 - auc: 0.9242 - val_loss: 0.1084 - val_accuracy: 0.8440 - val_auc: 0.9290\n",
      "Epoch 10/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.8462 - auc: 0.9288\n",
      "Epoch 10: val_accuracy improved from 0.84395 to 0.84580, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1081 - accuracy: 0.8453 - auc: 0.9283 - val_loss: 0.1051 - val_accuracy: 0.8458 - val_auc: 0.9332\n",
      "Epoch 11/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.8482 - auc: 0.9317\n",
      "Epoch 11: val_accuracy improved from 0.84580 to 0.85226, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.8483 - auc: 0.9317 - val_loss: 0.1024 - val_accuracy: 0.8523 - val_auc: 0.9369\n",
      "Epoch 12/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 0.8523 - auc: 0.9350\n",
      "Epoch 12: val_accuracy improved from 0.85226 to 0.85734, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1027 - accuracy: 0.8523 - auc: 0.9351 - val_loss: 0.0998 - val_accuracy: 0.8573 - val_auc: 0.9404\n",
      "Epoch 13/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.8576 - auc: 0.9388\n",
      "Epoch 13: val_accuracy improved from 0.85734 to 0.86427, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.8569 - auc: 0.9382 - val_loss: 0.0966 - val_accuracy: 0.8643 - val_auc: 0.9432\n",
      "Epoch 14/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.8625 - auc: 0.9416\n",
      "Epoch 14: val_accuracy did not improve from 0.86427\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0974 - accuracy: 0.8620 - auc: 0.9414 - val_loss: 0.0948 - val_accuracy: 0.8624 - val_auc: 0.9457\n",
      "Epoch 15/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.8650 - auc: 0.9447\n",
      "Epoch 15: val_accuracy improved from 0.86427 to 0.87165, saving model to \\saved_models1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0945 - accuracy: 0.8651 - auc: 0.9446 - val_loss: 0.0913 - val_accuracy: 0.8717 - val_auc: 0.9496\n",
      "68/68 [==============================] - 0s 966us/step - loss: 0.0913 - accuracy: 0.8717 - auc: 0.9496\n",
      "Epoch 1/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.6064 - auc: 0.6419\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69838, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2390 - accuracy: 0.6080 - auc: 0.6445 - val_loss: 0.2229 - val_accuracy: 0.6984 - val_auc: 0.7525\n",
      "Epoch 2/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.2081 - accuracy: 0.7129 - auc: 0.7770\n",
      "Epoch 2: val_accuracy improved from 0.69838 to 0.76952, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2072 - accuracy: 0.7149 - auc: 0.7791 - val_loss: 0.1844 - val_accuracy: 0.7695 - val_auc: 0.8330\n",
      "Epoch 3/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.7748 - auc: 0.8473\n",
      "Epoch 3: val_accuracy improved from 0.76952 to 0.79908, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1701 - accuracy: 0.7748 - auc: 0.8475 - val_loss: 0.1494 - val_accuracy: 0.7991 - val_auc: 0.8799\n",
      "Epoch 4/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.8073 - auc: 0.8835\n",
      "Epoch 4: val_accuracy improved from 0.79908 to 0.82125, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.8080 - auc: 0.8842 - val_loss: 0.1301 - val_accuracy: 0.8212 - val_auc: 0.9015\n",
      "Epoch 5/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1293 - accuracy: 0.8212 - auc: 0.9004\n",
      "Epoch 5: val_accuracy improved from 0.82125 to 0.83279, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1290 - accuracy: 0.8218 - auc: 0.9008 - val_loss: 0.1207 - val_accuracy: 0.8328 - val_auc: 0.9120\n",
      "Epoch 6/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1217 - accuracy: 0.8317 - auc: 0.9096\n",
      "Epoch 6: val_accuracy improved from 0.83279 to 0.83741, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1216 - accuracy: 0.8315 - auc: 0.9098 - val_loss: 0.1154 - val_accuracy: 0.8374 - val_auc: 0.9184\n",
      "Epoch 7/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 0.8378 - auc: 0.9163\n",
      "Epoch 7: val_accuracy improved from 0.83741 to 0.84342, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.8375 - auc: 0.9161 - val_loss: 0.1113 - val_accuracy: 0.8434 - val_auc: 0.9232\n",
      "Epoch 8/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1138 - accuracy: 0.8412 - auc: 0.9202\n",
      "Epoch 8: val_accuracy improved from 0.84342 to 0.85219, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8411 - auc: 0.9205 - val_loss: 0.1087 - val_accuracy: 0.8522 - val_auc: 0.9264\n",
      "Epoch 9/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.8440 - auc: 0.9239\n",
      "Epoch 9: val_accuracy did not improve from 0.85219\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.8440 - auc: 0.9239 - val_loss: 0.1068 - val_accuracy: 0.8494 - val_auc: 0.9288\n",
      "Epoch 10/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.8474 - auc: 0.9266\n",
      "Epoch 10: val_accuracy improved from 0.85219 to 0.85543, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8476 - auc: 0.9267 - val_loss: 0.1056 - val_accuracy: 0.8554 - val_auc: 0.9307\n",
      "Epoch 11/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.8479 - auc: 0.9287\n",
      "Epoch 11: val_accuracy improved from 0.85543 to 0.85589, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.8480 - auc: 0.9289 - val_loss: 0.1045 - val_accuracy: 0.8559 - val_auc: 0.9318\n",
      "Epoch 12/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1062 - accuracy: 0.8494 - auc: 0.9306\n",
      "Epoch 12: val_accuracy improved from 0.85589 to 0.85866, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1059 - accuracy: 0.8500 - auc: 0.9310 - val_loss: 0.1029 - val_accuracy: 0.8587 - val_auc: 0.9338\n",
      "Epoch 13/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1048 - accuracy: 0.8517 - auc: 0.9323\n",
      "Epoch 13: val_accuracy did not improve from 0.85866\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.8523 - auc: 0.9329 - val_loss: 0.1029 - val_accuracy: 0.8587 - val_auc: 0.9352\n",
      "Epoch 14/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.8526 - auc: 0.9349\n",
      "Epoch 14: val_accuracy improved from 0.85866 to 0.86051, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1029 - accuracy: 0.8526 - auc: 0.9349 - val_loss: 0.1004 - val_accuracy: 0.8605 - val_auc: 0.9371\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/610 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.8553 - auc: 0.9374\n",
      "Epoch 15: val_accuracy improved from 0.86051 to 0.86282, saving model to \\saved_models1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.8548 - auc: 0.9370 - val_loss: 0.0989 - val_accuracy: 0.8628 - val_auc: 0.9391\n",
      "68/68 [==============================] - 0s 989us/step - loss: 0.0989 - accuracy: 0.8628 - auc: 0.9391\n",
      "Epoch 1/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2452 - accuracy: 0.5736 - auc: 0.5889\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66744, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.5742 - auc: 0.5916 - val_loss: 0.2355 - val_accuracy: 0.6674 - val_auc: 0.7233\n",
      "Epoch 2/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.2264 - accuracy: 0.7055 - auc: 0.7868\n",
      "Epoch 2: val_accuracy improved from 0.66744 to 0.76952, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2259 - accuracy: 0.7074 - auc: 0.7885 - val_loss: 0.2135 - val_accuracy: 0.7695 - val_auc: 0.8343\n",
      "Epoch 3/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.2002 - accuracy: 0.7905 - auc: 0.8533\n",
      "Epoch 3: val_accuracy improved from 0.76952 to 0.81986, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1992 - accuracy: 0.7916 - auc: 0.8541 - val_loss: 0.1819 - val_accuracy: 0.8199 - val_auc: 0.8744\n",
      "Epoch 4/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.8269 - auc: 0.8744\n",
      "Epoch 4: val_accuracy improved from 0.81986 to 0.84434, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.8268 - auc: 0.8742 - val_loss: 0.1523 - val_accuracy: 0.8443 - val_auc: 0.8859\n",
      "Epoch 5/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1447 - accuracy: 0.8428 - auc: 0.8828\n",
      "Epoch 5: val_accuracy improved from 0.84434 to 0.85219, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1447 - accuracy: 0.8422 - auc: 0.8821 - val_loss: 0.1343 - val_accuracy: 0.8522 - val_auc: 0.8907\n",
      "Epoch 6/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1329 - accuracy: 0.8443 - auc: 0.8864\n",
      "Epoch 6: val_accuracy improved from 0.85219 to 0.85312, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1322 - accuracy: 0.8454 - auc: 0.8872 - val_loss: 0.1254 - val_accuracy: 0.8531 - val_auc: 0.8944\n",
      "Epoch 7/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1265 - accuracy: 0.8462 - auc: 0.8907\n",
      "Epoch 7: val_accuracy did not improve from 0.85312\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1262 - accuracy: 0.8467 - auc: 0.8912 - val_loss: 0.1211 - val_accuracy: 0.8531 - val_auc: 0.8978\n",
      "Epoch 8/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.8475 - auc: 0.8949\n",
      "Epoch 8: val_accuracy did not improve from 0.85312\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1232 - accuracy: 0.8471 - auc: 0.8948 - val_loss: 0.1188 - val_accuracy: 0.8531 - val_auc: 0.9006\n",
      "Epoch 9/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.8468 - auc: 0.8980\n",
      "Epoch 9: val_accuracy did not improve from 0.85312\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.8470 - auc: 0.8979 - val_loss: 0.1174 - val_accuracy: 0.8531 - val_auc: 0.9029\n",
      "Epoch 10/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1200 - accuracy: 0.8472 - auc: 0.9014\n",
      "Epoch 10: val_accuracy improved from 0.85312 to 0.85404, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1204 - accuracy: 0.8468 - auc: 0.9005 - val_loss: 0.1165 - val_accuracy: 0.8540 - val_auc: 0.9051\n",
      "Epoch 11/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.8470 - auc: 0.9028\n",
      "Epoch 11: val_accuracy did not improve from 0.85404\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1195 - accuracy: 0.8472 - auc: 0.9029 - val_loss: 0.1158 - val_accuracy: 0.8536 - val_auc: 0.9071\n",
      "Epoch 12/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 0.8484 - auc: 0.9057\n",
      "Epoch 12: val_accuracy did not improve from 0.85404\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1188 - accuracy: 0.8472 - auc: 0.9048 - val_loss: 0.1150 - val_accuracy: 0.8536 - val_auc: 0.9090\n",
      "Epoch 13/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 0.8474 - auc: 0.9066\n",
      "Epoch 13: val_accuracy did not improve from 0.85404\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.8474 - auc: 0.9067 - val_loss: 0.1143 - val_accuracy: 0.8531 - val_auc: 0.9107\n",
      "Epoch 14/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.8473 - auc: 0.9077\n",
      "Epoch 14: val_accuracy did not improve from 0.85404\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1176 - accuracy: 0.8477 - auc: 0.9084 - val_loss: 0.1138 - val_accuracy: 0.8540 - val_auc: 0.9122\n",
      "Epoch 15/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.8490 - auc: 0.9104\n",
      "Epoch 15: val_accuracy improved from 0.85404 to 0.85543, saving model to \\saved_models1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.8485 - auc: 0.9101 - val_loss: 0.1133 - val_accuracy: 0.8554 - val_auc: 0.9135\n",
      "68/68 [==============================] - 0s 990us/step - loss: 0.1133 - accuracy: 0.8554 - auc: 0.9135\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY1 = []\n",
    "VALIDATION_AUC1 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names1].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names1].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names1):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model1 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model1.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models1/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history1 = model1.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model1.load_weights(\"\\saved_models1/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model1.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model1.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY1.append(results['accuracy'])\n",
    "    VALIDATION_AUC1.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history1.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above visualizes the performance of the network on the training data and validation data versus the training iterations for the 10th fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8513388633728027 | 0.924900472164154  |\n",
      "|  2   | 0.8619575500488281 | 0.9446778297424316 |\n",
      "|  3   | 0.8379501104354858 | 0.8717092275619507 |\n",
      "|  4   | 0.8194829225540161 | 0.8808018565177917 |\n",
      "|  5   | 0.8568790555000305 | 0.9243960976600647 |\n",
      "|  6   | 0.8453370332717896 | 0.9288032054901123 |\n",
      "|  7   | 0.8527238965034485 | 0.9194851517677307 |\n",
      "|  8   | 0.8716528415679932 | 0.9496077299118042 |\n",
      "|  9   | 0.8628175258636475 | 0.9390691518783569 |\n",
      "|  10  | 0.8554272651672363 | 0.9135077595710754 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY1)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the table above, the first fold yielded the best raw results for validation accuracy and AUC, so we will utilize the weights from the model fit in that fold to apply to the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 8\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY1.index(max(VALIDATION_ACCURACY1))\n",
    "max_fold1 = idx + 1\n",
    "print(\"Best Fold:\", max_fold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.8108 - auc: 0.8962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13132330775260925, 0.8107746839523315, 0.8961811065673828]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_weights(\"\\saved_models1/model_\"+str(max_fold1)+\".h5\")\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model1.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 820us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model1.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat1 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.6028 - auc: 0.6194\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68006, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.6036 - auc: 0.6209 - val_loss: 0.2313 - val_accuracy: 0.6801 - val_auc: 0.7160\n",
      "Epoch 2/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.6908 - auc: 0.7473\n",
      "Epoch 2: val_accuracy improved from 0.68006 to 0.72946, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2167 - accuracy: 0.6904 - auc: 0.7470 - val_loss: 0.1961 - val_accuracy: 0.7295 - val_auc: 0.7942\n",
      "Epoch 3/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1835 - accuracy: 0.7343 - auc: 0.8092\n",
      "Epoch 3: val_accuracy improved from 0.72946 to 0.76777, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1824 - accuracy: 0.7364 - auc: 0.8112 - val_loss: 0.1627 - val_accuracy: 0.7678 - val_auc: 0.8498\n",
      "Epoch 4/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1538 - accuracy: 0.7778 - auc: 0.8624\n",
      "Epoch 4: val_accuracy improved from 0.76777 to 0.80748, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1535 - accuracy: 0.7780 - auc: 0.8630 - val_loss: 0.1376 - val_accuracy: 0.8075 - val_auc: 0.8898\n",
      "Epoch 5/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1346 - accuracy: 0.8066 - auc: 0.8928\n",
      "Epoch 5: val_accuracy improved from 0.80748 to 0.81533, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1340 - accuracy: 0.8075 - auc: 0.8935 - val_loss: 0.1245 - val_accuracy: 0.8153 - val_auc: 0.9082\n",
      "Epoch 6/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.8210 - auc: 0.9090\n",
      "Epoch 6: val_accuracy improved from 0.81533 to 0.82548, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.8211 - auc: 0.9090 - val_loss: 0.1173 - val_accuracy: 0.8255 - val_auc: 0.9183\n",
      "Epoch 7/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.8305 - auc: 0.9182\n",
      "Epoch 7: val_accuracy improved from 0.82548 to 0.83241, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1163 - accuracy: 0.8304 - auc: 0.9181 - val_loss: 0.1121 - val_accuracy: 0.8324 - val_auc: 0.9244\n",
      "Epoch 8/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.8352 - auc: 0.9240\n",
      "Epoch 8: val_accuracy improved from 0.83241 to 0.83795, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.8362 - auc: 0.9245 - val_loss: 0.1083 - val_accuracy: 0.8380 - val_auc: 0.9293\n",
      "Epoch 9/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.8439 - auc: 0.9296\n",
      "Epoch 9: val_accuracy improved from 0.83795 to 0.84534, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.8440 - auc: 0.9297 - val_loss: 0.1051 - val_accuracy: 0.8453 - val_auc: 0.9335\n",
      "Epoch 10/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1038 - accuracy: 0.8497 - auc: 0.9342\n",
      "Epoch 10: val_accuracy did not improve from 0.84534\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.8501 - auc: 0.9342 - val_loss: 0.1021 - val_accuracy: 0.8430 - val_auc: 0.9373\n",
      "Epoch 11/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1003 - accuracy: 0.8556 - auc: 0.9384\n",
      "Epoch 11: val_accuracy improved from 0.84534 to 0.85180, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1004 - accuracy: 0.8552 - auc: 0.9382 - val_loss: 0.0984 - val_accuracy: 0.8518 - val_auc: 0.9416\n",
      "Epoch 12/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.8628 - auc: 0.9423\n",
      "Epoch 12: val_accuracy improved from 0.85180 to 0.85319, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.8627 - auc: 0.9422 - val_loss: 0.0974 - val_accuracy: 0.8532 - val_auc: 0.9437\n",
      "Epoch 13/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.0940 - accuracy: 0.8683 - auc: 0.9456\n",
      "Epoch 13: val_accuracy improved from 0.85319 to 0.86657, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.8686 - auc: 0.9460 - val_loss: 0.0914 - val_accuracy: 0.8666 - val_auc: 0.9489\n",
      "Epoch 14/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.0898 - accuracy: 0.8741 - auc: 0.9502\n",
      "Epoch 14: val_accuracy improved from 0.86657 to 0.87073, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.8741 - auc: 0.9499 - val_loss: 0.0888 - val_accuracy: 0.8707 - val_auc: 0.9517\n",
      "Epoch 15/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.0871 - accuracy: 0.8775 - auc: 0.9530\n",
      "Epoch 15: val_accuracy improved from 0.87073 to 0.87488, saving model to \\saved_models2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0869 - accuracy: 0.8777 - auc: 0.9532 - val_loss: 0.0861 - val_accuracy: 0.8749 - val_auc: 0.9543\n",
      "68/68 [==============================] - 0s 975us/step - loss: 0.0861 - accuracy: 0.8749 - auc: 0.9543\n",
      "Epoch 1/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.2516 - accuracy: 0.4879 - auc: 0.4729\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51431, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2514 - accuracy: 0.4906 - auc: 0.4756 - val_loss: 0.2502 - val_accuracy: 0.5143 - val_auc: 0.5151\n",
      "Epoch 2/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.5586 - auc: 0.5786\n",
      "Epoch 2: val_accuracy improved from 0.51431 to 0.54571, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.5584 - auc: 0.5785 - val_loss: 0.2453 - val_accuracy: 0.5457 - val_auc: 0.6184\n",
      "Epoch 3/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.6076 - auc: 0.6712\n",
      "Epoch 3: val_accuracy improved from 0.54571 to 0.63620, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2371 - accuracy: 0.6087 - auc: 0.6729 - val_loss: 0.2327 - val_accuracy: 0.6362 - val_auc: 0.6946\n",
      "Epoch 4/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2178 - accuracy: 0.6715 - auc: 0.7358\n",
      "Epoch 4: val_accuracy improved from 0.63620 to 0.69067, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2171 - accuracy: 0.6716 - auc: 0.7362 - val_loss: 0.2079 - val_accuracy: 0.6907 - val_auc: 0.7543\n",
      "Epoch 5/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1896 - accuracy: 0.7207 - auc: 0.7931\n",
      "Epoch 5: val_accuracy improved from 0.69067 to 0.74192, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1896 - accuracy: 0.7204 - auc: 0.7930 - val_loss: 0.1796 - val_accuracy: 0.7419 - val_auc: 0.8131\n",
      "Epoch 6/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.7627 - auc: 0.8423\n",
      "Epoch 6: val_accuracy improved from 0.74192 to 0.78624, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1642 - accuracy: 0.7622 - auc: 0.8418 - val_loss: 0.1549 - val_accuracy: 0.7862 - val_auc: 0.8608\n",
      "Epoch 7/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1453 - accuracy: 0.7893 - auc: 0.8746\n",
      "Epoch 7: val_accuracy improved from 0.78624 to 0.79917, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.7899 - auc: 0.8748 - val_loss: 0.1369 - val_accuracy: 0.7992 - val_auc: 0.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1321 - accuracy: 0.8075 - auc: 0.8953\n",
      "Epoch 8: val_accuracy improved from 0.79917 to 0.81440, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1320 - accuracy: 0.8077 - auc: 0.8955 - val_loss: 0.1250 - val_accuracy: 0.8144 - val_auc: 0.9074\n",
      "Epoch 9/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1234 - accuracy: 0.8182 - auc: 0.9083\n",
      "Epoch 9: val_accuracy improved from 0.81440 to 0.82825, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1228 - accuracy: 0.8194 - auc: 0.9092 - val_loss: 0.1167 - val_accuracy: 0.8283 - val_auc: 0.9188\n",
      "Epoch 10/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.8304 - auc: 0.9187\n",
      "Epoch 10: val_accuracy improved from 0.82825 to 0.83657, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.8303 - auc: 0.9187 - val_loss: 0.1113 - val_accuracy: 0.8366 - val_auc: 0.9261\n",
      "Epoch 11/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.8406 - auc: 0.9256\n",
      "Epoch 11: val_accuracy improved from 0.83657 to 0.84534, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.8408 - auc: 0.9259 - val_loss: 0.1069 - val_accuracy: 0.8453 - val_auc: 0.9318\n",
      "Epoch 12/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1064 - accuracy: 0.8458 - auc: 0.9311\n",
      "Epoch 12: val_accuracy improved from 0.84534 to 0.85457, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.8468 - auc: 0.9314 - val_loss: 0.1030 - val_accuracy: 0.8546 - val_auc: 0.9367\n",
      "Epoch 13/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1021 - accuracy: 0.8533 - auc: 0.9361\n",
      "Epoch 13: val_accuracy improved from 0.85457 to 0.85780, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.8531 - auc: 0.9361 - val_loss: 0.0986 - val_accuracy: 0.8578 - val_auc: 0.9409\n",
      "Epoch 14/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.8614 - auc: 0.9409\n",
      "Epoch 14: val_accuracy improved from 0.85780 to 0.86288, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.8612 - auc: 0.9407 - val_loss: 0.0953 - val_accuracy: 0.8629 - val_auc: 0.9444\n",
      "Epoch 15/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.0952 - accuracy: 0.8666 - auc: 0.9440\n",
      "Epoch 15: val_accuracy improved from 0.86288 to 0.87073, saving model to \\saved_models2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0947 - accuracy: 0.8673 - auc: 0.9446 - val_loss: 0.0922 - val_accuracy: 0.8707 - val_auc: 0.9476\n",
      "68/68 [==============================] - 0s 957us/step - loss: 0.0922 - accuracy: 0.8707 - auc: 0.9476\n",
      "Epoch 1/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.5596 - auc: 0.5754\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61588, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.5615 - auc: 0.5787 - val_loss: 0.2368 - val_accuracy: 0.6159 - val_auc: 0.6538\n",
      "Epoch 2/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2252 - accuracy: 0.6591 - auc: 0.7154\n",
      "Epoch 2: val_accuracy improved from 0.61588 to 0.68513, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2249 - accuracy: 0.6602 - auc: 0.7159 - val_loss: 0.2151 - val_accuracy: 0.6851 - val_auc: 0.7378\n",
      "Epoch 3/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.7180 - auc: 0.7889\n",
      "Epoch 3: val_accuracy improved from 0.68513 to 0.73361, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1954 - accuracy: 0.7187 - auc: 0.7891 - val_loss: 0.1863 - val_accuracy: 0.7336 - val_auc: 0.7994\n",
      "Epoch 4/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.7638 - auc: 0.8469\n",
      "Epoch 4: val_accuracy improved from 0.73361 to 0.76270, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1637 - accuracy: 0.7642 - auc: 0.8474 - val_loss: 0.1616 - val_accuracy: 0.7627 - val_auc: 0.8445\n",
      "Epoch 5/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.7950 - auc: 0.8832\n",
      "Epoch 5: val_accuracy improved from 0.76270 to 0.78855, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1409 - accuracy: 0.7950 - auc: 0.8832 - val_loss: 0.1457 - val_accuracy: 0.7886 - val_auc: 0.8720\n",
      "Epoch 6/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1281 - accuracy: 0.8153 - auc: 0.9015\n",
      "Epoch 6: val_accuracy improved from 0.78855 to 0.79686, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1278 - accuracy: 0.8164 - auc: 0.9019 - val_loss: 0.1361 - val_accuracy: 0.7969 - val_auc: 0.8888\n",
      "Epoch 7/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1203 - accuracy: 0.8250 - auc: 0.9123\n",
      "Epoch 7: val_accuracy improved from 0.79686 to 0.80794, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1202 - accuracy: 0.8254 - auc: 0.9125 - val_loss: 0.1305 - val_accuracy: 0.8079 - val_auc: 0.8976\n",
      "Epoch 8/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.8332 - auc: 0.9193\n",
      "Epoch 8: val_accuracy improved from 0.80794 to 0.81440, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.8330 - auc: 0.9192 - val_loss: 0.1262 - val_accuracy: 0.8144 - val_auc: 0.9042\n",
      "Epoch 9/15\n",
      "561/610 [==========================>...] - ETA: 0s - loss: 0.1114 - accuracy: 0.8393 - auc: 0.9242\n",
      "Epoch 9: val_accuracy improved from 0.81440 to 0.81948, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.8385 - auc: 0.9238 - val_loss: 0.1231 - val_accuracy: 0.8195 - val_auc: 0.9093\n",
      "Epoch 10/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.8430 - auc: 0.9274\n",
      "Epoch 10: val_accuracy improved from 0.81948 to 0.82179, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8429 - auc: 0.9274 - val_loss: 0.1206 - val_accuracy: 0.8218 - val_auc: 0.9122\n",
      "Epoch 11/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.8471 - auc: 0.9306\n",
      "Epoch 11: val_accuracy did not improve from 0.82179\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1069 - accuracy: 0.8461 - auc: 0.9301 - val_loss: 0.1189 - val_accuracy: 0.8209 - val_auc: 0.9149\n",
      "Epoch 12/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.8516 - auc: 0.9325\n",
      "Epoch 12: val_accuracy did not improve from 0.82179\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.8517 - auc: 0.9326 - val_loss: 0.1182 - val_accuracy: 0.8209 - val_auc: 0.9164\n",
      "Epoch 13/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1029 - accuracy: 0.8532 - auc: 0.9349\n",
      "Epoch 13: val_accuracy improved from 0.82179 to 0.82733, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.8529 - auc: 0.9345 - val_loss: 0.1160 - val_accuracy: 0.8273 - val_auc: 0.9186\n",
      "Epoch 14/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1016 - accuracy: 0.8553 - auc: 0.9366\n",
      "Epoch 14: val_accuracy improved from 0.82733 to 0.83102, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.8551 - auc: 0.9364 - val_loss: 0.1158 - val_accuracy: 0.8310 - val_auc: 0.9202\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/610 [============================>.] - ETA: 0s - loss: 0.1003 - accuracy: 0.8570 - auc: 0.9379\n",
      "Epoch 15: val_accuracy improved from 0.83102 to 0.83380, saving model to \\saved_models2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.8570 - auc: 0.9381 - val_loss: 0.1132 - val_accuracy: 0.8338 - val_auc: 0.9232\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8338 - auc: 0.9232\n",
      "Epoch 1/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.2426 - accuracy: 0.5760 - auc: 0.6044\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59972, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2424 - accuracy: 0.5773 - auc: 0.6071 - val_loss: 0.2383 - val_accuracy: 0.5997 - val_auc: 0.6564\n",
      "Epoch 2/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.6359 - auc: 0.6975\n",
      "Epoch 2: val_accuracy improved from 0.59972 to 0.66343, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2286 - accuracy: 0.6366 - auc: 0.6987 - val_loss: 0.2190 - val_accuracy: 0.6634 - val_auc: 0.7363\n",
      "Epoch 3/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2040 - accuracy: 0.6967 - auc: 0.7662\n",
      "Epoch 3: val_accuracy improved from 0.66343 to 0.72207, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2036 - accuracy: 0.6966 - auc: 0.7664 - val_loss: 0.1905 - val_accuracy: 0.7221 - val_auc: 0.7971\n",
      "Epoch 4/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.7407 - auc: 0.8204\n",
      "Epoch 4: val_accuracy improved from 0.72207 to 0.76085, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.7411 - auc: 0.8209 - val_loss: 0.1677 - val_accuracy: 0.7608 - val_auc: 0.8427\n",
      "Epoch 5/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1533 - accuracy: 0.7779 - auc: 0.8627\n",
      "Epoch 5: val_accuracy improved from 0.76085 to 0.78994, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1533 - accuracy: 0.7780 - auc: 0.8624 - val_loss: 0.1482 - val_accuracy: 0.7899 - val_auc: 0.8710\n",
      "Epoch 6/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1373 - accuracy: 0.8010 - auc: 0.8877\n",
      "Epoch 6: val_accuracy improved from 0.78994 to 0.80009, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1371 - accuracy: 0.8013 - auc: 0.8880 - val_loss: 0.1378 - val_accuracy: 0.8001 - val_auc: 0.8867\n",
      "Epoch 7/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1275 - accuracy: 0.8152 - auc: 0.9022\n",
      "Epoch 7: val_accuracy improved from 0.80009 to 0.81533, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1270 - accuracy: 0.8161 - auc: 0.9029 - val_loss: 0.1312 - val_accuracy: 0.8153 - val_auc: 0.8963\n",
      "Epoch 8/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1204 - accuracy: 0.8249 - auc: 0.9122\n",
      "Epoch 8: val_accuracy improved from 0.81533 to 0.82641, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.8251 - auc: 0.9124 - val_loss: 0.1273 - val_accuracy: 0.8264 - val_auc: 0.9027\n",
      "Epoch 9/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1147 - accuracy: 0.8329 - auc: 0.9200\n",
      "Epoch 9: val_accuracy improved from 0.82641 to 0.82733, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.8325 - auc: 0.9193 - val_loss: 0.1251 - val_accuracy: 0.8273 - val_auc: 0.9063\n",
      "Epoch 10/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.8382 - auc: 0.9244\n",
      "Epoch 10: val_accuracy did not improve from 0.82733\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1112 - accuracy: 0.8383 - auc: 0.9245 - val_loss: 0.1213 - val_accuracy: 0.8269 - val_auc: 0.9113\n",
      "Epoch 11/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1079 - accuracy: 0.8433 - auc: 0.9287\n",
      "Epoch 11: val_accuracy did not improve from 0.82733\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.8427 - auc: 0.9287 - val_loss: 0.1203 - val_accuracy: 0.8227 - val_auc: 0.9133\n",
      "Epoch 12/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1051 - accuracy: 0.8489 - auc: 0.9322\n",
      "Epoch 12: val_accuracy did not improve from 0.82733\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.8493 - auc: 0.9325 - val_loss: 0.1181 - val_accuracy: 0.8264 - val_auc: 0.9163\n",
      "Epoch 13/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.8534 - auc: 0.9360\n",
      "Epoch 13: val_accuracy improved from 0.82733 to 0.83195, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1022 - accuracy: 0.8528 - auc: 0.9359 - val_loss: 0.1159 - val_accuracy: 0.8319 - val_auc: 0.9196\n",
      "Epoch 14/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.8582 - auc: 0.9392\n",
      "Epoch 14: val_accuracy did not improve from 0.83195\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.8577 - auc: 0.9389 - val_loss: 0.1142 - val_accuracy: 0.8296 - val_auc: 0.9220\n",
      "Epoch 15/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.8616 - auc: 0.9420\n",
      "Epoch 15: val_accuracy improved from 0.83195 to 0.83472, saving model to \\saved_models2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.8616 - auc: 0.9420 - val_loss: 0.1126 - val_accuracy: 0.8347 - val_auc: 0.9250\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.8347 - auc: 0.9250\n",
      "Epoch 1/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.2457 - accuracy: 0.5527 - auc: 0.5939\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58957, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.5537 - auc: 0.5962 - val_loss: 0.2412 - val_accuracy: 0.5896 - val_auc: 0.6693\n",
      "Epoch 2/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.2339 - accuracy: 0.6414 - auc: 0.7116\n",
      "Epoch 2: val_accuracy improved from 0.58957 to 0.69391, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2333 - accuracy: 0.6438 - auc: 0.7144 - val_loss: 0.2201 - val_accuracy: 0.6939 - val_auc: 0.7638\n",
      "Epoch 3/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2016 - accuracy: 0.7165 - auc: 0.7869\n",
      "Epoch 3: val_accuracy improved from 0.69391 to 0.74977, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2015 - accuracy: 0.7159 - auc: 0.7868 - val_loss: 0.1786 - val_accuracy: 0.7498 - val_auc: 0.8250\n",
      "Epoch 4/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1661 - accuracy: 0.7595 - auc: 0.8410\n",
      "Epoch 4: val_accuracy improved from 0.74977 to 0.78116, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1657 - accuracy: 0.7604 - auc: 0.8415 - val_loss: 0.1521 - val_accuracy: 0.7812 - val_auc: 0.8628\n",
      "Epoch 5/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1452 - accuracy: 0.7870 - auc: 0.8739\n",
      "Epoch 5: val_accuracy improved from 0.78116 to 0.80009, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1449 - accuracy: 0.7877 - auc: 0.8745 - val_loss: 0.1377 - val_accuracy: 0.8001 - val_auc: 0.8853\n",
      "Epoch 6/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1328 - accuracy: 0.8046 - auc: 0.8932\n",
      "Epoch 6: val_accuracy improved from 0.80009 to 0.81440, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1326 - accuracy: 0.8053 - auc: 0.8938 - val_loss: 0.1289 - val_accuracy: 0.8144 - val_auc: 0.8985\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1244 - accuracy: 0.8207 - auc: 0.9057\n",
      "Epoch 7: val_accuracy improved from 0.81440 to 0.82456, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1244 - accuracy: 0.8206 - auc: 0.9056 - val_loss: 0.1231 - val_accuracy: 0.8246 - val_auc: 0.9074\n",
      "Epoch 8/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.8285 - auc: 0.9135\n",
      "Epoch 8: val_accuracy improved from 0.82456 to 0.83287, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.8282 - auc: 0.9135 - val_loss: 0.1182 - val_accuracy: 0.8329 - val_auc: 0.9136\n",
      "Epoch 9/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.8317 - auc: 0.9188\n",
      "Epoch 9: val_accuracy improved from 0.83287 to 0.83980, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.8328 - auc: 0.9191 - val_loss: 0.1158 - val_accuracy: 0.8398 - val_auc: 0.9173\n",
      "Epoch 10/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.8368 - auc: 0.9227\n",
      "Epoch 10: val_accuracy improved from 0.83980 to 0.84164, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.8373 - auc: 0.9232 - val_loss: 0.1126 - val_accuracy: 0.8416 - val_auc: 0.9210\n",
      "Epoch 11/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1102 - accuracy: 0.8406 - auc: 0.9256\n",
      "Epoch 11: val_accuracy improved from 0.84164 to 0.84441, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.8419 - auc: 0.9265 - val_loss: 0.1107 - val_accuracy: 0.8444 - val_auc: 0.9237\n",
      "Epoch 12/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1072 - accuracy: 0.8471 - auc: 0.9293\n",
      "Epoch 12: val_accuracy improved from 0.84441 to 0.84995, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.8463 - auc: 0.9291 - val_loss: 0.1093 - val_accuracy: 0.8500 - val_auc: 0.9257\n",
      "Epoch 13/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1058 - accuracy: 0.8471 - auc: 0.9312\n",
      "Epoch 13: val_accuracy improved from 0.84995 to 0.85180, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1056 - accuracy: 0.8475 - auc: 0.9314 - val_loss: 0.1070 - val_accuracy: 0.8518 - val_auc: 0.9286\n",
      "Epoch 14/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1038 - accuracy: 0.8505 - auc: 0.9338\n",
      "Epoch 14: val_accuracy improved from 0.85180 to 0.85549, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.8512 - auc: 0.9339 - val_loss: 0.1059 - val_accuracy: 0.8555 - val_auc: 0.9300\n",
      "Epoch 15/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.8538 - auc: 0.9361\n",
      "Epoch 15: val_accuracy improved from 0.85549 to 0.85734, saving model to \\saved_models2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.8540 - auc: 0.9363 - val_loss: 0.1043 - val_accuracy: 0.8573 - val_auc: 0.9324\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.8573 - auc: 0.9324\n",
      "Epoch 1/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.2431 - accuracy: 0.5444 - auc: 0.6238\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55633, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.5442 - auc: 0.6267 - val_loss: 0.2366 - val_accuracy: 0.5563 - val_auc: 0.7023\n",
      "Epoch 2/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.6056 - auc: 0.7286\n",
      "Epoch 2: val_accuracy improved from 0.55633 to 0.66805, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2279 - accuracy: 0.6074 - auc: 0.7292 - val_loss: 0.2187 - val_accuracy: 0.6681 - val_auc: 0.7657\n",
      "Epoch 3/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.2097 - accuracy: 0.6946 - auc: 0.7795\n",
      "Epoch 3: val_accuracy improved from 0.66805 to 0.72068, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2088 - accuracy: 0.6964 - auc: 0.7813 - val_loss: 0.1985 - val_accuracy: 0.7207 - val_auc: 0.8079\n",
      "Epoch 4/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1894 - accuracy: 0.7416 - auc: 0.8209\n",
      "Epoch 4: val_accuracy improved from 0.72068 to 0.77054, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1893 - accuracy: 0.7420 - auc: 0.8210 - val_loss: 0.1793 - val_accuracy: 0.7705 - val_auc: 0.8422\n",
      "Epoch 5/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.7711 - auc: 0.8532\n",
      "Epoch 5: val_accuracy improved from 0.77054 to 0.78809, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1713 - accuracy: 0.7711 - auc: 0.8532 - val_loss: 0.1629 - val_accuracy: 0.7881 - val_auc: 0.8680\n",
      "Epoch 6/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1571 - accuracy: 0.7896 - auc: 0.8744\n",
      "Epoch 6: val_accuracy improved from 0.78809 to 0.80055, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1563 - accuracy: 0.7915 - auc: 0.8762 - val_loss: 0.1498 - val_accuracy: 0.8006 - val_auc: 0.8850\n",
      "Epoch 7/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.8083 - auc: 0.8915\n",
      "Epoch 7: val_accuracy improved from 0.80055 to 0.81348, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1446 - accuracy: 0.8087 - auc: 0.8919 - val_loss: 0.1400 - val_accuracy: 0.8135 - val_auc: 0.8973\n",
      "Epoch 8/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.8189 - auc: 0.9024\n",
      "Epoch 8: val_accuracy improved from 0.81348 to 0.81948, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1356 - accuracy: 0.8190 - auc: 0.9027 - val_loss: 0.1326 - val_accuracy: 0.8195 - val_auc: 0.9061\n",
      "Epoch 9/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.8276 - auc: 0.9111\n",
      "Epoch 9: val_accuracy improved from 0.81948 to 0.82825, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.8276 - auc: 0.9111 - val_loss: 0.1270 - val_accuracy: 0.8283 - val_auc: 0.9114\n",
      "Epoch 10/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1233 - accuracy: 0.8339 - auc: 0.9168\n",
      "Epoch 10: val_accuracy improved from 0.82825 to 0.83102, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.8345 - auc: 0.9171 - val_loss: 0.1225 - val_accuracy: 0.8310 - val_auc: 0.9154\n",
      "Epoch 11/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1189 - accuracy: 0.8375 - auc: 0.9213\n",
      "Epoch 11: val_accuracy improved from 0.83102 to 0.83518, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1186 - accuracy: 0.8382 - auc: 0.9217 - val_loss: 0.1196 - val_accuracy: 0.8352 - val_auc: 0.9193\n",
      "Epoch 12/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.8427 - auc: 0.9252\n",
      "Epoch 12: val_accuracy improved from 0.83518 to 0.83795, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.8426 - auc: 0.9252 - val_loss: 0.1169 - val_accuracy: 0.8380 - val_auc: 0.9209\n",
      "Epoch 13/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1121 - accuracy: 0.8468 - auc: 0.9281\n",
      "Epoch 13: val_accuracy improved from 0.83795 to 0.84257, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.8460 - auc: 0.9276 - val_loss: 0.1148 - val_accuracy: 0.8426 - val_auc: 0.9240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1098 - accuracy: 0.8500 - auc: 0.9304\n",
      "Epoch 14: val_accuracy did not improve from 0.84257\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.8495 - auc: 0.9301 - val_loss: 0.1126 - val_accuracy: 0.8421 - val_auc: 0.9256\n",
      "Epoch 15/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.8518 - auc: 0.9318\n",
      "Epoch 15: val_accuracy improved from 0.84257 to 0.84949, saving model to \\saved_models2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1078 - accuracy: 0.8522 - auc: 0.9322 - val_loss: 0.1108 - val_accuracy: 0.8495 - val_auc: 0.9278\n",
      "68/68 [==============================] - 0s 928us/step - loss: 0.1108 - accuracy: 0.8495 - auc: 0.9278\n",
      "Epoch 1/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.5512 - auc: 0.5911\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57987, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2458 - accuracy: 0.5514 - auc: 0.5918 - val_loss: 0.2402 - val_accuracy: 0.5799 - val_auc: 0.6751\n",
      "Epoch 2/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.2364 - accuracy: 0.6038 - auc: 0.6883\n",
      "Epoch 2: val_accuracy improved from 0.57987 to 0.67267, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2359 - accuracy: 0.6057 - auc: 0.6908 - val_loss: 0.2264 - val_accuracy: 0.6727 - val_auc: 0.7361\n",
      "Epoch 3/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.2192 - accuracy: 0.6802 - auc: 0.7446\n",
      "Epoch 3: val_accuracy improved from 0.67267 to 0.71745, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2186 - accuracy: 0.6819 - auc: 0.7464 - val_loss: 0.2058 - val_accuracy: 0.7175 - val_auc: 0.7778\n",
      "Epoch 4/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1961 - accuracy: 0.7199 - auc: 0.7911\n",
      "Epoch 4: val_accuracy improved from 0.71745 to 0.75069, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1957 - accuracy: 0.7205 - auc: 0.7917 - val_loss: 0.1809 - val_accuracy: 0.7507 - val_auc: 0.8190\n",
      "Epoch 5/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1717 - accuracy: 0.7522 - auc: 0.8328\n",
      "Epoch 5: val_accuracy improved from 0.75069 to 0.78070, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1709 - accuracy: 0.7540 - auc: 0.8340 - val_loss: 0.1574 - val_accuracy: 0.7807 - val_auc: 0.8572\n",
      "Epoch 6/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1512 - accuracy: 0.7803 - auc: 0.8658\n",
      "Epoch 6: val_accuracy improved from 0.78070 to 0.80332, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1507 - accuracy: 0.7807 - auc: 0.8667 - val_loss: 0.1416 - val_accuracy: 0.8033 - val_auc: 0.8808\n",
      "Epoch 7/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1374 - accuracy: 0.8017 - auc: 0.8870\n",
      "Epoch 7: val_accuracy improved from 0.80332 to 0.81348, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.8019 - auc: 0.8874 - val_loss: 0.1308 - val_accuracy: 0.8135 - val_auc: 0.8967\n",
      "Epoch 8/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1283 - accuracy: 0.8133 - auc: 0.9007\n",
      "Epoch 8: val_accuracy improved from 0.81348 to 0.81671, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1281 - accuracy: 0.8138 - auc: 0.9010 - val_loss: 0.1236 - val_accuracy: 0.8167 - val_auc: 0.9068\n",
      "Epoch 9/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1221 - accuracy: 0.8236 - auc: 0.9097\n",
      "Epoch 9: val_accuracy improved from 0.81671 to 0.82502, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1216 - accuracy: 0.8244 - auc: 0.9104 - val_loss: 0.1187 - val_accuracy: 0.8250 - val_auc: 0.9134\n",
      "Epoch 10/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.8358 - auc: 0.9182\n",
      "Epoch 10: val_accuracy improved from 0.82502 to 0.82964, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.8343 - auc: 0.9174 - val_loss: 0.1157 - val_accuracy: 0.8296 - val_auc: 0.9178\n",
      "Epoch 11/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.8398 - auc: 0.9229\n",
      "Epoch 11: val_accuracy improved from 0.82964 to 0.83426, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1126 - accuracy: 0.8397 - auc: 0.9228 - val_loss: 0.1127 - val_accuracy: 0.8343 - val_auc: 0.9216\n",
      "Epoch 12/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1100 - accuracy: 0.8444 - auc: 0.9261\n",
      "Epoch 12: val_accuracy improved from 0.83426 to 0.83841, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.8449 - auc: 0.9269 - val_loss: 0.1110 - val_accuracy: 0.8384 - val_auc: 0.9241\n",
      "Epoch 13/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.8491 - auc: 0.9304\n",
      "Epoch 13: val_accuracy improved from 0.83841 to 0.84672, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.8490 - auc: 0.9304 - val_loss: 0.1086 - val_accuracy: 0.8467 - val_auc: 0.9272\n",
      "Epoch 14/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.8519 - auc: 0.9333\n",
      "Epoch 14: val_accuracy improved from 0.84672 to 0.84765, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.8521 - auc: 0.9334 - val_loss: 0.1068 - val_accuracy: 0.8476 - val_auc: 0.9295\n",
      "Epoch 15/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1015 - accuracy: 0.8564 - auc: 0.9366\n",
      "Epoch 15: val_accuracy improved from 0.84765 to 0.85134, saving model to \\saved_models2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.8560 - auc: 0.9365 - val_loss: 0.1041 - val_accuracy: 0.8513 - val_auc: 0.9325\n",
      "68/68 [==============================] - 0s 967us/step - loss: 0.1041 - accuracy: 0.8513 - auc: 0.9325\n",
      "Epoch 1/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.2531 - accuracy: 0.4730 - auc: 0.4618\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51016, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.4749 - auc: 0.4642 - val_loss: 0.2496 - val_accuracy: 0.5102 - val_auc: 0.5056\n",
      "Epoch 2/15\n",
      "562/610 [==========================>...] - ETA: 0s - loss: 0.2481 - accuracy: 0.5307 - auc: 0.5504\n",
      "Epoch 2: val_accuracy improved from 0.51016 to 0.52493, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2479 - accuracy: 0.5322 - auc: 0.5527 - val_loss: 0.2476 - val_accuracy: 0.5249 - val_auc: 0.5848\n",
      "Epoch 3/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.2461 - accuracy: 0.5430 - auc: 0.6125\n",
      "Epoch 3: val_accuracy improved from 0.52493 to 0.53509, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.5440 - auc: 0.6151 - val_loss: 0.2456 - val_accuracy: 0.5351 - val_auc: 0.6345\n",
      "Epoch 4/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.5689 - auc: 0.6539\n",
      "Epoch 4: val_accuracy improved from 0.53509 to 0.59834, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.5681 - auc: 0.6536 - val_loss: 0.2421 - val_accuracy: 0.5983 - val_auc: 0.6725\n",
      "Epoch 5/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.2391 - accuracy: 0.6221 - auc: 0.6824\n",
      "Epoch 5: val_accuracy improved from 0.59834 to 0.64728, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2389 - accuracy: 0.6238 - auc: 0.6836 - val_loss: 0.2360 - val_accuracy: 0.6473 - val_auc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2316 - accuracy: 0.6558 - auc: 0.7089\n",
      "Epoch 6: val_accuracy improved from 0.64728 to 0.66944, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2316 - accuracy: 0.6559 - auc: 0.7089 - val_loss: 0.2269 - val_accuracy: 0.6694 - val_auc: 0.7273\n",
      "Epoch 7/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.2198 - accuracy: 0.6818 - auc: 0.7408\n",
      "Epoch 7: val_accuracy improved from 0.66944 to 0.70683, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2196 - accuracy: 0.6818 - auc: 0.7408 - val_loss: 0.2111 - val_accuracy: 0.7068 - val_auc: 0.7624\n",
      "Epoch 8/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.2015 - accuracy: 0.7151 - auc: 0.7826\n",
      "Epoch 8: val_accuracy improved from 0.70683 to 0.73315, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2007 - accuracy: 0.7164 - auc: 0.7842 - val_loss: 0.1878 - val_accuracy: 0.7331 - val_auc: 0.8116\n",
      "Epoch 9/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1753 - accuracy: 0.7578 - auc: 0.8350\n",
      "Epoch 9: val_accuracy improved from 0.73315 to 0.77285, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1743 - accuracy: 0.7592 - auc: 0.8368 - val_loss: 0.1594 - val_accuracy: 0.7729 - val_auc: 0.8614\n",
      "Epoch 10/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1497 - accuracy: 0.7896 - auc: 0.8743\n",
      "Epoch 10: val_accuracy improved from 0.77285 to 0.80240, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1490 - accuracy: 0.7908 - auc: 0.8754 - val_loss: 0.1385 - val_accuracy: 0.8024 - val_auc: 0.8908\n",
      "Epoch 11/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1330 - accuracy: 0.8079 - auc: 0.8962\n",
      "Epoch 11: val_accuracy improved from 0.80240 to 0.82041, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1329 - accuracy: 0.8082 - auc: 0.8963 - val_loss: 0.1254 - val_accuracy: 0.8204 - val_auc: 0.9072\n",
      "Epoch 12/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.8220 - auc: 0.9085\n",
      "Epoch 12: val_accuracy improved from 0.82041 to 0.82687, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1234 - accuracy: 0.8220 - auc: 0.9085 - val_loss: 0.1189 - val_accuracy: 0.8269 - val_auc: 0.9166\n",
      "Epoch 13/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1177 - accuracy: 0.8279 - auc: 0.9161\n",
      "Epoch 13: val_accuracy improved from 0.82687 to 0.83610, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.8290 - auc: 0.9167 - val_loss: 0.1116 - val_accuracy: 0.8361 - val_auc: 0.9252\n",
      "Epoch 14/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.8373 - auc: 0.9224\n",
      "Epoch 14: val_accuracy improved from 0.83610 to 0.84164, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.8372 - auc: 0.9225 - val_loss: 0.1071 - val_accuracy: 0.8416 - val_auc: 0.9313\n",
      "Epoch 15/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1095 - accuracy: 0.8416 - auc: 0.9268\n",
      "Epoch 15: val_accuracy improved from 0.84164 to 0.84395, saving model to \\saved_models2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1096 - accuracy: 0.8416 - auc: 0.9267 - val_loss: 0.1057 - val_accuracy: 0.8440 - val_auc: 0.9345\n",
      "68/68 [==============================] - 0s 962us/step - loss: 0.1057 - accuracy: 0.8440 - auc: 0.9345\n",
      "Epoch 1/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.2458 - accuracy: 0.5559 - auc: 0.5659\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61940, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.5602 - auc: 0.5723 - val_loss: 0.2355 - val_accuracy: 0.6194 - val_auc: 0.6624\n",
      "Epoch 2/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.2266 - accuracy: 0.6530 - auc: 0.7015\n",
      "Epoch 2: val_accuracy improved from 0.61940 to 0.69376, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2258 - accuracy: 0.6547 - auc: 0.7040 - val_loss: 0.2112 - val_accuracy: 0.6938 - val_auc: 0.7485\n",
      "Epoch 3/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1983 - accuracy: 0.7092 - auc: 0.7750\n",
      "Epoch 3: val_accuracy improved from 0.69376 to 0.74457, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1982 - accuracy: 0.7094 - auc: 0.7754 - val_loss: 0.1789 - val_accuracy: 0.7446 - val_auc: 0.8153\n",
      "Epoch 4/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.7572 - auc: 0.8385\n",
      "Epoch 4: val_accuracy improved from 0.74457 to 0.78568, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1667 - accuracy: 0.7583 - auc: 0.8395 - val_loss: 0.1484 - val_accuracy: 0.7857 - val_auc: 0.8708\n",
      "Epoch 5/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1419 - accuracy: 0.7956 - auc: 0.8810\n",
      "Epoch 5: val_accuracy improved from 0.78568 to 0.81293, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1417 - accuracy: 0.7961 - auc: 0.8813 - val_loss: 0.1299 - val_accuracy: 0.8129 - val_auc: 0.8990\n",
      "Epoch 6/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1278 - accuracy: 0.8168 - auc: 0.9015\n",
      "Epoch 6: val_accuracy improved from 0.81293 to 0.82679, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1279 - accuracy: 0.8163 - auc: 0.9014 - val_loss: 0.1207 - val_accuracy: 0.8268 - val_auc: 0.9110\n",
      "Epoch 7/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1200 - accuracy: 0.8257 - auc: 0.9123\n",
      "Epoch 7: val_accuracy improved from 0.82679 to 0.84065, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.8262 - auc: 0.9127 - val_loss: 0.1147 - val_accuracy: 0.8406 - val_auc: 0.9185\n",
      "Epoch 8/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1150 - accuracy: 0.8336 - auc: 0.9190\n",
      "Epoch 8: val_accuracy did not improve from 0.84065\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.8357 - auc: 0.9205 - val_loss: 0.1112 - val_accuracy: 0.8379 - val_auc: 0.9243\n",
      "Epoch 9/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.8429 - auc: 0.9266\n",
      "Epoch 9: val_accuracy improved from 0.84065 to 0.84758, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.8427 - auc: 0.9265 - val_loss: 0.1071 - val_accuracy: 0.8476 - val_auc: 0.9291\n",
      "Epoch 10/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1052 - accuracy: 0.8494 - auc: 0.9319\n",
      "Epoch 10: val_accuracy improved from 0.84758 to 0.85543, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.8495 - auc: 0.9318 - val_loss: 0.1032 - val_accuracy: 0.8554 - val_auc: 0.9339\n",
      "Epoch 11/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1014 - accuracy: 0.8549 - auc: 0.9366\n",
      "Epoch 11: val_accuracy improved from 0.85543 to 0.85912, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.8547 - auc: 0.9365 - val_loss: 0.1004 - val_accuracy: 0.8591 - val_auc: 0.9377\n",
      "Epoch 12/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.0980 - accuracy: 0.8596 - auc: 0.9406\n",
      "Epoch 12: val_accuracy improved from 0.85912 to 0.86697, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.8605 - auc: 0.9411 - val_loss: 0.0967 - val_accuracy: 0.8670 - val_auc: 0.9417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.0938 - accuracy: 0.8663 - auc: 0.9452\n",
      "Epoch 13: val_accuracy did not improve from 0.86697\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.8662 - auc: 0.9451 - val_loss: 0.0940 - val_accuracy: 0.8670 - val_auc: 0.9454\n",
      "Epoch 14/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.0905 - accuracy: 0.8721 - auc: 0.9489\n",
      "Epoch 14: val_accuracy improved from 0.86697 to 0.86975, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.8727 - auc: 0.9491 - val_loss: 0.0908 - val_accuracy: 0.8697 - val_auc: 0.9484\n",
      "Epoch 15/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.0867 - accuracy: 0.8794 - auc: 0.9531\n",
      "Epoch 15: val_accuracy improved from 0.86975 to 0.87945, saving model to \\saved_models2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.8788 - auc: 0.9525 - val_loss: 0.0876 - val_accuracy: 0.8794 - val_auc: 0.9516\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.8794 - auc: 0.9516\n",
      "Epoch 1/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.2471 - accuracy: 0.5406 - auc: 0.5537\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58614, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.5413 - auc: 0.5571 - val_loss: 0.2414 - val_accuracy: 0.5861 - val_auc: 0.6328\n",
      "Epoch 2/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.2344 - accuracy: 0.6119 - auc: 0.7005\n",
      "Epoch 2: val_accuracy improved from 0.58614 to 0.66513, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2342 - accuracy: 0.6133 - auc: 0.7017 - val_loss: 0.2244 - val_accuracy: 0.6651 - val_auc: 0.7332\n",
      "Epoch 3/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.2103 - accuracy: 0.6939 - auc: 0.7718\n",
      "Epoch 3: val_accuracy improved from 0.66513 to 0.72333, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.6951 - auc: 0.7717 - val_loss: 0.1937 - val_accuracy: 0.7233 - val_auc: 0.7986\n",
      "Epoch 4/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.7491 - auc: 0.8293\n",
      "Epoch 4: val_accuracy improved from 0.72333 to 0.76166, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1766 - accuracy: 0.7493 - auc: 0.8300 - val_loss: 0.1617 - val_accuracy: 0.7617 - val_auc: 0.8533\n",
      "Epoch 5/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1499 - accuracy: 0.7866 - auc: 0.8708\n",
      "Epoch 5: val_accuracy improved from 0.76166 to 0.79400, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1498 - accuracy: 0.7865 - auc: 0.8707 - val_loss: 0.1411 - val_accuracy: 0.7940 - val_auc: 0.8836\n",
      "Epoch 6/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.8081 - auc: 0.8942\n",
      "Epoch 6: val_accuracy improved from 0.79400 to 0.81755, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1336 - accuracy: 0.8081 - auc: 0.8942 - val_loss: 0.1293 - val_accuracy: 0.8176 - val_auc: 0.8999\n",
      "Epoch 7/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1239 - accuracy: 0.8216 - auc: 0.9076\n",
      "Epoch 7: val_accuracy improved from 0.81755 to 0.82910, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1239 - accuracy: 0.8213 - auc: 0.9075 - val_loss: 0.1217 - val_accuracy: 0.8291 - val_auc: 0.9104\n",
      "Epoch 8/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1176 - accuracy: 0.8301 - auc: 0.9162\n",
      "Epoch 8: val_accuracy improved from 0.82910 to 0.83048, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.8300 - auc: 0.9161 - val_loss: 0.1174 - val_accuracy: 0.8305 - val_auc: 0.9159\n",
      "Epoch 9/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1133 - accuracy: 0.8367 - auc: 0.9220\n",
      "Epoch 9: val_accuracy improved from 0.83048 to 0.83557, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.8365 - auc: 0.9220 - val_loss: 0.1143 - val_accuracy: 0.8356 - val_auc: 0.9207\n",
      "Epoch 10/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.8390 - auc: 0.9257\n",
      "Epoch 10: val_accuracy improved from 0.83557 to 0.83926, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.8393 - auc: 0.9259 - val_loss: 0.1110 - val_accuracy: 0.8393 - val_auc: 0.9243\n",
      "Epoch 11/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1077 - accuracy: 0.8434 - auc: 0.9292\n",
      "Epoch 11: val_accuracy improved from 0.83926 to 0.83972, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.8432 - auc: 0.9292 - val_loss: 0.1094 - val_accuracy: 0.8397 - val_auc: 0.9263\n",
      "Epoch 12/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1054 - accuracy: 0.8464 - auc: 0.9321\n",
      "Epoch 12: val_accuracy improved from 0.83972 to 0.84388, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1055 - accuracy: 0.8458 - auc: 0.9319 - val_loss: 0.1074 - val_accuracy: 0.8439 - val_auc: 0.9288\n",
      "Epoch 13/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1038 - accuracy: 0.8490 - auc: 0.9341\n",
      "Epoch 13: val_accuracy improved from 0.84388 to 0.84573, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.8496 - auc: 0.9344 - val_loss: 0.1058 - val_accuracy: 0.8457 - val_auc: 0.9311\n",
      "Epoch 14/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1012 - accuracy: 0.8540 - auc: 0.9371\n",
      "Epoch 14: val_accuracy improved from 0.84573 to 0.85035, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.8531 - auc: 0.9370 - val_loss: 0.1039 - val_accuracy: 0.8503 - val_auc: 0.9335\n",
      "Epoch 15/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.0990 - accuracy: 0.8572 - auc: 0.9397\n",
      "Epoch 15: val_accuracy improved from 0.85035 to 0.85404, saving model to \\saved_models2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.8569 - auc: 0.9396 - val_loss: 0.1015 - val_accuracy: 0.8540 - val_auc: 0.9365\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.8540 - auc: 0.9365\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY2 = []\n",
    "VALIDATION_AUC2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names2].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names2].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names2):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model2 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model2.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models2/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history2 = model2.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model2.load_weights(\"\\saved_models2/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model2.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model2.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY2.append(results['accuracy'])\n",
    "    VALIDATION_AUC2.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history2.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8748846054077148 | 0.9543370008468628 |\n",
      "|  2   | 0.8707294464111328 | 0.9476138353347778 |\n",
      "|  3   | 0.8337950110435486 | 0.9231528043746948 |\n",
      "|  4   | 0.8347183465957642 | 0.9249693155288696 |\n",
      "|  5   | 0.8573406934738159 | 0.9324154853820801 |\n",
      "|  6   | 0.8494921326637268 | 0.9278420805931091 |\n",
      "|  7   | 0.8513388633728027 | 0.9325298070907593 |\n",
      "|  8   | 0.8439520001411438 | 0.9344832301139832 |\n",
      "|  9   | 0.8794457316398621 | 0.9516303539276123 |\n",
      "|  10  | 0.854041576385498  | 0.9365116953849792 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY2)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 9\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY2.index(max(VALIDATION_ACCURACY2))\n",
    "max_fold2 = idx + 1\n",
    "print(\"Best Fold:\", max_fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.8008 - auc: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13657717406749725, 0.8008310794830322, 0.8904063701629639]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_weights(\"\\saved_models2/model_\"+str(max_fold2)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model2.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 790us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model2.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat2 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2484 - accuracy: 0.5461 - auc: 0.5868\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64174, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.5462 - auc: 0.5868 - val_loss: 0.2418 - val_accuracy: 0.6417 - val_auc: 0.6883\n",
      "Epoch 2/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.2361 - accuracy: 0.6776 - auc: 0.7448\n",
      "Epoch 2: val_accuracy improved from 0.64174 to 0.69852, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2357 - accuracy: 0.6784 - auc: 0.7465 - val_loss: 0.2282 - val_accuracy: 0.6985 - val_auc: 0.7762\n",
      "Epoch 3/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.7240 - auc: 0.7993\n",
      "Epoch 3: val_accuracy improved from 0.69852 to 0.73546, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2174 - accuracy: 0.7240 - auc: 0.7993 - val_loss: 0.2059 - val_accuracy: 0.7355 - val_auc: 0.8166\n",
      "Epoch 4/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1943 - accuracy: 0.7514 - auc: 0.8335\n",
      "Epoch 4: val_accuracy improved from 0.73546 to 0.76362, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1932 - accuracy: 0.7533 - auc: 0.8353 - val_loss: 0.1809 - val_accuracy: 0.7636 - val_auc: 0.8511\n",
      "Epoch 5/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1692 - accuracy: 0.7833 - auc: 0.8674\n",
      "Epoch 5: val_accuracy improved from 0.76362 to 0.79317, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1691 - accuracy: 0.7834 - auc: 0.8675 - val_loss: 0.1583 - val_accuracy: 0.7932 - val_auc: 0.8808\n",
      "Epoch 6/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1500 - accuracy: 0.8068 - auc: 0.8894\n",
      "Epoch 6: val_accuracy improved from 0.79317 to 0.81671, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1495 - accuracy: 0.8080 - auc: 0.8901 - val_loss: 0.1420 - val_accuracy: 0.8167 - val_auc: 0.8971\n",
      "Epoch 7/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1362 - accuracy: 0.8232 - auc: 0.9030\n",
      "Epoch 7: val_accuracy improved from 0.81671 to 0.82548, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1361 - accuracy: 0.8230 - auc: 0.9028 - val_loss: 0.1315 - val_accuracy: 0.8255 - val_auc: 0.9067\n",
      "Epoch 8/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1274 - accuracy: 0.8310 - auc: 0.9101\n",
      "Epoch 8: val_accuracy improved from 0.82548 to 0.83287, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1273 - accuracy: 0.8314 - auc: 0.9102 - val_loss: 0.1243 - val_accuracy: 0.8329 - val_auc: 0.9130\n",
      "Epoch 9/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.8375 - auc: 0.9153\n",
      "Epoch 9: val_accuracy improved from 0.83287 to 0.83657, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1214 - accuracy: 0.8378 - auc: 0.9153 - val_loss: 0.1195 - val_accuracy: 0.8366 - val_auc: 0.9172\n",
      "Epoch 10/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.8396 - auc: 0.9186\n",
      "Epoch 10: val_accuracy improved from 0.83657 to 0.84718, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1173 - accuracy: 0.8400 - auc: 0.9189 - val_loss: 0.1162 - val_accuracy: 0.8472 - val_auc: 0.9202\n",
      "Epoch 11/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.8434 - auc: 0.9216\n",
      "Epoch 11: val_accuracy improved from 0.84718 to 0.84811, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1143 - accuracy: 0.8437 - auc: 0.9217 - val_loss: 0.1139 - val_accuracy: 0.8481 - val_auc: 0.9222\n",
      "Epoch 12/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.8468 - auc: 0.9238\n",
      "Epoch 12: val_accuracy improved from 0.84811 to 0.85042, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.8469 - auc: 0.9238 - val_loss: 0.1119 - val_accuracy: 0.8504 - val_auc: 0.9245\n",
      "Epoch 13/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.8487 - auc: 0.9259\n",
      "Epoch 13: val_accuracy improved from 0.85042 to 0.85319, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.8487 - auc: 0.9258 - val_loss: 0.1103 - val_accuracy: 0.8532 - val_auc: 0.9258\n",
      "Epoch 14/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.8522 - auc: 0.9281\n",
      "Epoch 14: val_accuracy improved from 0.85319 to 0.85549, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1087 - accuracy: 0.8515 - auc: 0.9276 - val_loss: 0.1087 - val_accuracy: 0.8555 - val_auc: 0.9275\n",
      "Epoch 15/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.8515 - auc: 0.9290\n",
      "Epoch 15: val_accuracy improved from 0.85549 to 0.85780, saving model to \\saved_models3/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.8516 - auc: 0.9290 - val_loss: 0.1079 - val_accuracy: 0.8578 - val_auc: 0.9286\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.8578 - auc: 0.9286\n",
      "Epoch 1/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.2473 - accuracy: 0.5614 - auc: 0.5846\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54524, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2472 - accuracy: 0.5628 - auc: 0.5869 - val_loss: 0.2456 - val_accuracy: 0.5452 - val_auc: 0.6631\n",
      "Epoch 2/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.5831 - auc: 0.7128\n",
      "Epoch 2: val_accuracy improved from 0.54524 to 0.57295, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2415 - accuracy: 0.5834 - auc: 0.7128 - val_loss: 0.2392 - val_accuracy: 0.5729 - val_auc: 0.7543\n",
      "Epoch 3/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.6372 - auc: 0.7743\n",
      "Epoch 3: val_accuracy improved from 0.57295 to 0.67959, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2318 - accuracy: 0.6376 - auc: 0.7744 - val_loss: 0.2256 - val_accuracy: 0.6796 - val_auc: 0.7899\n",
      "Epoch 4/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.7141 - auc: 0.8018\n",
      "Epoch 4: val_accuracy improved from 0.67959 to 0.73684, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2134 - accuracy: 0.7148 - auc: 0.8021 - val_loss: 0.2014 - val_accuracy: 0.7368 - val_auc: 0.8183\n",
      "Epoch 5/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.7562 - auc: 0.8322\n",
      "Epoch 5: val_accuracy improved from 0.73684 to 0.77239, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.7563 - auc: 0.8321 - val_loss: 0.1716 - val_accuracy: 0.7724 - val_auc: 0.8537\n",
      "Epoch 6/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.7868 - auc: 0.8660\n",
      "Epoch 6: val_accuracy improved from 0.77239 to 0.80471, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1591 - accuracy: 0.7866 - auc: 0.8660 - val_loss: 0.1464 - val_accuracy: 0.8047 - val_auc: 0.8846\n",
      "Epoch 7/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1395 - accuracy: 0.8087 - auc: 0.8901\n",
      "Epoch 7: val_accuracy improved from 0.80471 to 0.82410, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1391 - accuracy: 0.8095 - auc: 0.8905 - val_loss: 0.1302 - val_accuracy: 0.8241 - val_auc: 0.9038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1276 - accuracy: 0.8248 - auc: 0.9037\n",
      "Epoch 8: val_accuracy improved from 0.82410 to 0.83149, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1274 - accuracy: 0.8251 - auc: 0.9040 - val_loss: 0.1211 - val_accuracy: 0.8315 - val_auc: 0.9136\n",
      "Epoch 9/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1215 - accuracy: 0.8320 - auc: 0.9111\n",
      "Epoch 9: val_accuracy improved from 0.83149 to 0.83749, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.8339 - auc: 0.9119 - val_loss: 0.1159 - val_accuracy: 0.8375 - val_auc: 0.9196\n",
      "Epoch 10/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1165 - accuracy: 0.8393 - auc: 0.9169\n",
      "Epoch 10: val_accuracy improved from 0.83749 to 0.83980, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.8396 - auc: 0.9170 - val_loss: 0.1125 - val_accuracy: 0.8398 - val_auc: 0.9235\n",
      "Epoch 11/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1130 - accuracy: 0.8434 - auc: 0.9214\n",
      "Epoch 11: val_accuracy improved from 0.83980 to 0.84395, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8428 - auc: 0.9207 - val_loss: 0.1104 - val_accuracy: 0.8440 - val_auc: 0.9260\n",
      "Epoch 12/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.8475 - auc: 0.9234\n",
      "Epoch 12: val_accuracy improved from 0.84395 to 0.84488, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.8475 - auc: 0.9234 - val_loss: 0.1087 - val_accuracy: 0.8449 - val_auc: 0.9283\n",
      "Epoch 13/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1089 - accuracy: 0.8499 - auc: 0.9269\n",
      "Epoch 13: val_accuracy improved from 0.84488 to 0.84995, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.8485 - auc: 0.9258 - val_loss: 0.1074 - val_accuracy: 0.8500 - val_auc: 0.9299\n",
      "Epoch 14/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1079 - accuracy: 0.8503 - auc: 0.9283\n",
      "Epoch 14: val_accuracy improved from 0.84995 to 0.85042, saving model to \\saved_models3/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1083 - accuracy: 0.8499 - auc: 0.9277 - val_loss: 0.1064 - val_accuracy: 0.8504 - val_auc: 0.9311\n",
      "Epoch 15/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1072 - accuracy: 0.8509 - auc: 0.9294\n",
      "Epoch 15: val_accuracy did not improve from 0.85042\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.8513 - auc: 0.9294 - val_loss: 0.1054 - val_accuracy: 0.8500 - val_auc: 0.9324\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.8504 - auc: 0.9311\n",
      "Epoch 1/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.2476 - accuracy: 0.5375 - auc: 0.5574\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56925, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2475 - accuracy: 0.5381 - auc: 0.5585 - val_loss: 0.2432 - val_accuracy: 0.5693 - val_auc: 0.6375\n",
      "Epoch 2/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.5802 - auc: 0.6722\n",
      "Epoch 2: val_accuracy improved from 0.56925 to 0.63573, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2403 - accuracy: 0.5810 - auc: 0.6732 - val_loss: 0.2333 - val_accuracy: 0.6357 - val_auc: 0.7206\n",
      "Epoch 3/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.2223 - accuracy: 0.6828 - auc: 0.7623\n",
      "Epoch 3: val_accuracy improved from 0.63573 to 0.70545, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2215 - accuracy: 0.6843 - auc: 0.7631 - val_loss: 0.2074 - val_accuracy: 0.7054 - val_auc: 0.7772\n",
      "Epoch 4/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1860 - accuracy: 0.7463 - auc: 0.8208\n",
      "Epoch 4: val_accuracy improved from 0.70545 to 0.74792, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1849 - accuracy: 0.7476 - auc: 0.8224 - val_loss: 0.1740 - val_accuracy: 0.7479 - val_auc: 0.8266\n",
      "Epoch 5/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1545 - accuracy: 0.7842 - auc: 0.8634\n",
      "Epoch 5: val_accuracy improved from 0.74792 to 0.78347, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1537 - accuracy: 0.7853 - auc: 0.8647 - val_loss: 0.1525 - val_accuracy: 0.7835 - val_auc: 0.8613\n",
      "Epoch 6/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1368 - accuracy: 0.8052 - auc: 0.8884\n",
      "Epoch 6: val_accuracy improved from 0.78347 to 0.79640, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1366 - accuracy: 0.8055 - auc: 0.8887 - val_loss: 0.1400 - val_accuracy: 0.7964 - val_auc: 0.8821\n",
      "Epoch 7/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1274 - accuracy: 0.8170 - auc: 0.9019\n",
      "Epoch 7: val_accuracy improved from 0.79640 to 0.80840, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1266 - accuracy: 0.8182 - auc: 0.9031 - val_loss: 0.1315 - val_accuracy: 0.8084 - val_auc: 0.8954\n",
      "Epoch 8/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1195 - accuracy: 0.8288 - auc: 0.9133\n",
      "Epoch 8: val_accuracy improved from 0.80840 to 0.81071, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.8289 - auc: 0.9131 - val_loss: 0.1257 - val_accuracy: 0.8107 - val_auc: 0.9045\n",
      "Epoch 9/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.8345 - auc: 0.9198\n",
      "Epoch 9: val_accuracy improved from 0.81071 to 0.81810, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8351 - auc: 0.9201 - val_loss: 0.1218 - val_accuracy: 0.8181 - val_auc: 0.9102\n",
      "Epoch 10/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1103 - accuracy: 0.8421 - auc: 0.9255\n",
      "Epoch 10: val_accuracy improved from 0.81810 to 0.82133, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1108 - accuracy: 0.8413 - auc: 0.9250 - val_loss: 0.1190 - val_accuracy: 0.8213 - val_auc: 0.9145\n",
      "Epoch 11/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1077 - accuracy: 0.8460 - auc: 0.9289\n",
      "Epoch 11: val_accuracy improved from 0.82133 to 0.82687, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.8464 - auc: 0.9290 - val_loss: 0.1158 - val_accuracy: 0.8269 - val_auc: 0.9186\n",
      "Epoch 12/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1054 - accuracy: 0.8500 - auc: 0.9317\n",
      "Epoch 12: val_accuracy improved from 0.82687 to 0.83195, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.8505 - auc: 0.9321 - val_loss: 0.1141 - val_accuracy: 0.8319 - val_auc: 0.9220\n",
      "Epoch 13/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.8533 - auc: 0.9352\n",
      "Epoch 13: val_accuracy did not improve from 0.83195\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1025 - accuracy: 0.8534 - auc: 0.9352 - val_loss: 0.1122 - val_accuracy: 0.8319 - val_auc: 0.9247\n",
      "Epoch 14/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.8588 - auc: 0.9386\n",
      "Epoch 14: val_accuracy improved from 0.83195 to 0.83980, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0997 - accuracy: 0.8581 - auc: 0.9385 - val_loss: 0.1088 - val_accuracy: 0.8398 - val_auc: 0.9286\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/610 [===========================>..] - ETA: 0s - loss: 0.0973 - accuracy: 0.8625 - auc: 0.9413\n",
      "Epoch 15: val_accuracy improved from 0.83980 to 0.84488, saving model to \\saved_models3/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.8619 - auc: 0.9413 - val_loss: 0.1070 - val_accuracy: 0.8449 - val_auc: 0.9316\n",
      "68/68 [==============================] - 0s 943us/step - loss: 0.1070 - accuracy: 0.8449 - auc: 0.9316\n",
      "Epoch 1/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.2430 - accuracy: 0.6369 - auc: 0.6961\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73823, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2426 - accuracy: 0.6425 - auc: 0.7011 - val_loss: 0.2354 - val_accuracy: 0.7382 - val_auc: 0.8046\n",
      "Epoch 2/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.2263 - accuracy: 0.7685 - auc: 0.8372\n",
      "Epoch 2: val_accuracy improved from 0.73823 to 0.77747, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2258 - accuracy: 0.7701 - auc: 0.8380 - val_loss: 0.2166 - val_accuracy: 0.7775 - val_auc: 0.8456\n",
      "Epoch 3/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.2028 - accuracy: 0.7973 - auc: 0.8604\n",
      "Epoch 3: val_accuracy improved from 0.77747 to 0.78578, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2019 - accuracy: 0.7980 - auc: 0.8605 - val_loss: 0.1909 - val_accuracy: 0.7858 - val_auc: 0.8603\n",
      "Epoch 4/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1755 - accuracy: 0.8148 - auc: 0.8754\n",
      "Epoch 4: val_accuracy improved from 0.78578 to 0.79778, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1747 - accuracy: 0.8149 - auc: 0.8758 - val_loss: 0.1672 - val_accuracy: 0.7978 - val_auc: 0.8721\n",
      "Epoch 5/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1530 - accuracy: 0.8283 - auc: 0.8871\n",
      "Epoch 5: val_accuracy improved from 0.79778 to 0.80979, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1526 - accuracy: 0.8289 - auc: 0.8874 - val_loss: 0.1507 - val_accuracy: 0.8098 - val_auc: 0.8804\n",
      "Epoch 6/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.8381 - auc: 0.8957\n",
      "Epoch 6: val_accuracy improved from 0.80979 to 0.81440, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.8382 - auc: 0.8957 - val_loss: 0.1411 - val_accuracy: 0.8144 - val_auc: 0.8855\n",
      "Epoch 7/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.8426 - auc: 0.9003\n",
      "Epoch 7: val_accuracy improved from 0.81440 to 0.81671, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.8431 - auc: 0.9010 - val_loss: 0.1357 - val_accuracy: 0.8167 - val_auc: 0.8884\n",
      "Epoch 8/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1225 - accuracy: 0.8461 - auc: 0.9051\n",
      "Epoch 8: val_accuracy did not improve from 0.81671\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.8462 - auc: 0.9045 - val_loss: 0.1326 - val_accuracy: 0.8167 - val_auc: 0.8906\n",
      "Epoch 9/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1193 - accuracy: 0.8475 - auc: 0.9074\n",
      "Epoch 9: val_accuracy did not improve from 0.81671\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1193 - accuracy: 0.8474 - auc: 0.9074 - val_loss: 0.1309 - val_accuracy: 0.8167 - val_auc: 0.8925\n",
      "Epoch 10/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1172 - accuracy: 0.8483 - auc: 0.9096\n",
      "Epoch 10: val_accuracy did not improve from 0.81671\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.8481 - auc: 0.9096 - val_loss: 0.1299 - val_accuracy: 0.8163 - val_auc: 0.8940\n",
      "Epoch 11/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.8482 - auc: 0.9115\n",
      "Epoch 11: val_accuracy did not improve from 0.81671\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8482 - auc: 0.9115 - val_loss: 0.1293 - val_accuracy: 0.8167 - val_auc: 0.8949\n",
      "Epoch 12/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1142 - accuracy: 0.8487 - auc: 0.9135\n",
      "Epoch 12: val_accuracy did not improve from 0.81671\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8483 - auc: 0.9130 - val_loss: 0.1288 - val_accuracy: 0.8167 - val_auc: 0.8963\n",
      "Epoch 13/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1143 - accuracy: 0.8482 - auc: 0.9136\n",
      "Epoch 13: val_accuracy improved from 0.81671 to 0.81717, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.8490 - auc: 0.9144 - val_loss: 0.1285 - val_accuracy: 0.8172 - val_auc: 0.8974\n",
      "Epoch 14/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1130 - accuracy: 0.8493 - auc: 0.9156\n",
      "Epoch 14: val_accuracy did not improve from 0.81717\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.8492 - auc: 0.9157 - val_loss: 0.1281 - val_accuracy: 0.8172 - val_auc: 0.8987\n",
      "Epoch 15/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.8491 - auc: 0.9167\n",
      "Epoch 15: val_accuracy improved from 0.81717 to 0.81810, saving model to \\saved_models3/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1124 - accuracy: 0.8495 - auc: 0.9170 - val_loss: 0.1279 - val_accuracy: 0.8181 - val_auc: 0.8994\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.8181 - auc: 0.8994\n",
      "Epoch 1/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.5490 - auc: 0.5488\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59834, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2470 - accuracy: 0.5490 - auc: 0.5489 - val_loss: 0.2424 - val_accuracy: 0.5983 - val_auc: 0.6239\n",
      "Epoch 2/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.2358 - accuracy: 0.6309 - auc: 0.6813\n",
      "Epoch 2: val_accuracy improved from 0.59834 to 0.66482, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2354 - accuracy: 0.6324 - auc: 0.6828 - val_loss: 0.2295 - val_accuracy: 0.6648 - val_auc: 0.7080\n",
      "Epoch 3/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.2183 - accuracy: 0.6893 - auc: 0.7477\n",
      "Epoch 3: val_accuracy improved from 0.66482 to 0.72207, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2175 - accuracy: 0.6906 - auc: 0.7492 - val_loss: 0.2061 - val_accuracy: 0.7221 - val_auc: 0.7729\n",
      "Epoch 4/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1902 - accuracy: 0.7393 - auc: 0.8074\n",
      "Epoch 4: val_accuracy improved from 0.72207 to 0.75669, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1889 - accuracy: 0.7415 - auc: 0.8104 - val_loss: 0.1728 - val_accuracy: 0.7567 - val_auc: 0.8361\n",
      "Epoch 5/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1579 - accuracy: 0.7820 - auc: 0.8625\n",
      "Epoch 5: val_accuracy improved from 0.75669 to 0.79963, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.7831 - auc: 0.8638 - val_loss: 0.1430 - val_accuracy: 0.7996 - val_auc: 0.8830\n",
      "Epoch 6/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 0.8092 - auc: 0.8938\n",
      "Epoch 6: val_accuracy improved from 0.79963 to 0.82133, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1354 - accuracy: 0.8093 - auc: 0.8937 - val_loss: 0.1270 - val_accuracy: 0.8213 - val_auc: 0.9039\n",
      "Epoch 7/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.8233 - auc: 0.9076\n",
      "Epoch 7: val_accuracy improved from 0.82133 to 0.82964, saving model to \\saved_models3/model_5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1244 - accuracy: 0.8230 - auc: 0.9076 - val_loss: 0.1190 - val_accuracy: 0.8296 - val_auc: 0.9146\n",
      "Epoch 8/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.8317 - auc: 0.9152\n",
      "Epoch 8: val_accuracy improved from 0.82964 to 0.83887, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.8319 - auc: 0.9154 - val_loss: 0.1149 - val_accuracy: 0.8389 - val_auc: 0.9195\n",
      "Epoch 9/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1151 - accuracy: 0.8343 - auc: 0.9196\n",
      "Epoch 9: val_accuracy improved from 0.83887 to 0.84164, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.8355 - auc: 0.9202 - val_loss: 0.1114 - val_accuracy: 0.8416 - val_auc: 0.9243\n",
      "Epoch 10/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1114 - accuracy: 0.8401 - auc: 0.9243\n",
      "Epoch 10: val_accuracy improved from 0.84164 to 0.84857, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8400 - auc: 0.9241 - val_loss: 0.1088 - val_accuracy: 0.8486 - val_auc: 0.9276\n",
      "Epoch 11/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1096 - accuracy: 0.8436 - auc: 0.9267\n",
      "Epoch 11: val_accuracy improved from 0.84857 to 0.84949, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.8440 - auc: 0.9271 - val_loss: 0.1069 - val_accuracy: 0.8495 - val_auc: 0.9302\n",
      "Epoch 12/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1064 - accuracy: 0.8486 - auc: 0.9308\n",
      "Epoch 12: val_accuracy did not improve from 0.84949\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.8476 - auc: 0.9298 - val_loss: 0.1051 - val_accuracy: 0.8486 - val_auc: 0.9329\n",
      "Epoch 13/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.8507 - auc: 0.9322\n",
      "Epoch 13: val_accuracy improved from 0.84949 to 0.85596, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.8508 - auc: 0.9322 - val_loss: 0.1036 - val_accuracy: 0.8560 - val_auc: 0.9340\n",
      "Epoch 14/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1034 - accuracy: 0.8539 - auc: 0.9344\n",
      "Epoch 14: val_accuracy improved from 0.85596 to 0.85780, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1033 - accuracy: 0.8538 - auc: 0.9346 - val_loss: 0.1023 - val_accuracy: 0.8578 - val_auc: 0.9359\n",
      "Epoch 15/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.8566 - auc: 0.9369\n",
      "Epoch 15: val_accuracy improved from 0.85780 to 0.85919, saving model to \\saved_models3/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.8570 - auc: 0.9371 - val_loss: 0.1005 - val_accuracy: 0.8592 - val_auc: 0.9380\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.8592 - auc: 0.9380\n",
      "Epoch 1/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.5927 - auc: 0.6402\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61311, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.5937 - auc: 0.6414 - val_loss: 0.2410 - val_accuracy: 0.6131 - val_auc: 0.7050\n",
      "Epoch 2/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.6556 - auc: 0.7544\n",
      "Epoch 2: val_accuracy improved from 0.61311 to 0.68421, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2341 - accuracy: 0.6559 - auc: 0.7549 - val_loss: 0.2292 - val_accuracy: 0.6842 - val_auc: 0.7797\n",
      "Epoch 3/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.7185 - auc: 0.7971\n",
      "Epoch 3: val_accuracy improved from 0.68421 to 0.73730, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2180 - accuracy: 0.7179 - auc: 0.7966 - val_loss: 0.2097 - val_accuracy: 0.7373 - val_auc: 0.8086\n",
      "Epoch 4/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.7503 - auc: 0.8197\n",
      "Epoch 4: val_accuracy improved from 0.73730 to 0.76177, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1955 - accuracy: 0.7505 - auc: 0.8203 - val_loss: 0.1864 - val_accuracy: 0.7618 - val_auc: 0.8305\n",
      "Epoch 5/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.7742 - auc: 0.8459\n",
      "Epoch 5: val_accuracy improved from 0.76177 to 0.78578, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.7744 - auc: 0.8461 - val_loss: 0.1651 - val_accuracy: 0.7858 - val_auc: 0.8597\n",
      "Epoch 6/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1542 - accuracy: 0.7989 - auc: 0.8724\n",
      "Epoch 6: val_accuracy improved from 0.78578 to 0.80979, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1542 - accuracy: 0.7989 - auc: 0.8725 - val_loss: 0.1474 - val_accuracy: 0.8098 - val_auc: 0.8832\n",
      "Epoch 7/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1390 - accuracy: 0.8193 - auc: 0.8920\n",
      "Epoch 7: val_accuracy improved from 0.80979 to 0.82595, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1391 - accuracy: 0.8190 - auc: 0.8915 - val_loss: 0.1342 - val_accuracy: 0.8259 - val_auc: 0.8987\n",
      "Epoch 8/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.8310 - auc: 0.9034\n",
      "Epoch 8: val_accuracy improved from 0.82595 to 0.83195, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.8310 - auc: 0.9032 - val_loss: 0.1256 - val_accuracy: 0.8319 - val_auc: 0.9075\n",
      "Epoch 9/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1222 - accuracy: 0.8368 - auc: 0.9098\n",
      "Epoch 9: val_accuracy improved from 0.83195 to 0.83980, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1219 - accuracy: 0.8374 - auc: 0.9102 - val_loss: 0.1205 - val_accuracy: 0.8398 - val_auc: 0.9122\n",
      "Epoch 10/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1178 - accuracy: 0.8432 - auc: 0.9143\n",
      "Epoch 10: val_accuracy improved from 0.83980 to 0.84118, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.8431 - auc: 0.9143 - val_loss: 0.1174 - val_accuracy: 0.8412 - val_auc: 0.9155\n",
      "Epoch 11/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.8461 - auc: 0.9169\n",
      "Epoch 11: val_accuracy improved from 0.84118 to 0.84349, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.8462 - auc: 0.9171 - val_loss: 0.1153 - val_accuracy: 0.8435 - val_auc: 0.9174\n",
      "Epoch 12/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.8470 - auc: 0.9192\n",
      "Epoch 12: val_accuracy improved from 0.84349 to 0.84488, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8470 - auc: 0.9192 - val_loss: 0.1140 - val_accuracy: 0.8449 - val_auc: 0.9194\n",
      "Epoch 13/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.8486 - auc: 0.9209\n",
      "Epoch 13: val_accuracy improved from 0.84488 to 0.84534, saving model to \\saved_models3/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1124 - accuracy: 0.8482 - auc: 0.9207 - val_loss: 0.1130 - val_accuracy: 0.8453 - val_auc: 0.9204\n",
      "Epoch 14/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1115 - accuracy: 0.8487 - auc: 0.9221\n",
      "Epoch 14: val_accuracy did not improve from 0.84534\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1114 - accuracy: 0.8492 - auc: 0.9222 - val_loss: 0.1123 - val_accuracy: 0.8449 - val_auc: 0.9213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.8499 - auc: 0.9235\n",
      "Epoch 15: val_accuracy did not improve from 0.84534\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.8499 - auc: 0.9233 - val_loss: 0.1117 - val_accuracy: 0.8453 - val_auc: 0.9224\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.8453 - auc: 0.9204\n",
      "Epoch 1/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.2468 - accuracy: 0.5649 - auc: 0.5825\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64589, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2464 - accuracy: 0.5686 - auc: 0.5882 - val_loss: 0.2391 - val_accuracy: 0.6459 - val_auc: 0.6941\n",
      "Epoch 2/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.6752 - auc: 0.7263\n",
      "Epoch 2: val_accuracy improved from 0.64589 to 0.69252, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2301 - accuracy: 0.6762 - auc: 0.7274 - val_loss: 0.2179 - val_accuracy: 0.6925 - val_auc: 0.7595\n",
      "Epoch 3/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.7072 - auc: 0.7736\n",
      "Epoch 3: val_accuracy improved from 0.69252 to 0.71745, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2049 - accuracy: 0.7072 - auc: 0.7735 - val_loss: 0.1916 - val_accuracy: 0.7175 - val_auc: 0.7952\n",
      "Epoch 4/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.7387 - auc: 0.8153\n",
      "Epoch 4: val_accuracy improved from 0.71745 to 0.75854, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1797 - accuracy: 0.7388 - auc: 0.8152 - val_loss: 0.1679 - val_accuracy: 0.7585 - val_auc: 0.8360\n",
      "Epoch 5/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.7708 - auc: 0.8540\n",
      "Epoch 5: val_accuracy improved from 0.75854 to 0.78809, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1579 - accuracy: 0.7712 - auc: 0.8544 - val_loss: 0.1483 - val_accuracy: 0.7881 - val_auc: 0.8706\n",
      "Epoch 6/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1413 - accuracy: 0.7966 - auc: 0.8817\n",
      "Epoch 6: val_accuracy improved from 0.78809 to 0.80609, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1414 - accuracy: 0.7967 - auc: 0.8814 - val_loss: 0.1363 - val_accuracy: 0.8061 - val_auc: 0.8891\n",
      "Epoch 7/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.8117 - auc: 0.8971\n",
      "Epoch 7: val_accuracy improved from 0.80609 to 0.81487, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1308 - accuracy: 0.8116 - auc: 0.8970 - val_loss: 0.1293 - val_accuracy: 0.8149 - val_auc: 0.8990\n",
      "Epoch 8/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.8207 - auc: 0.9064\n",
      "Epoch 8: val_accuracy improved from 0.81487 to 0.82041, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.8212 - auc: 0.9067 - val_loss: 0.1239 - val_accuracy: 0.8204 - val_auc: 0.9061\n",
      "Epoch 9/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.8285 - auc: 0.9130\n",
      "Epoch 9: val_accuracy improved from 0.82041 to 0.82502, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1195 - accuracy: 0.8281 - auc: 0.9128 - val_loss: 0.1197 - val_accuracy: 0.8250 - val_auc: 0.9111\n",
      "Epoch 10/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1164 - accuracy: 0.8324 - auc: 0.9171\n",
      "Epoch 10: val_accuracy improved from 0.82502 to 0.82964, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.8329 - auc: 0.9175 - val_loss: 0.1179 - val_accuracy: 0.8296 - val_auc: 0.9137\n",
      "Epoch 11/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.8381 - auc: 0.9208\n",
      "Epoch 11: val_accuracy improved from 0.82964 to 0.83102, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8381 - auc: 0.9208 - val_loss: 0.1165 - val_accuracy: 0.8310 - val_auc: 0.9162\n",
      "Epoch 12/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1117 - accuracy: 0.8410 - auc: 0.9234\n",
      "Epoch 12: val_accuracy improved from 0.83102 to 0.84072, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8411 - auc: 0.9234 - val_loss: 0.1141 - val_accuracy: 0.8407 - val_auc: 0.9186\n",
      "Epoch 13/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.8438 - auc: 0.9253\n",
      "Epoch 13: val_accuracy did not improve from 0.84072\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1101 - accuracy: 0.8438 - auc: 0.9256 - val_loss: 0.1131 - val_accuracy: 0.8403 - val_auc: 0.9200\n",
      "Epoch 14/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.8463 - auc: 0.9279\n",
      "Epoch 14: val_accuracy improved from 0.84072 to 0.84211, saving model to \\saved_models3/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.8459 - auc: 0.9275 - val_loss: 0.1125 - val_accuracy: 0.8421 - val_auc: 0.9210\n",
      "Epoch 15/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.8474 - auc: 0.9289\n",
      "Epoch 15: val_accuracy did not improve from 0.84211\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.8475 - auc: 0.9289 - val_loss: 0.1112 - val_accuracy: 0.8421 - val_auc: 0.9225\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8421 - auc: 0.9210\n",
      "Epoch 1/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.2404 - accuracy: 0.6141 - auc: 0.6594\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67498, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.6145 - auc: 0.6600 - val_loss: 0.2293 - val_accuracy: 0.6750 - val_auc: 0.7524\n",
      "Epoch 2/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.2200 - accuracy: 0.6887 - auc: 0.7626\n",
      "Epoch 2: val_accuracy improved from 0.67498 to 0.71976, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2194 - accuracy: 0.6894 - auc: 0.7635 - val_loss: 0.2023 - val_accuracy: 0.7198 - val_auc: 0.8113\n",
      "Epoch 3/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1910 - accuracy: 0.7378 - auc: 0.8169\n",
      "Epoch 3: val_accuracy improved from 0.71976 to 0.76824, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1907 - accuracy: 0.7381 - auc: 0.8172 - val_loss: 0.1713 - val_accuracy: 0.7682 - val_auc: 0.8491\n",
      "Epoch 4/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.7771 - auc: 0.8572\n",
      "Epoch 4: val_accuracy improved from 0.76824 to 0.79501, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.7774 - auc: 0.8574 - val_loss: 0.1476 - val_accuracy: 0.7950 - val_auc: 0.8777\n",
      "Epoch 5/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.8039 - auc: 0.8849\n",
      "Epoch 5: val_accuracy improved from 0.79501 to 0.80840, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1411 - accuracy: 0.8036 - auc: 0.8848 - val_loss: 0.1326 - val_accuracy: 0.8084 - val_auc: 0.8972\n",
      "Epoch 6/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.8225 - auc: 0.9010\n",
      "Epoch 6: val_accuracy improved from 0.80840 to 0.82041, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1281 - accuracy: 0.8230 - auc: 0.9015 - val_loss: 0.1223 - val_accuracy: 0.8204 - val_auc: 0.9108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.8316 - auc: 0.9111\n",
      "Epoch 7: val_accuracy improved from 0.82041 to 0.82918, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.8317 - auc: 0.9112 - val_loss: 0.1154 - val_accuracy: 0.8292 - val_auc: 0.9190\n",
      "Epoch 8/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.8382 - auc: 0.9174\n",
      "Epoch 8: val_accuracy improved from 0.82918 to 0.83795, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.8377 - auc: 0.9171 - val_loss: 0.1121 - val_accuracy: 0.8380 - val_auc: 0.9231\n",
      "Epoch 9/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1133 - accuracy: 0.8418 - auc: 0.9202\n",
      "Epoch 9: val_accuracy improved from 0.83795 to 0.84580, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1126 - accuracy: 0.8433 - auc: 0.9210 - val_loss: 0.1085 - val_accuracy: 0.8458 - val_auc: 0.9276\n",
      "Epoch 10/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1109 - accuracy: 0.8436 - auc: 0.9232\n",
      "Epoch 10: val_accuracy improved from 0.84580 to 0.84765, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.8443 - auc: 0.9235 - val_loss: 0.1068 - val_accuracy: 0.8476 - val_auc: 0.9295\n",
      "Epoch 11/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1091 - accuracy: 0.8458 - auc: 0.9257\n",
      "Epoch 11: val_accuracy did not improve from 0.84765\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1091 - accuracy: 0.8459 - auc: 0.9255 - val_loss: 0.1058 - val_accuracy: 0.8472 - val_auc: 0.9312\n",
      "Epoch 12/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1079 - accuracy: 0.8479 - auc: 0.9272\n",
      "Epoch 12: val_accuracy improved from 0.84765 to 0.85180, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.8479 - auc: 0.9273 - val_loss: 0.1035 - val_accuracy: 0.8518 - val_auc: 0.9337\n",
      "Epoch 13/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1070 - accuracy: 0.8506 - auc: 0.9284\n",
      "Epoch 13: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1070 - accuracy: 0.8503 - auc: 0.9285 - val_loss: 0.1034 - val_accuracy: 0.8509 - val_auc: 0.9345\n",
      "Epoch 14/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.8498 - auc: 0.9294\n",
      "Epoch 14: val_accuracy improved from 0.85180 to 0.85365, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.8502 - auc: 0.9297 - val_loss: 0.1019 - val_accuracy: 0.8536 - val_auc: 0.9358\n",
      "Epoch 15/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.8513 - auc: 0.9310\n",
      "Epoch 15: val_accuracy improved from 0.85365 to 0.85457, saving model to \\saved_models3/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1053 - accuracy: 0.8513 - auc: 0.9310 - val_loss: 0.1018 - val_accuracy: 0.8546 - val_auc: 0.9358\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.8546 - auc: 0.9358\n",
      "Epoch 1/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.2400 - accuracy: 0.6238 - auc: 0.6834\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73118, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.6294 - auc: 0.6895 - val_loss: 0.2239 - val_accuracy: 0.7312 - val_auc: 0.7997\n",
      "Epoch 2/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.7334 - auc: 0.8064\n",
      "Epoch 2: val_accuracy improved from 0.73118 to 0.77229, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2049 - accuracy: 0.7333 - auc: 0.8063 - val_loss: 0.1754 - val_accuracy: 0.7723 - val_auc: 0.8555\n",
      "Epoch 3/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.7721 - auc: 0.8536\n",
      "Epoch 3: val_accuracy improved from 0.77229 to 0.80647, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1640 - accuracy: 0.7720 - auc: 0.8536 - val_loss: 0.1422 - val_accuracy: 0.8065 - val_auc: 0.8888\n",
      "Epoch 4/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1417 - accuracy: 0.7957 - auc: 0.8833\n",
      "Epoch 4: val_accuracy improved from 0.80647 to 0.82217, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1415 - accuracy: 0.7960 - auc: 0.8836 - val_loss: 0.1267 - val_accuracy: 0.8222 - val_auc: 0.9052\n",
      "Epoch 5/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1299 - accuracy: 0.8121 - auc: 0.8993\n",
      "Epoch 5: val_accuracy improved from 0.82217 to 0.83557, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.8124 - auc: 0.8995 - val_loss: 0.1184 - val_accuracy: 0.8356 - val_auc: 0.9153\n",
      "Epoch 6/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1224 - accuracy: 0.8237 - auc: 0.9096\n",
      "Epoch 6: val_accuracy improved from 0.83557 to 0.83926, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1224 - accuracy: 0.8246 - auc: 0.9098 - val_loss: 0.1132 - val_accuracy: 0.8393 - val_auc: 0.9216\n",
      "Epoch 7/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1168 - accuracy: 0.8314 - auc: 0.9173\n",
      "Epoch 7: val_accuracy improved from 0.83926 to 0.84665, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.8310 - auc: 0.9168 - val_loss: 0.1098 - val_accuracy: 0.8467 - val_auc: 0.9257\n",
      "Epoch 8/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1127 - accuracy: 0.8385 - auc: 0.9226\n",
      "Epoch 8: val_accuracy improved from 0.84665 to 0.85173, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.8382 - auc: 0.9223 - val_loss: 0.1067 - val_accuracy: 0.8517 - val_auc: 0.9296\n",
      "Epoch 9/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1093 - accuracy: 0.8419 - auc: 0.9271\n",
      "Epoch 9: val_accuracy improved from 0.85173 to 0.85681, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.8417 - auc: 0.9270 - val_loss: 0.1043 - val_accuracy: 0.8568 - val_auc: 0.9324\n",
      "Epoch 10/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1066 - accuracy: 0.8470 - auc: 0.9304\n",
      "Epoch 10: val_accuracy improved from 0.85681 to 0.85774, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.8474 - auc: 0.9307 - val_loss: 0.1018 - val_accuracy: 0.8577 - val_auc: 0.9354\n",
      "Epoch 11/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1037 - accuracy: 0.8506 - auc: 0.9339\n",
      "Epoch 11: val_accuracy did not improve from 0.85774\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.8505 - auc: 0.9342 - val_loss: 0.1006 - val_accuracy: 0.8573 - val_auc: 0.9378\n",
      "Epoch 12/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.8551 - auc: 0.9375\n",
      "Epoch 12: val_accuracy improved from 0.85774 to 0.86467, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1009 - accuracy: 0.8552 - auc: 0.9376 - val_loss: 0.0980 - val_accuracy: 0.8647 - val_auc: 0.9399\n",
      "Epoch 13/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.8596 - auc: 0.9408\n",
      "Epoch 13: val_accuracy improved from 0.86467 to 0.86605, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0981 - accuracy: 0.8595 - auc: 0.9408 - val_loss: 0.0956 - val_accuracy: 0.8661 - val_auc: 0.9428\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/610 [===========================>..] - ETA: 0s - loss: 0.0954 - accuracy: 0.8643 - auc: 0.9440\n",
      "Epoch 14: val_accuracy did not improve from 0.86605\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.8647 - auc: 0.9441 - val_loss: 0.0932 - val_accuracy: 0.8647 - val_auc: 0.9455\n",
      "Epoch 15/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.0927 - accuracy: 0.8693 - auc: 0.9471\n",
      "Epoch 15: val_accuracy improved from 0.86605 to 0.86928, saving model to \\saved_models3/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0924 - accuracy: 0.8696 - auc: 0.9473 - val_loss: 0.0907 - val_accuracy: 0.8693 - val_auc: 0.9484\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.8693 - auc: 0.9484\n",
      "Epoch 1/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.5270 - auc: 0.5566\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55289, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.5271 - auc: 0.5567 - val_loss: 0.2427 - val_accuracy: 0.5529 - val_auc: 0.6712\n",
      "Epoch 2/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.5535 - auc: 0.7293\n",
      "Epoch 2: val_accuracy improved from 0.55289 to 0.58661, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2386 - accuracy: 0.5557 - auc: 0.7319 - val_loss: 0.2321 - val_accuracy: 0.5866 - val_auc: 0.7712\n",
      "Epoch 3/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2243 - accuracy: 0.6476 - auc: 0.8001\n",
      "Epoch 3: val_accuracy improved from 0.58661 to 0.69792, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2240 - accuracy: 0.6485 - auc: 0.8007 - val_loss: 0.2127 - val_accuracy: 0.6979 - val_auc: 0.8222\n",
      "Epoch 4/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.2007 - accuracy: 0.7467 - auc: 0.8369\n",
      "Epoch 4: val_accuracy improved from 0.69792 to 0.78060, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2005 - accuracy: 0.7474 - auc: 0.8375 - val_loss: 0.1858 - val_accuracy: 0.7806 - val_auc: 0.8576\n",
      "Epoch 5/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1746 - accuracy: 0.7887 - auc: 0.8673\n",
      "Epoch 5: val_accuracy improved from 0.78060 to 0.80970, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1740 - accuracy: 0.7887 - auc: 0.8671 - val_loss: 0.1601 - val_accuracy: 0.8097 - val_auc: 0.8847\n",
      "Epoch 6/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1521 - accuracy: 0.8103 - auc: 0.8886\n",
      "Epoch 6: val_accuracy improved from 0.80970 to 0.82079, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1516 - accuracy: 0.8110 - auc: 0.8893 - val_loss: 0.1406 - val_accuracy: 0.8208 - val_auc: 0.9005\n",
      "Epoch 7/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.8228 - auc: 0.9021\n",
      "Epoch 7: val_accuracy improved from 0.82079 to 0.83141, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1359 - accuracy: 0.8230 - auc: 0.9024 - val_loss: 0.1283 - val_accuracy: 0.8314 - val_auc: 0.9098\n",
      "Epoch 8/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1262 - accuracy: 0.8334 - auc: 0.9105\n",
      "Epoch 8: val_accuracy improved from 0.83141 to 0.83510, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1262 - accuracy: 0.8331 - auc: 0.9102 - val_loss: 0.1210 - val_accuracy: 0.8351 - val_auc: 0.9150\n",
      "Epoch 9/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.8373 - auc: 0.9150\n",
      "Epoch 9: val_accuracy improved from 0.83510 to 0.84111, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.8378 - auc: 0.9151 - val_loss: 0.1166 - val_accuracy: 0.8411 - val_auc: 0.9187\n",
      "Epoch 10/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.8397 - auc: 0.9186\n",
      "Epoch 10: val_accuracy improved from 0.84111 to 0.84527, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.8397 - auc: 0.9186 - val_loss: 0.1140 - val_accuracy: 0.8453 - val_auc: 0.9209\n",
      "Epoch 11/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.8422 - auc: 0.9212\n",
      "Epoch 11: val_accuracy did not improve from 0.84527\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.8422 - auc: 0.9212 - val_loss: 0.1122 - val_accuracy: 0.8453 - val_auc: 0.9228\n",
      "Epoch 12/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.8439 - auc: 0.9232\n",
      "Epoch 12: val_accuracy improved from 0.84527 to 0.84850, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.8440 - auc: 0.9233 - val_loss: 0.1106 - val_accuracy: 0.8485 - val_auc: 0.9246\n",
      "Epoch 13/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1106 - accuracy: 0.8459 - auc: 0.9252\n",
      "Epoch 13: val_accuracy did not improve from 0.84850\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1107 - accuracy: 0.8457 - auc: 0.9250 - val_loss: 0.1093 - val_accuracy: 0.8485 - val_auc: 0.9261\n",
      "Epoch 14/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1096 - accuracy: 0.8472 - auc: 0.9263\n",
      "Epoch 14: val_accuracy improved from 0.84850 to 0.84942, saving model to \\saved_models3/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.8474 - auc: 0.9265 - val_loss: 0.1081 - val_accuracy: 0.8494 - val_auc: 0.9276\n",
      "Epoch 15/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1090 - accuracy: 0.8472 - auc: 0.9273\n",
      "Epoch 15: val_accuracy did not improve from 0.84942\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.8480 - auc: 0.9280 - val_loss: 0.1078 - val_accuracy: 0.8490 - val_auc: 0.9284\n",
      "68/68 [==============================] - 0s 953us/step - loss: 0.1081 - accuracy: 0.8494 - auc: 0.9276\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY3 = []\n",
    "VALIDATION_AUC3 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names3].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names3].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names3):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model3 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model3.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models3/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history3 = model3.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model3.load_weights(\"\\saved_models3/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model3.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model3.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY3.append(results['accuracy'])\n",
    "    VALIDATION_AUC3.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAEWCAYAAAAjJDDoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABM9UlEQVR4nO3ddXxd9f3H8dcnN+51S50KpULbUGjRYSsMHbDhMBgwGFPGxsbGGBsbczZgyHAbLoXhFPkxtC11V5q6JmlcPr8/zklJSyVE7r1J3s/H4z6O3COfpOHD53zP95yvuTsiIiIiEh8SYh2AiIiIiHxOxZmIiIhIHFFxJiIiIhJHVJyJiIiIxBEVZyIiIiJxRMWZiIiISBxRcSatipm9bGYXNPe2IiJNYWZuZvuE83eY2a8asm0jznOOmb3W2DildTC950xampltq7eYDlQANeHyZe7+SPSjEhHZkZm9Anzs7tfttP5k4E4gz92rd7OvA4PcfXEDztOgbc2sH7AMSNrdeaVtUsuZtDh3z6z7AJ8BJ9Zbt70wM7PE2EUpIsIDwLlmZjutPw94RAWSRIuKM4kZMzvCzArM7Gdmtha4z8w6mNmLZrbBzLaE83n19nnbzL4dzl9oZu+Z2V/CbZeZ2XGN3La/mb1rZsVm9oaZ3WZmD0fx1yEisfcc0Ak4tG6FmXUATgAmmdkHZrbVzNaY2a1mlryrg5jZ/Wb2u3rLV4f7rDazi3ba9mtm9qmZFZnZSjO7vt7X74bTrWa2zczG1+WyevtPMLNPzKwwnE6o993bZvZbM/tfmNteM7POjf/1SLSoOJNY6w50BPoClxL8Td4XLvcByoBb97D/gcACoDPwJ+CeXVz1NmTbR4GPCRLz9QRXyiLSjrh7GfAEcH691d8A5gPbgB8R5I/xwFHAFXs7pplNBH4CHAMMAo7eaZOS8Hy5wNeAy83slPC7w8Jpbnin4YOdjt0R+C/wT4Lc9Tfgv2bWqd5mZwPfAroCyWEsEudUnEms1QK/dvcKdy9z903u/rS7l7p7MXAjcPge9l/h7v929xqCWxI9gG5fZlsz6wMcAFzn7pXu/h4wqbl+QBFpVR4ATjez1HD5fOABd5/q7h+6e7W7Lyfog7an3FTnG8B97j7b3UsILv62c/e33X2Wu9e6+0zgPw08LgTF3CJ3fyiM6z8EheSJ9ba5z90X1is892/gsSWGVJxJrG1w9/K6BTNLN7M7zWyFmRURNOvnmllkN/uvrZtx99JwNvNLbtsT2FxvHcDKL/lziEgbEF6cbQROMbOBwDjgUTMbHHazWBvmpt8TtKLtTU92zCcr6n9pZgea2VthV45C4DsNPG7dsVfstG4F0Kve8tp686XsPj9KHFFxJrG28+PCVwFDgAPdPZvPm/V3d6uyOawBOppZer11vVvwfCIS3x4kaDE7F3jV3dcBtxO0Sg0Kc9MvaFheWsOO+aTPTt8/StBS39vdc4A76h13b69TWE3QBaS+PsCqBsQlcUzFmcSbLIJ+ZlvD/hS/bukTuvsKYApwvZklm9l4drwtICLty4MEfcMuIbjNCUFuKgK2mdlQ4PIGHusJ4EIzGxZeAO6c07IIWu7LzWwcQR+xOhsIun4M2M2xXwIGm9nZZpZoZt8EhgEvNjA2iVMqziTe3AykEdxW+BB4JUrnPYegk+8m4HfA4wTvYxORdibsU/Y+kMHn/U9/QlA4FQP/JsgRDTnWywR5bTKwOJzWdwVwg5kVA9cRFHN1+5YS9Lv9X/iU6EE7HXsTwZOkVxHkrp8CJ7j7xgb+qBKn9BJakV0ws8eB+e7e4i13IiIi9anlTAQwswPMbKCZJYSPvp9M8M4jERGRqNIb2UUC3YFnCN4VVABc7u6fxjYkERFpj3RbU0RERCSO6LamiIiISBxpM7c1O3fu7P369Yt1GCISRVOnTt3o7l1iHUdzUA4TaV/2lL/aTHHWr18/pkyZEuswRCSKzGznt6O3WsphIu3LnvKXbmuKiIiIxBEVZyIiIiJxpM3c1hSR3XN3qmudiupaKsNPRXVNOK39fH1NLRVVNVTWfL5d3fwO21XXUllTU+9YwbSq1qmtdWpqnRoP53eYQq3v6nu2r/vLGaM4fHCb6EYm0u5VVNdQXF4dfqooKgumxeXVFJVXURSuL6mopikvj3A+zy3VNU51bS01tU5VjYfTYLm6NviuOly/83KCGQkGZkZCAkTMSDDDjPA7IyEh2Kb+tpFw3fgBnfjxsUOa/HtTcSYSRTW1TllVDWWVwae0qnr7fEVYMFVU11JRVW++OiiYts9X14Tf73r7HQupcF1NbZMSX33JkQSSE8NPOJ8SLidGEogYYaIykhMTts9H6iW0SEKQ4CLb1xuRhGC/zpnJzROoiABBgbS1tIrNJZVsKa1kS0lVOK1kS2kVW8sqm5wf6oqworK6wisouiqqa/e6b2ZKIhkpESLWkHHkdy8hwUhMCHJKUiTIPYkJFuSlBCMlKYH0hIRgXYKRGDEiCQkkhftEEgz3oMir3T79fN7D4q/WgwveuvU1tb59P2viz1BHxZm0e9U1tZSFxU/5bqYVX1jecZvy6hpK6wquyprtBVhpZVh8VQXrG5KodsUMUhITSEmMBNOkevPh+tz05O1FUkpiZHvRlFKvkEpJqiuoIp+vr7dNSmICyZFIve12KsQiCSQkNE/yEZHGqa11Nm6rYE1hOWsKy9hQXMGW+sVXaVVYeAUFWEllzW6PlZmSSE5aEpEm/nednJhAVmoiOenJ9O6YTlZqEtmpiWSlJgbzaYlkpSTtuJyaRGZKYpPP3RapOJM2xd0pqaxhS0klm0oqdz8trWRzSfApLKtq9PkSDFKTIqQmRUhLipCWHCE9OZjvnJlMWnIaaUmJpIfrU5Mi2+fTkhNJS/p8fVpyvWIracfCKylizXZFJiLxqyYsvFZvLWNtYfn2AmxNYfn25XVF5VTXfrGpKys1kQ7pyXTISKZTZjKDumaSm55Mx4wkOmQkB9+lJ9MhI4mO6cnkpCeRkhiJwU8pe6PiTFqdLSWVLFxXzMJ1xSxYV8yKTaVs2hYWW6WVVO6mdSopYnQME1SnzGT265lNp4xkctOTyUxJJLWuNSqc1l9OrZuGRVPdNCmiZ2pEZPeqa2opKq+msKyKraXBxeD2T2kVW0qrWFccFl5by1hXXEHNToVXSmICPXPT6J6dyoH9O9IjN5XuOWn0yE6le04qXbNT6JCerHzUhqg4k7hVUlHNovXbWLg2KMIWritmwdpi1hdXbN8mKzWRAV0y6Zmbyn49s+mYmUzH9GQ6Znzxk5mSqNYnEWkyd2fl5jJmry5kxaZStpZVUlRWxdbSqrAIC6ZFZVUUV1Tv8VgZyRG6hUXW+IGd6ZETzPfMTaV7dho9clLJTU9S7mpnVJxJzFVU17Bkfcn2lrCFa4tZuL6YlZvLtm+TmpTAoK5ZHDqoC0O7ZzG4exZDumXRLTtFSUtEWkxtrbNsUwmzVxUyZ3URs1cVMntVIUXlnxddyZEEctKTyE1LIictiR45qQztkUVOWhK5acnkpCWG3yeTnZZEbnqwXXZqEsmJau2SL1JxJlFVVlnD3DVFzCrYysxVhcwqKGTpxpLtzfiJCcaALhmMysvlG2N7by/CendMV6dREWlR1TW1LN6wjdmrisJirJC5q4u2d6hPTkxg3+5ZnDCqJyN65TC8Zw4Du2aQlhTRRaI0KxVn0mIqqmuYv6Y4LMK2MrOgkEXrt20vxDpnpjAyL4ev7td9exHWv3OGriRFpMVVVteyYG0xs1cHLWGzVxcxf03R9ieq05MjDOuRzRn5vdmvZzbDe+WwT9dM9euSqFBxJs2isrqWheuKmbWqkJkFhcxatZUFa4upqgkKsQ7pSYzMy+WYYd0Y0SuHkXm5uiUpIlFRXVPLovXbmFVQyIyCrcxaVcj8NcVU1gSFWFZqIsN75nD++L4M75XDfj1z6N85Q631EjMqzqRRamqd95ds5LU565i5qpB5a4q2PyWZnZrIyLxcvn3oAEb2ymFEXg69ctNUiIlIi6updZZt3MaMlYXhxeJW5q4porwqLMRSEhneK4dvHdyPEXk5jOyVS++Oyk8SX2JSnJnZROAfQAS4291v2un7PsADQG64zTXu/lK045QvWr6xhKemFvD0tALWFJaTkRxheK8cLpzQL2wRy6FPx3QlOhFpce7Oik2lQWtYQSEzVxUyZ1Xh9j5iaUkRhvfK5pwD+zIyL4cRvXLo1ylDL1KWuBf14szMIsBtwDFAAfCJmU1y97n1Nvsl8IS7325mw4CXgH7RjlUC2yqqeWnWGp6aUsDHyzeTYHDooC5c+7V9OXrfbqQm6SWGIhI964vLuXXyYp77dNX2pyaTExMY1iOb08fmMSIvl5F5OQzskqlbk9IqxaLlbByw2N2XApjZY8DJQP3izIHscD4HWB3VCAV356Nlm3lySgEvz15DaWUN/TtncPVXh3DamDy656TGOkSRmFHrf2wUl1dx17tLuee9ZVRU13LSqJ4c2L8jI/JyGNwtS531pc2IRXHWC1hZb7kAOHCnba4HXjOz7wEZwNG7OpCZXQpcCtCnT59mD7Q9WrW1jKenFvDU1AI+21xKZkoiJ43qyelj8xjbt4NuV0q7p9b/6KuoruGhD1Zw21uL2VJaxddG9uAnxw6hf+eMWIcm0iLi9YGAs4D73f2vZjYeeMjMhrv7DuPyuPtdwF0A+fn5XxxoTBqkvKqGV2av5ampBfxvyUbcYfyATvzw6EFMHN6d9OR4/TMRiQm1/kdJTa3z7Ker+PvrC1m1tYxD9unMTycOYWRebqxDE2lRsfi/7iqgd73lvHBdfRcDEwHc/QMzSwU6A+ujEmE7MWd1IQ9/+BkvzlhNcUU1eR3S+MFRgzhtTB69O6bHOjyReKXW/xbm7kyev54/vbKABeuKGdErhz+eNpJDBnWOdWgiURGL4uwTYJCZ9Scoys4Ezt5pm8+Ao4D7zWxfIBXYENUo27Cqmlr+8cYi/vX2YpITEzh+eA9Oz8/joP6d9BSTSPNQ638jTV2xmZtens8ny7fQr1M6t549muOH91BuknYl6sWZu1eb2ZXAqwQdZe919zlmdgMwxd0nAVcB/zazHxHcHrjQ3ZW4msGSDdv40ePTmVlQyBlj8/jlCcPISUuKdVgirYla/1vAwnXF/OmVBbwxbx1dslL43SnD+eYBvdXJX9qlZinOzGwfgmb8NOAv7v7BnrYPn1p6aad119Wbnwsc3ByxScDdefijz7jxv3NJTYpwx7ljmDi8R6zDEmmN1PrfjFZtLePvry/k6WkFZCYn8pNjB3PRIf3V11XatUb99ZtZqruX11v1W+Cn4fwLwP5NjEua0YbiCn729Ewmz1/PYYO78OfTR9ItW6/CEGkMtf43jy0lldz21mIe/HAFAN8+pD9XHLEPHTKSYxyZSOw19tLkBTN7yN0fDJerCB4Td6CmOQKT5vH63HVc8/RMtlVUc/2Jw7hgQj+9DkOkidT63zQbiis47h//x+aSCk4bk8cPjxlMr9y0WIclEjcaW5xNBC43s1eA3wM/Ab5PcFvznGaKTZqgpKKa3/13Lv/5eCXDemTz2Jn7M6hbVqzDEhHhuudnU1RexbNXHMyo3rmxDkck7jSqOHP3GuBWM3sI+BVwOfBLd1/SnMFJ43z62RZ+9Ph0Vmwu5TuHD+THxwwmOVGdakUk9l6atYaXZ6/lpxOHqDAT2Y3G9jk7ELgaqCRoOSsDbjSzVcBv3X1rs0UoDVZdU8utby3mlsmL6Z6dymOXHMSBAzrFOiwREQA2l1Ry3fOzGdErh0sPHRDrcETiVmNva94JHA9kAve5+8HAmWZ2OPA48NVmik8aaPnGEn74+HSmr9zKqaN78ZuT9yM7Va/IEJH48ZsX5lBYVsXD3z6QRL0iQ2S3GlucVRM8AJBB0HoGgLu/A7zT9LCkodydxz9ZyQ0vziUxwbjlrNGcOKpnrMMSEdnB63PX8fz01fzw6EEM7Z699x1E2rHGFmdnA5cRFGbnN1848mVs2lbBNc/M4vW565gwsBN//cYoeuToiScRiS+FZVVc++wshnbP4ooj9ol1OCJxr7EPBCwkeI+PxMj8tUWce/fHFJVV8cuv7ctFB/fX8CYiEpdu/O9cNpVUcs8FB+jhJJEG0CuYW6HaWucXz8zC3Xn+yoPZt4duEYhIfHpn4QaemFLAFUcMZEReTqzDEWkVdAnTCj3z6SqmfbaVa44bqsJMROJWcXkVP396Jvt0zeT7Rw2KdTgirUaTijMzO9HMVOBFUWFZFTe9PI/RfXI5bUxerMMREdmtP74ynzVF5fzp9JGkJkViHY5Iq9HUwuqbwCIz+5OZDW2OgGTPbn5jIZtKKvntycPVx0xE4tYHSzbx8IefcfHB/RnTp0OswxFpVZpUnLn7ucBoYAlwv5l9YGaXmpnGCWoB89cW8eAHKzh7XB+G91LfDRGJT6WV1fzs6Zn065TOVccOiXU4Iq1Ok29JunsR8BTwGNADOBWYZmbfa+qx5XPuzq+fn0NWaiI/UbITkTj2l1cX8tnmUv542kjSknU7U+TLamqfs5PM7FngbSAJGOfuxwGj0Ks2mtULM9fw0bLNXP3VIXTISI51OCIiuzR1xWbue38Z54/vq+HjRBqpqa/SOA34u7u/W3+lu5ea2cVNPLaESiqqufG/cxneK5szD+gT63BERHapvKqGq5+aSc+cNH42Ud2QRRqrqcXZ9cCaugUzSwO6uftyd3+ziceW0D8nL2JdUQW3nzuWiB4CEJE4dfMbi1i6oYSHLz6QjBS9RlOksZra5+xJoLbeck24TprJ4vXbuPe9ZZwxNk9PPIlI3Jqxcit3vbuEMw/ozSGDOsc6HJFWranFWaK71x/4vBLYa4coM5toZgvMbLGZXbOL7/9uZtPDz0Iz29rEOFsld+c3L8whNSnCT3WLQETiVGV1LT99aiZds1L5xdf2jXU4Iq1eU9udN5jZSe4+CcDMTgY27mkHM4sAtwHHAAXAJ2Y2yd3n1m3j7j+qt/33CF7X0e68Omcd/7doI78+cRhdslJiHY6IyC7d+tZiFqwr5t4L88lOTYp1OCKtXlOLs+8Aj5jZrYABK4Hz97LPOGCxuy8FMLPHgJOBubvZ/izg102Ms9Upq6zhty/OZWj3LM47qG+swxER2aW5q4v411uL+froXhw5tFuswxFpE5pUnLn7EuAgM8sMl7c1YLdeBEVcnQLgwF1taGZ9gf7A5N18fylwKUCfPm3rKcbb31nCqq1lPH7pQSRGNEKWiMSfqpparn5qBrnpyVx34rBYhyPSZjT5cRoz+xqwH5BqFjxJ6O43NPW4oTOBp9y9ZldfuvtdwF0A+fn53kznjLkVm0q4450lnLx/T70nSCQOmdlE4B9ABLjb3W/a6fu/A18JF9OBru6eG9Ugo+Cud5cyZ3URd5w7ltx0vX9RpLk0qTgzszsIEs9XgLuB04GP97LbKqB3veW8cN2unAl8tykxtka/fXEuSQnGL45Xx1qReKN+s4FF64r5xxuL+NrIHkwc3j3W4Yi0KU29XzbB3c8Htrj7b4DxwOC97PMJMMjM+ptZMkEBNmnnjcKB1DsAHzQxxlZl8vx1vDFvPd8/ahDdslNjHY6IfNH2frPhE+p1/WZ35yzgP1GJLEpqap2rn5pJRkqE35y0X6zDEWlzmlqclYfTUjPrCVQRjK+5W+5eDVwJvArMA55w9zlmdoOZnVRv0zOBx9y9zdyu3Jvyqhp+88JcBnbJ4FsH9491OCKya7vqN9trVxs2pN+smU0xsykbNmxo9kBbyqMfrWD6yq1cf9J+dM7Uk+Qiza2pfc5eMLNc4M/ANMCBf+9tJ3d/CXhpp3XX7bR8fRNja3XueW8ZKzaV8tDF40hO1EMAIm1Am+s3W1Fdw21vLWFc/46cNKpnrMMRaZMaXZyZWQLwprtvBZ42sxeBVHcvbK7g2pNVW8u4ZfIijhvenUMHdYl1OCKye+263+yTUwpYW1TOX84YRd1DYCLSvBrdPOPutQSdYuuWK1SYNd6N/w36El+rt2uLxLt222+2qqaW299ewug+uRy8j54kF2kpTb139qaZnWa6fGqS9xZt5KVZa/nuEfuQ1yE91uGIyB60536zz05bxaqtZXz/yEFqNRNpQU3tc3YZ8GOg2szKCUYJcHfPbnJk7URldS2/njSbPh3TueSwAbEOR0QaoD32m62uqeW2txczolcORwxR1wuRltTUEQKymiuQ9uqB95ezZEMJ91yQT2pSJNbhiIjs0gszV7NiUyl3njdWrWYiLaypL6E9bFfr3f3dphy3vVhfVM7NbyzkqKFdOWpfjUknIvGppta5dfJihnbP4hjlKpEW19TbmlfXm08leDnjVODIJh63Xfj9S/OoqnGNSScice3l2WtYsqGEW88eTUKCWs1EWlpTb2ueWH/ZzHoDNzflmO3FR0s38dz01XzvyH3o2ykj1uGIiOxSbdhqNrBLBscN3+M7xkWkmTT3m04LAL0LYi+qamr59aQ59MpN44oj9ol1OCIiu/X6vHXMX1vMlUfuQ0StZiJR0dQ+Z7cQjAoAQaG3P8FIAbIH//6/pcxfW8xd540lLVkPAYhIfHJ3bpm8iL6d0jlxpEYDEImWpvY5m1Jvvhr4j7v/r4nHbNOWbyzhH28EIwEcu1/3WIcjIrJbby/YwOxVRfzptJEkRjSknEi0NLU4ewoorxs3zswiZpbu7qVND63tcXd+8ewskhMTuP6k/WIdjojIbrk7/5y8iF65aZw6ZpfjuotIC2nyCAFAWr3lNOCNJh6zzXpqagHvL9nENccNpVt2aqzDERHZrf8t3sSnn23l8iMGkqRWM5Goaup/canuvq1uIZzX+EO7sHFbBTe+NI/8vh0464A+sQ5HRGSP/jl5Ed2zUzkjPy/WoYi0O00tzkrMbEzdgpmNBcqaeMw26XcvzqWkopo/fH2E3hMkInHto6Wb+HjZZi47fAApiXpoSSTamtrn7IfAk2a2mmBcze7AN5saVFvzzsINPDd9NT84ahCDumnEKxGJb7dMXkznzBTOGqdWfpFYaOpLaD8xs6HAkHDVAnevanpYbUdpZTXXPjuLgV0yuOIrA2MdjojIHk37bAvvLd7IL44fqvF+RWKkSbc1zey7QIa7z3b32UCmmV3RPKG1DX9/fSEFW8r4w9dH6vaAiMS9W95cRIf0JM45sG+sQxFpt5ra5+wSd99at+DuW4BLmnjMNmP2qkLueW8ZZ43rw7j+HWMdjojIHs0qKOStBRv49qEDyEhpaq8XEWmsphZnETPb3rvdzCJA8t52MrOJZrbAzBab2TW72eYbZjbXzOaY2aNNjDPqqmtqueaZmXTKTOGa44bGOhwRkb26ZfIislMTOX+8Ws1EYqmpl0avAI+b2Z3h8mXhut0KC7jbgGMIxuL8xMwmufvcetsMAn4OHOzuW8ysaxPjjLr7/rec2auK+Nc5Y8hJS4p1OCIiezRvTRGvzV3HD44aRFaqcpZILDW1OPsZcClwebj8OvDvvewzDljs7ksBzOwx4GRgbr1tLgFuC2+T4u7rmxhnVK3cXMrfXl/I0ft25bjhGqJJROLfrW8tJjMlkYsO7h/rUETavSbd1nT3Wne/w91Pd/fTCQqsW/ayWy9gZb3lgnBdfYOBwWb2PzP70Mwm7upAZnapmU0xsykbNmxo7I/RrNyda5+bTYLBDScPp95dXxGRuLR4fTEvzVrD+eP7kpOuVjORWGvymBxmNtrM/mRmy4EbgPlNjipo0RsEHAGcBfzbzHJ33sjd73L3fHfP79KlSzOctukmzVjNuws3cPVXh9AzN23vO4iIxNhtby0hNTHCxYeo1UwkHjTqtqaZDSYoms4CNgKPA+buX2nA7quA3vWW88J19RUAH4XvTFtmZgsJirVPGhNvtGwpqeSGF+ayf+9czhvfL9bhiIjs1fKNJTw/fRUXH9KfTpkpsQ5HRGh8y9l84EjgBHc/xN1vAWoauO8nwCAz629mycCZwKSdtnmOoNUMM+tMcJtzaSNjjZobX5pHYVkVf/j6CCIaokmkzWpLT5z/6+3FJEUSuOSwAbEORURCjX0g4OsERdVbZvYK8BjB8E175e7VZnYl8CoQAe519zlmdgMwxd0nhd8da2ZzCYq+q919UyNjjYr3F2/kqakFXHHEQPbtkR3rcESkhbSlJ85Xbi7lmWmrOPegvnTNSo11OCISalRx5u7PAc+ZWQbBk5Y/BLqa2e3As+7+2l72fwl4aad119Wbd+DH4SfulVfV8PNnZ9GvUzrfP2pQrMMRkZbVZp44v+OdJSSYcdnhajUTiSdNfVqzxN0fdfcTCfqOfUrweo125Z9vLmLFplJ+f+oIjUUn0va1iSfO1xaW8+SUAk7Pz6NHjh5eEoknTX5as467bwmfnjyquY7ZGsxbU8Rd7y7l9LF5TNinc6zDEZH4EPdPnN/xzhJq3bn88IFRPa+I7F2zFWftUU2tc80zs8hJS+La4/eNdTgiEh0NfeJ8krtXufsyoO6J87iwvric/3z8GaeO7kXvjumxDkdEdqLirAke+mA5M1Zu5boTh9EhY69DiopI29Dqnzi/+/+WUVVTyxVf2SfWoYjILjR1+KZ2a/XWMv786gIOH9yFk0b1jHU4IhIlrfmJ88KyKv786nwe+egzTtm/F/07Z8Q6JBHZBRVnjeDu/Oq52dQ6/O4UDdEk0t60tifO3Z0XZq7hty/OZdO2Ci6c0I+fHDsk1mGJyG6oOPuSpq/cyj/fXMTk+eu59vh91V9DROLaik0l/PK52fzfoo2MzMvhvgsPYHivnFiHJSJ7oOKsgT5etplbJi/i/xZtJDc9iau/OoSLNA6diMSpiuoa7npnKbe+FYwA8JuT9uPcg/pq9BKRVkDF2R64O+8v2cQ/31zER8s20zkzmWuOG8q5B/UlM0W/OhGJTx8u3cS1z85iyYYSvjaiB9edOIxu2RoBQKS1UIWxC+7O2ws2cMvkRUz7bCvdslO47oRhnDWuD2nJesmsiMSnzSWV3PjfeTw9rYC8Dmncd+EBfGVoXI4cJSJ7oOKsntpa5/V567h18mJmrSqkV24avz1lOGeMzdOb/0UkbtXWOk9NLeD3L89jW3k1VxwxkO8dOUgXkyKtlIozgpfJvjRrDbe9tZj5a4vp2ymdP502klNG9yI5Ua+CE5H4tXBdMb98djYfL9/MAf06cOOpIxjcLSvWYYlIE7Tr4qy6ppZJM1Zz21uLWbKhhIFdMvj7N0dx4sieJEZUlIlI/CqrrOGWyYu4692lZKYm8sfTRnDG2N4kqMO/SKvXLouzyupanv20gH+9vYQVm0oZ2j2L284ew8Th3fUkk4jEvbcXrOdXz89m5eYyvj6mF9cevy+dMlNiHZaINJN2V5y5O6ff8T4zCwoZ0SuHu84by9H7dtPVpoi0Cve+t4wbXpzLgC4ZPHrJgUwY2DnWIYlIM2t3xZmZcfEh/clOS+KIwV30dn8RaVWOH9GD0spqLjlsACmJ6vAv0ha1u+IM4OT9e8U6BBGRRumek8qVRw6KdRgi0oLU611EREQkjqg4ExEREYkj5u6xjqFZmNkGYMWX2KUzsLGFwlEMikExRCeGvu7epSWDiZYvmcNa27+TYlAMiuGLdpu/2kxx9mWZ2RR3z1cMikExKIbWJh5+R4pBMSiGlotBtzVFRERE4oiKMxEREZE40p6Ls7tiHQCKoY5iCCiGQDzEEO/i4XekGAKKIaAYAs0SQ7vtcyYiIiISj9pzy5mIiIhI3FFxJiIiIhJH2l1xZmYTzWyBmS02s2ticP7eZvaWmc01szlm9oNox1AvloiZfWpmL8bo/Llm9pSZzTezeWY2PgYx/Cj8d5htZv8xs9QonPNeM1tvZrPrretoZq+b2aJw2iEGMfw5/LeYaWbPmllutGOo991VZuZmplG9d6IctkMsymHKYW0yh7Wr4szMIsBtwHHAMOAsMxsW5TCqgavcfRhwEPDdGMRQ5wfAvBidG+AfwCvuPhQYFe1YzKwX8H0g392HAxHgzCic+n5g4k7rrgHedPdBwJvhcrRjeB0Y7u4jgYXAz2MQA2bWGzgW+KyFz9/qKId9gXKYclh9bSaHtaviDBgHLHb3pe5eCTwGnBzNANx9jbtPC+eLCf5jjvpI7GaWB3wNuDva5w7PnwMcBtwD4O6V7r41BqEkAmlmlgikA6tb+oTu/i6weafVJwMPhPMPAKdEOwZ3f83dq8PFD4G8aMcQ+jvwU0BPK32RclhIOWw75bDP17WZHNbeirNewMp6ywXEIKnUMbN+wGjgoxic/maCP57aGJwboD+wAbgvvC1xt5llRDMAd18F/IXg6mYNUOjur0Uzhnq6ufuacH4t0C1GcdS5CHg52ic1s5OBVe4+I9rnbiWUwz53M8phymG716pzWHsrzuKGmWUCTwM/dPeiKJ/7BGC9u0+N5nl3kgiMAW5399FACS3fDL6DsE/EyQRJtieQYWbnRjOGXfHg/TYxazUys2sJbl09EuXzpgO/AK6L5nmlcZTDlMN2Rzms6TmsvRVnq4De9ZbzwnVRZWZJBEntEXd/JtrnBw4GTjKz5QS3RY40s4ejHEMBUODudVfcTxEkumg6Gljm7hvcvQp4BpgQ5RjqrDOzHgDhdH0sgjCzC4ETgHM8+i9BHEjwP5kZ4d9mHjDNzLpHOY54phwWUA4LKIftpK3ksPZWnH0CDDKz/maWTNBxclI0AzAzI+ijMM/d/xbNc9dx95+7e5679yP4HUx296hebbn7WmClmQ0JVx0FzI1mDAS3Ag4ys/Tw3+UoYte5eBJwQTh/AfB8tAMws4kEt4lOcvfSaJ/f3We5e1d37xf+bRYAY8K/FQkoh6EcVo9yWD1tKYe1q+Is7Ch4JfAqwR/wE+4+J8phHAycR3ClNz38HB/lGOLF94BHzGwmsD/w+2iePLzifQqYBswi+O+hxYf/MLP/AB8AQ8yswMwuBm4CjjGzRQRXwzfFIIZbgSzg9fDv8o4YxCB7oBwWd5TDlMNaJIdp+CYRERGRONKuWs5ERERE4p2KMxEREZE4ouJMREREJI4ktuTBwycn/kEwpMTd7n7TTt//GPg2wftINgAXufuK8Lsagg6OAJ+5+0l7Olfnzp29X79+zfsDiEhcmzp16kZ37xLrOJqDcphI+7Kn/NVixVm9MeCOIXic9BMzm+Tu9R81/pRgTLBSM7sc+BPwzfC7Mnffv6Hn69evH1OmTGme4EWkVTCzFbGOobkoh4m0L3vKXy15W3OvY8C5+1v13kXS4uNgiYiIiMS7lizOvuwYcBez4zhYqWY2xcw+NLNTdrWDmV0abjNlw4YNDQ7sw6WbWLy+uMHbi4jEiw3FFbw5bx21tXoNkkhb1aJ9zhoqHAssHzi83uq+7r7KzAYAk81slrsvqb+fu99F+MK9/Pz8BmeqXz8/hwXritm3RzYnjurBiSN70rtjejP8JCIiLevpaQXc9PJ8+nZK57yD+nJGfm9y0pJiHZaINKOWbDlr0BhwZnY0cC3BcAsVdevdfVU4XQq8DYxursAeungcvz5xGGlJCfzplQUc+qe3OPVf/+O+/y1jfVF5c51GRKTZXXxIf245azRdMlP43X/nMf4Pb/LL52axaJ3uBoi0FS02QoCZJQILCcb6WkUwJtzZ9YcaMbPRBENPTHT3RfXWdwBK3b3CzDoTDI9w8k4PE+wgPz/fG9OZduXmUl6cuYZJM1Yzb00RCQYHDejEiaN6ctzw7uSmJ3/pY4pIdJjZVHfPj3UczaExOWz2qkLuf385k2asprK6lkP26cwFE/px5NCuRBKshSIVkeawp/zVosM3heOt3UzwKo173f1GM7sBmOLuk8zsDWAEsCbc5TN3P8nMJgB3ArUErXs3u/s9ezpXY4uz+havL2bSjDW8MGM1yzaWkJhgHDa4CyeN6snRw7qRmRIXd4FFJNTei7M6m7ZV8NgnK3n4wxWsKSynd8c0zj+oH9/I701Oum55isSjmBVn0dQcxVkdd2fO6iImzVjNizNWs7qwnNSkBI4a2o0TR/XgiCFdSU2KNMu5RKTxVJztqLqmltfmruP+/y3n4+WbSUuKcMroXlw4oR9Dumc1U6Qi0hxUnDVBba0z7bMtTJqxmpdmrWHjtkoyUxKZOLw7V35lH/p1zmj2c4pIw6g42705qwt54P3lPD99NRXVtYwf0IkLJvTjmGHddMtTJA6oOGsm1TW1fLB0Ey/MWM2LM9dQVVPLRQf358oj9yErVbcORKJNxdnebSmp5LFPVvLQB8tZXVhOr9w0zhvfl3MO7KO8JRJDKs5awPqicv786gKemlZAp4xkfnLsEM7I760rUpEoUnHWcNU1tbwxbx33/W85Hy3bTN9O6dxx7lj27ZHdYucUkd3bU/7SwOeN1DU7lT+fMYpJ3z2Efp0yuOaZWZx4y3t8uHRTrEMTEfmCxEgCE4f34PHLxvPEZeMpq6zh1H/9j+c+/cIbjkQkxlScNdGIvBye/M54bjlrNIVlVZx514d856GpfLapdO87i4jEwLj+HXnx+4cwslcuP3x8OtdPmkNldW2swxKRkIqzZmBmnDiqJ29edThXHTOYdxZu4Oi/vcMfX5nPtorqWIcnIvIFXbNSeeSSA7n4kP7c//5yzv73h6zTS7hF4oKKs2aUmhThe0cN4q2fHMEJI3tw+9tLOOLPb/PEJys1Dp6IxJ2kSAK/OmEY/zxrNHNWF3HCLe/x8bLNsQ5LpN1TcdYCuuek8rdv7s+zV0ygd8c0fvr0TE66TUlPROLTSaN68vyVB5OZksjZ//6Qe99bRlt5WEykNVJx1oJG9+nAM5dP4B9n7s+mbZV8484P+O6j01i5Wf3RRCS+DO6WxfNXHsxXhnblhhfn8oPHplNaqW4ZIrGg4qyFmRkn79+LN686nB8cNYg3563jqL+9w19eXUCJ+qOJSBzJTk3iznPHcvVXh/DCzNWcetv7LNtYEuuwRNqdL1WcmVmCmemlOI2QnpzIj44ZzOSrjuC44d259a3FnPqv/6kDrojElYQE47tf2YcHvjWO9cXlnHTLe7wxd12swxJpV/ZanJnZo2aWbWYZwGxgrpld3fKhtU09c9P4x5mjefCicazaUsZpt7/Pcl2ZikicOWxwF1743iH065zBtx+cwl9fW0CNHmwSiYqGtJwNc/ci4BTgZaA/cF5LBtUeHDa4C49echAlFdWcfscHzF1dFOuQRER2kNchnSe/M55v5Odxy+TFfOv+T9hSUhnrsETavIYUZ0lmlkRQnE1y9ypAl0/NYFTvXJ78zniSIsY37/qAT5braU4RiS+pSRH+dPoo/vD1EXy4ZBMn3voes1cVxjoskTatIcXZncByIAN418z6AmrmaSb7dM3iqcsn0CUzhfPu+Yi35q+PdUgiIl9w1rg+PPGd8dTWOl+//X2enLIy1iGJtFl7Lc7c/Z/u3svdj/fACuArUYit3eiVm8aT3xnPPl0zueTBKRrrTkTi0v69c3nhe4dwQL8OXP3UTP7z8WexDkmkTWrIAwE/CB8IMDO7x8ymAUdGIbZ2pVNmCv+55CDy+3Xgh49P54H3l8c6JBGRL+iUmcJ9F47j8MFduPbZWbwye02sQxJpcxpyW/Oi8IGAY4EOBA8D3NSiUbVTWalJ3P+tcRwzrBu/njSHm99YqLd0i0jcSU5M4PZzx7B/71y+/5/pvL94Y6xDEmlTGlKcWTg9HnjI3efUWyfNLDUpwu3njOH0sXnc/MYirp80R+NyikjcSU9O5N4LD6Bf53QueXAKswr0kIBIc2lIcTbVzF4jKM5eNbMsoLZlw2rfEiMJ/Om0kXz7kP488MEKfvTEdKpq9CsXkfiSm57MgxcdSG56Mhfc9zFLNmyLdUgibUJDirOLgWuAA9y9FEgGvtWiUQkJCca1X9uXq786hOenr+bSB6dQVlkT67BERHbQPSeVh799IAacf8/HrCksi3VIIq1eQ57WrAXygF+a2V+ACe4+s8UjE8yCYVRuPHU4by/cwPn3fkRhWVWswxJpF8xsopktMLPFZnbNLr7/sZnNNbOZZvZm+Jqhuu8uMLNF4eeC6EYeff07Z/DAReMoLKvi/Hs+1otqRZqoIU9r3gT8AJgbfr5vZr9v6cDkc+cc2JdbzhrN9JVb+eadH7C+WONxirQkM4sAtwHHAcOAs8xs2E6bfQrku/tI4CngT+G+HYFfAwcC44Bfm1mHaMUeK8N75XDX+WNZsamUix74hNLK6liHJNJqNeS25vHAMe5+r7vfC0wETmjIwXXl2XxOGNmTuy84gBWbSjnjjg9Yubk01iGJtGXjgMXuvtTdK4HHgJPrb+Dub4VdPQA+JLjDAPBV4HV33+zuW4DXCfJmmzdhYGf+edZoZqzcyncenkZltfrKijRGQ4ozgNx68zkN2UFXns3v8MFdeOSSA9laWsVpt7/P/LUaqEGkhfQC6r8CvyBctzsXE4w9/KX2NbNLzWyKmU3ZsGFDE8KNHxOHd+cPXx/Buws3cNWTM/S0uUgjNKQ4+wPwqZndb2YPAFOBGxuwn648W8CYPh144rLxAHzzzg81xp1IjJnZuUA+8Ocvu6+73+Xu+e6e36VLl+YPLka+eUAffjZxKC/MWM31L8zR+xpFvqSGPBDwH+Ag4BngaWA8wVibe9PiV55t8aqzIYZ0z+LpyyeQkRzhvHs+YuG64liHJNLWrAJ611vOC9ftwMyOBq4FTnL3ii+zb1v3ncMHcMmh/XnwgxX8481FsQ5HpFVp0G1Nd1/j7pPCz1rgyeYMorFXnm31qrMhendM59FLDiIpksDZ//6IpXq/kEhz+gQYZGb9zSwZOBOYVH8DMxsN3ElQmK2v99WrwLFm1iHsjnFsuK5dMTN+cfy+21+o/dAHy2Mdkkir0dA+ZztryAgBuvJsYf06Z/DoJQfi7pxz90d6SECkmbh7NXAlQVE1D3jC3eeY2Q1mdlK42Z+BTOBJM5tuZpPCfTcDvyUo8D4BbgjXtTtmxk1fH8HR+3bjuklzmDRjdaxDEmkVrDF9AczsM3fvs5dtEoGFwFEEhdUnwNnh8E9124wmeBBgorsvqre+I0HftjHhqmnA2D0luPz8fJ8yZcqX/lnagrmrizjr3x+SnZbIE5eNp0dOWqxDEokKM5vq7vmxjqM5tOUcVl5Vw/n3fsy0FVu458IDOHxw+7rTIbIre8pfu205M7MXzGzSLj4vAJ32dlJdeUbPsJ7ZPHjROLaWVHHOvz/Se9BEJK6kJkW4+4J8BnXL4jsPTWXaZ1tiHZJIXNtty5mZHb6nHd39nRaJqJHa8lVnQ01Zvpnz7/2YvA5pPHbpeDpmJMc6JJEWpZaz1mV9cTln3PEBhWVVPHnZeAZ1y4p1SCIx06iWM3d/Z0+flgtXGiu/X0fuPj+fFZtKOe+ejygs1VBPIhI/umal8tBFB5IUSeC8ez6mYIv6yYrsSmMfCJA4NWGfztx53lgWrivmgvs+ZluFhlARkfjRp1M6D140jtLKas65+yPWFakbhsjOVJy1QUcM6cqtZ49h1qpCLrr/E8oqa2IdkojIdvv2yOb+i8axsbiCc+7+iE3bKva+k0g7ouKsjfrqft25+Zv7M2X5Zi55cArlVSrQRCR+jOnTgXsuPICCLaWce8/H6oYhUs9ei7PdPLX5kJn9wMxSoxGkNM6Jo3ryp9NH8d7ijVzxiAYhFpH4ctCATtx5Xj5L1m/j/Ps+prhcBZoINKzlbCmwDfh3+CkCioHB4bLEsdPH5vG7U4Yzef56fvDYp1TXqEATkfhx+OAu3Hr2aGavKuTi+6eoG4YIDSvOJrj72e7+Qvg5FzjA3b/L5y+JlTh27kF9+dUJw3h59lp+8uQMamo1CLGIxI9j67phrNjMpQ+pG4ZIQ4qzTDPbPhpAOJ8ZLla2SFTS7C4+pD9Xf3UIz01fzbXPzqJWBZqIxJETR/Xkj6eN5P8WbeTKR6dRpVZ+accSG7DNVcB7ZraEYEzN/sAVZpYBPNCSwUnz+u5X9qG8qoZbJi8mNSnCr08chllDhkkVEWl5Z+T3pryqhl89P4cfPjadf5y5P4kRPbcm7c9eizN3f8nMBgFDw1UL3L3uxTQ3t1Rg0jJ+fMxgyipruPu9ZaQkJXDNxKEq0EQkbpw3vh/lVbXc+NI8UpIS+Mvpo0hIUI6S9qUhLWcAY4F+4fajzAx3f7DFopIWY2Zc+7V9qaiu5c53lmIYP5s4RAWaiMSNSw4bQFlVDX97fSFpSRF+d8pw5ShpV/ZanJnZQ8BAYDpQ10vTARVnrZSZ8ZuT9qPWnTveWcL6onJuOm0kyYm6fSAi8eF7R+5DaWUNd7yzhNSkCL/82r4q0KTdaEjLWT4wzHc3Qrq0SgkJxu9OGU6PnFT+8tpC1hWXc/u5Y8lOTYp1aCIimAWt+uVVNdzz3jLSkyNcdeyQWIclEhUNaSqZDXRv6UAk+syMK48cxF/PGMVHSzfzjTs+YE1hWazDEhEBghx13QnD+GZ+b26ZvJjb3loc65BEoqIhLWedgblm9jGwfQA0dz+pxaKSqDptbB5ds1O4/OFpfP1f73P/t8YxpHtWrMMSESEhwfj910dQXl3Dn19dQFpShIsO6R/rsERaVEOKs+tbOgiJvUMHdeGJy8bzrfs/5vQ73ufO88YyYWDnWIclIkIkwfjrGaOoqKrlhhfnkpYc4axxffa+o0grtdfbmu7+zq4+0QhOomtYz2yeueJgumencsG9H/P89FWxDklEBIDESAL/PGs0Rwzpwi+encWznxbEOiSRFrPb4szM3gunxWZWVO9TbGZF0QtRoqlXbhpPfWcCY/p04AePTef2t5egZ0FEJB4kJyZwx7ljOah/J656YgYvzVoT65BEWsRuizN3PyScZrl7dr1PlrtnRy9Eibac9CQevHhcMJzKK/O57vk5Go9TROJCalKEuy/IZ3SfDlz56DTufEcXkNL2NOjFVmYWMbOeZtan7tPSgUlspSRG+Mc39+eywwfw0Icr+M7DUymr1GDEIhJ7GSmJPHjROI4b0YM/vDyf7z46jW0V1bEOS6TZ7LU4M7PvAeuA14H/hp8XWzguiQMJCcbPj9uX35y0H2/MW8dZ//6QTdsq9r6jiEgLy0hJ5NazRvOL44fyyuy1nHrb/1iyYVuswxJpFg1pOfsBMMTd93P3EeFnZEsHJvHjggn9uP2cscxbU8Rpt7/P8o0lsQ5JRAQz49LDBvLwxQeyqaSSU279H6/NWRvrsESarCHF2UqgsKUDkfg2cXh3Hr3kIArLqvj67e/z6WdbYh2SSIsys4lmtsDMFpvZNbv4/jAzm2Zm1WZ2+k7f1ZjZ9PAzKXpRt08T9unMC987hP5dMrj0oan89bUF6icrrVpDirOlwNtm9nMz+3HdpyEHV3JrW8b27cDTl08gMyWRs/79Ia/PXRfrkERahJlFgNuA44BhwFlmNmynzT4DLgQe3cUhytx9//CjF3ZHQa/cNJ64bPz20QQuuv8TtpZWxjoskUZpSHH2GUF/s2Qgq95nj5Tc2qYBXTJ55ooJDOmWxWUPTeHBD5brSSlpi8YBi919qbtXAo8BJ9ffwN2Xu/tMoDYWAcoXpSZF+OPpI/n9qSN4f8lGTrz1Peas1o0faX0a8hLa3+zq04BjK7m1UZ0zU/jPpQfxlSFdue75OVxw3yes2KR+aNKm9CLo0lGnIFzXUKlmNsXMPjSzU3a3kZldGm43ZcOGDY0MVXZ29oF9eOKy8VRVO6fd/r5eWCutzp5eQntzOH3BzCbt/GnAsVs8uSmxxU56ciJ3nZ/P9ScOY9qKLRzz93f555uLqKjW6zZEgL7ung+cDdxsZgN3tZG73+Xu+e6e36VLl+hG2MaN7tOBF753CKPycvnR4zO4ftIcqmrUDiCtw57G1nwonP4lGoHsQl93X2VmA4DJZjbL3ZfU38Dd7wLuAsjPz9e9tSiLJBgXHtyf40b04IYX5/K31xfy3Ker+N0pw5mwj8bllFZtFdC73nJeuK5B3H1VOF1qZm8Do4Ele9xJml2XrBQe/vaB/PHl+dz93jLmrC7ktrPH0DU7NdahiezRnkYImBpOGzu2ZrMlN+BtguQmcahbdiq3nT2GBy4aR407Z9/9ET987FM2FOudaNJqfQIMMrP+ZpYMnAk06MEkM+tgZinhfGfgYGBui0Uqe5QUSeCXJwzjn2eNZvaqIk645T2mrtgc67BE9qghL6EdZGZPmdlcM1ta92nAsZXc2pnDB3fh1R8exveP3If/zlrDkX99m4c+XKFH2qXVcfdq4ErgVWAe8IS7zzGzG8zsJAAzO8DMCoAzgDvNbE64+77AFDObAbwF3OTuyl8xdtKonjz73QmkJUc4864PeUgPM0kcs739cYYDoP8a+DtwIvAtIMHdr9vrwc2OB24GIsC97n6jmd0ATHH3SWZ2APAs0AEoB9a6+35mNgG4k+BBgQTgZne/Z0/nys/P9ylTpuwtJImSJRu28avnZvP+kk2M6p3LjacMZ3ivnFiHJW2MmU0N+3a1esph0VFYVsWPHp/O5PnrOW1MHr89ZT/Sk/fUw0ekZewpfzWkOJvq7mPDPl8j6q9rgVgbTYkt/rg7z09fze/+O5fNJZVcOKE/Pz52MJkpSoTSPFScSWPU1jr/nLyIm99YRKeMZC45bADnHdSXDOUmiaI95a+GvOeswswSgEVmdqWZnQpkNmuE0iaZGaeM7sWbPz6Cs8b14b73l3HUX9/mpVlrdDtBRGImIcH44dGDefryCQzrmc1NL8/nkD9O5ra3FlNcXhXr8EQaPLZmOvB9YCxwLnBBSwYlbUtOehI3njqCZy6fQKeMFK54ZBoX3vcJn20qjXVoItKOje3bgYcuPpBnrpjAqN65/PnVBRzyx7e45c1FFKlIkxja423N8C3/f3T3n0QvpMbRLYHWobqmlgc+WMHfXltAda3zvSP34duHDiA1KRLr0KQV0m1NaU4zVm7ln28u4s3568lOTeSiQ/rzrYP7k5OWFOvQpA1qVJ8zM0t092oz+9DdD2rRCJuBElvrsrawnBtenMNLs9aSm57EKfv34oz8PPbrqYcGpOFUnElLmL2qkH+8uYjX564jKyWRbx3cj4sO6U9uenKsQ5M2pLHF2TR3H2NmtxO82f9JYPsYPe7+TEsE21hKbK3T+0s28uhHn/HanHVU1tSyX89svpHfm5P376lEKHul4kxa0pzVhdzy5mJembOWzJRELpjQl4sPGUDHDOUmabqmFmf31VvtgAHu7hc1f6iNp8TWum0treT56at5YspK5qwuIjmSwDH7deMb+b05ZJ/ORBIs1iFKHFJxJtEwf20Rt7y5mJdmryEtKcL54/txyaH96ZSZEuvQpBVrbHFWAPyNsBgLp3Xc3f/W3IE2hRJb2zFndSFPTinguemr2FpaRY+cVE4bk8cZ+Xn07ZQR6/Akjqg4k2hauK6YWyYv5sWZq0lNjHDe+L58+9D+dM3ScFDy5TW2OFsD3M6ORVkdd/cbmi/EplNia3sqqmt4c956npiykncXbqDW4cD+HflGfm+OG9FdL44UFWcSE4vXb+PWyYuYNGM1AGP6dOArQ7ty1L5dGdItCzO19MveNem2ZotG1oyU2Nq2tYXlPD2tgCenrGT5plIyUxI5YWQPzsjvzZg+uUqG7ZSKM4mlpRu28dz01Uyev47Zq4oA6JmTypH7duXIoV2ZMLCznkSX3Wpscfapu7eawcaV2NoHd+eT5Vt4YspKXpq1htLKGvp2SufA/h0Z27cDY/t2ZGCXDBVr7YSKM4kX64rKeWv+eibPX897izdSWllDalICEwZ25sihQbHWMzct1mFKHGlscdbR3Te3aGTNSImt/dlWUc1LM9fw2ty1TF2xhS2lwUsjc9OTGNunA2P7dSC/b0dG5uXo6rWNUnEm8aiiuoaPlm5m8vz1vDl/HSs3lwEwtHsWR4a3P/fv3UEPOrVzTRpbs7VQYmvf3J0lG0qYtmILU1ZsZsqKLSzdELz5JSli7Nczh7F9O5DfNyja1IG3bVBxJvEuyE3bgkJt3nqmrNhCTa3TIT2JI4Z05StDuzK6dy69ctNIULHWrqg4k3Zpc0llWKxtYdqKLcwo2EpFdS0AvTumkd+37lZoB/bpmklSpCGjmUk8UXEmrU1hWRXvLtzAW/PX89aC9dtb/DNTEhncLZOhPbIZ2j2Lod2zGdI9S6MTtGEqzkSAyupaZq8uDAq25UHRtnFbBQCRBKN3hzT6d86gX+cM+oeffp0y6JmbptsPcUrFmbRmNbXO7FWFzF1TxPw1RcxfW8z8tcUUln0+rmfPnFSGdM/aoWgb0CVDF5NtwJ7yl95FIO1GcmICY/p0YEyfDnz70OB2w8rNZUz7bAuL129j2cYSlm0s4cOlmymrqtlhv74d07cXbPULuK5ZKXr4QEQaJZJgjOqdy6jeudvXuTvriiqYt7aI+WuKWbA2KNreW7yRqpqgMSUpYgzsksm+PYLWtYFdMumRk0q37FQ6ZSTr9mgboOJM2i0zo0+ndPp0St9hvbuzvriCpRtKWL6phOUbS1gaFm5vL9hAZU3t9m3TkyP065RB307pdMtOpUtWCt2yU+mWnULXrGCak5akAk5EGsTM6J6TSvecVL4ypOv29ZXVtSzduI0Fa4uZFxZtHy7dxLOfrtph/6SI0TUr2L97dlCw9chJpVu43CMnla7ZKaQk6iGpeKbiTGQnZhYWWKmMH9hph+9qap3VW8tYvqlke0vbso0lLFwXXNkWl1d/4XjJiQl0zUqha1i4dc1KoWs4rTtP16ygiNMVr4jsSnJiAkO7ZzO0ezYn7//5+sLSKpZvKmFtUTnrispZU1jOusJy1haVM29NEW8tWE9pZc0XjtcxI5nu2UER1y07lY4ZSXRITyY3PZnctCQ6ZCRtn89JSyJRt1GjSsWZyJcQSTB6d0ynd8d0Dh3U5Qvfl1XWsL64nHVFFZ9Pi8pZX1zBuqJyFq3fttsiLsEgJ60uQYaJMT1Y7rDT8ufrk0lNSlDLnEg7lZOexKj0XEbt5nt3p7iimrWF5cGnKCje1hR9XsTNLNjKltIqamp33wc9OzWR3DAX5YTTDunJYc4K8lNOWhLZaUnkpCWG0yS10DWSijORZpSWHKFvp4y9jgG6qyJuS0klW8sq2VJaxdbSStYWlrNgbTFbSit3eeVbJzkxIUiOaclkpiaSlZpIVmpSOE0kOzWJzJQvrs9K+XxeV8UibZOZkZ2aRHZqEoO7Ze12u7oibmtJFVtKK9laFuShIC9VsbU0XB/mp+UbS9haWknRLi4060tNSiAnLNSyU5M+n0/74nxmSmLwSU0kIyVCZkoiaUmRdnnxqeJMJAYaWsTVqaiuobC0ii3bE2RlmCzDBFpaSWFZFcXl1WzaFiTObRXVFJVXU1ldu9fjpyVFyEoNEmN6SoT05HA+OUJGcrAuWA6SZvB9ZKflRNKSI6QlBR/dohVpPeoXcTv3w92T6ppaCsuq2FpWRVFZFYXhp26+qLyawtLP168pLGfBuuLt+WpvEgwy6oq2lMQvzGeFhVzd+l3lpvo5LCWxddxpUHEm0gqkJEbomh2ha/aXf3luRXUNxeXV4adqj/MlldWUVtZQUlHN+uJySitqKKmspiScfpk376QkJuxQrKUmRUhPjpCWHMzXrU8L19UtHzOsG/06N6xoFZHYSowk0CkzhU6ZKV9635pap7i8rpirpriiKsg1FdUUV1RTUlHNtvJqtlUEn5KKz+fXF5dv/66ksmaPt2TrSzC2F2t10+0Xl0kREiNGxIyEhGAaCZcjCZ9/EsxITPh8m8RIsC6SAAM6Z3L0sG5f+nexMxVnIm1cSmKElMwInRuRPOtzd8qrasNiLSjYSiuDxFgSJs7SyhrKq2ooq6qhrHLHad36bRXVbCiu2GG78qra7U/BDuiSoeJMpB2IJFjYlza5Scepn5vqLihLK6vZVlFDaVi8lVbWy1n1clfwfTUbt1VQGhZ51bW11NZCdW0tNbVQ6051TS21HhSUNbVOjfsuC8LjR3RXcSYi0WNm21u5mlro7UpVTS3lVTXqQCwiX0r93ERm9M7r7l8o2JqrN4eKMxGJC0mRBL31XERaDTMjYrTICDLKhCIiIiJxRMWZiIiISBxpMwOfm9kGYMWX2KUzsLGFwlEMikExRCeGvu7+xbcBt0JfMoe1tn8nxaAYFMMX7TZ/tZni7Msysym7Gw1eMSgGxdC+Y4h38fA7UgyKQTG0XAy6rSkiIiISR1SciYiIiMSR9lyc3RXrAFAMdRRDQDEE4iGGeBcPvyPFEFAMAcUQaJYY2m2fMxEREZF41J5bzkRERETijoozERERkTjS7oozM5toZgvMbLGZXROD8/c2s7fMbK6ZzTGzH0Q7hnqxRMzsUzN7MUbnzzWzp8xsvpnNM7PxMYjhR+G/w2wz+4+ZpUbhnPea2Xozm11vXUcze93MFoXTDjGI4c/hv8VMM3vWzHKjHUO9764yMzezzi0ZQ2ukHLZDLMphymFtMoe1q+LMzCLAbcBxwDDgLDMbFuUwqoGr3H0YcBDw3RjEUOcHwLwYnRvgH8Ar7j4UGBXtWMysF/B9IN/dhwMR4MwonPp+YOJO664B3nT3QcCb4XK0Y3gdGO7uI4GFwM9jEANm1hs4Fvishc/f6iiHfYFymHJYfW0mh7Wr4gwYByx296XuXgk8BpwczQDcfY27Twvniwn+Y+4VzRgAzCwP+Bpwd7TPHZ4/BzgMuAfA3SvdfWsMQkkE0swsEUgHVrf0Cd39XWDzTqtPBh4I5x8ATol2DO7+mrtXh4sfAnnRjiH0d+CngJ5W+iLlsJBy2HbKYZ+vazM5rL0VZ72AlfWWC4hBUqljZv2A0cBHMTj9zQR/PLUxODdAf2ADcF94W+JuM8uIZgDuvgr4C8HVzRqg0N1fi2YM9XRz9zXh/FqgW4ziqHMR8HK0T2pmJwOr3H1GtM/dSiiHfe5mlMOUw3avVeew9lacxQ0zywSeBn7o7kVRPvcJwHp3nxrN8+4kERgD3O7uo4ESWr4ZfAdhn4iTCZJsTyDDzM6NZgy74sH7bWLWamRm1xLcunokyudNB34BXBfN80rjKIcph+2OcljTc1h7K85WAb3rLeeF66LKzJIIktoj7v5MtM8PHAycZGbLCW6LHGlmD0c5hgKgwN3rrrifIkh00XQ0sMzdN7h7FfAMMCHKMdRZZ2Y9AMLp+lgEYWYXAicA53j0X4I4kOB/MjPCv808YJqZdY9yHPFMOSygHBZQDttJW8lh7a04+wQYZGb9zSyZoOPkpGgGYGZG0Edhnrv/LZrnruPuP3f3PHfvR/A7mOzuUb3acve1wEozGxKuOgqYG80YCG4FHGRm6eG/y1HErnPxJOCCcP4C4PloB2BmEwluE53k7qXRPr+7z3L3ru7eL/zbLADGhH8rElAOQzmsHuWwetpSDmtXxVnYUfBK4FWCP+An3H1OlMM4GDiP4Epvevg5PsoxxIvvAY+Y2Uxgf+D30Tx5eMX7FDANmEXw30OLD/9hZv8BPgCGmFmBmV0M3AQcY2aLCK6Gb4pBDLcCWcDr4d/lHTGIQfZAOSzuKIcph7VIDtPwTSIiIiJxpF21nImIiIjEOxVnIiIiInFExZmIiIhIHFFxJiIiIhJHVJyJiIiIxBEVZ9JmmdkRZvZirOMQEfmylL/aNxVnIiIiInFExZnEnJmda2Yfhy8NvNPMIma2zcz+bmZzzOxNM+sSbru/mX1oZjPN7NlwbDnMbB8ze8PMZpjZNDMbGB4+08yeMrP5ZvZI+BZtzOwmM5sbHucvMfrRRaSVU/6SlqDiTGLKzPYFvgkc7O77AzXAOUAGMMXd9wPeAX4d7vIg8DN3H0nwRuy69Y8At7n7KIKx5daE60cDPwSGAQOAg82sE3AqsF94nN+15M8oIm2T8pe0FBVnEmtHAWOBT8xserg8AKgFHg+3eRg4xMxygFx3fydc/wBwmJllAb3c/VkAdy+vN67ax+5e4O61wHSgH1AIlAP3mNnXgaiPwSYibYLyl7QIFWcSawY84O77h58h7n79LrZr7DhjFfXma4DEcHzCcQRj0p0AvNLIY4tI+6b8JS1CxZnE2pvA6WbWFcDMOppZX4K/zdPDbc4G3nP3QmCLmR0arj8PeMfdi4ECMzslPEaKmaXv7oRmlgnkuPtLwI+AUS3wc4lI26f8JS0iMdYBSPvm7nPN7JfAa2aWAFQB3wVKgHHhd+sJ+nUAXADcESavpcC3wvXnAXea2Q3hMc7Yw2mzgOfNLJXgyvfHzfxjiUg7oPwlLcXcG9vaKtJyzGybu2fGOg4RkS9L+UuaSrc1RUREROKIWs5ERERE4ohazkRERETiiIozERERkTii4kxEREQkjqg4ExEREYkjKs5ERERE4sj/A0JlvdChqCYwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history3.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8578023910522461 | 0.9286025762557983 |\n",
      "|  2   | 0.8504155278205872 | 0.9310996532440186 |\n",
      "|  3   | 0.8448753356933594 | 0.931586503982544  |\n",
      "|  4   | 0.8180978894233704 | 0.8994466066360474 |\n",
      "|  5   | 0.8591874241828918 | 0.9380176663398743 |\n",
      "|  6   | 0.8453370332717896 | 0.9204404354095459 |\n",
      "|  7   | 0.8421052694320679 | 0.9210142493247986 |\n",
      "|  8   | 0.8545706272125244 | 0.9357939958572388 |\n",
      "|  9   | 0.8692840933799744 | 0.9483535885810852 |\n",
      "|  10  | 0.8494226336479187 | 0.927574098110199  |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY3)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC3)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 9\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY3.index(max(VALIDATION_ACCURACY3))\n",
    "max_fold3 = idx + 1\n",
    "print(\"Best Fold:\", max_fold3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 934us/step - loss: 0.1298 - accuracy: 0.8109 - auc: 0.8988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1297912746667862, 0.8109230995178223, 0.8987582921981812]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.load_weights(\"\\saved_models3/model_\"+str(max_fold3)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model3.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 773us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model3.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat3 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 1 - More Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.2424 - accuracy: 0.5528 - auc: 0.6339\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61173, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2420 - accuracy: 0.5544 - auc: 0.6389 - val_loss: 0.2317 - val_accuracy: 0.6117 - val_auc: 0.7618\n",
      "Epoch 2/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.2227 - accuracy: 0.7007 - auc: 0.7904\n",
      "Epoch 2: val_accuracy improved from 0.61173 to 0.77193, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2224 - accuracy: 0.7026 - auc: 0.7908 - val_loss: 0.2086 - val_accuracy: 0.7719 - val_auc: 0.8290\n",
      "Epoch 3/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1968 - accuracy: 0.7854 - auc: 0.8396\n",
      "Epoch 3: val_accuracy improved from 0.77193 to 0.80425, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1963 - accuracy: 0.7860 - auc: 0.8400 - val_loss: 0.1799 - val_accuracy: 0.8042 - val_auc: 0.8636\n",
      "Epoch 4/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.8135 - auc: 0.8724\n",
      "Epoch 4: val_accuracy improved from 0.80425 to 0.82687, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1675 - accuracy: 0.8131 - auc: 0.8720 - val_loss: 0.1537 - val_accuracy: 0.8269 - val_auc: 0.8839\n",
      "Epoch 5/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.8315 - auc: 0.8897\n",
      "Epoch 5: val_accuracy improved from 0.82687 to 0.83703, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1446 - accuracy: 0.8315 - auc: 0.8897 - val_loss: 0.1361 - val_accuracy: 0.8370 - val_auc: 0.8958\n",
      "Epoch 6/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.8414 - auc: 0.8992\n",
      "Epoch 6: val_accuracy improved from 0.83703 to 0.84488, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1306 - accuracy: 0.8414 - auc: 0.8992 - val_loss: 0.1267 - val_accuracy: 0.8449 - val_auc: 0.9020\n",
      "Epoch 7/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1232 - accuracy: 0.8458 - auc: 0.9053\n",
      "Epoch 7: val_accuracy improved from 0.84488 to 0.84580, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1232 - accuracy: 0.8455 - auc: 0.9052 - val_loss: 0.1219 - val_accuracy: 0.8458 - val_auc: 0.9057\n",
      "Epoch 8/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.8471 - auc: 0.9089\n",
      "Epoch 8: val_accuracy did not improve from 0.84580\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1193 - accuracy: 0.8470 - auc: 0.9087 - val_loss: 0.1193 - val_accuracy: 0.8458 - val_auc: 0.9086\n",
      "Epoch 9/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.8477 - auc: 0.9118\n",
      "Epoch 9: val_accuracy did not improve from 0.84580\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.8478 - auc: 0.9118 - val_loss: 0.1180 - val_accuracy: 0.8453 - val_auc: 0.9103\n",
      "Epoch 10/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1157 - accuracy: 0.8479 - auc: 0.9139\n",
      "Epoch 10: val_accuracy did not improve from 0.84580\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8479 - auc: 0.9142 - val_loss: 0.1168 - val_accuracy: 0.8458 - val_auc: 0.9122\n",
      "Epoch 11/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1142 - accuracy: 0.8495 - auc: 0.9163\n",
      "Epoch 11: val_accuracy improved from 0.84580 to 0.84672, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8489 - auc: 0.9160 - val_loss: 0.1160 - val_accuracy: 0.8467 - val_auc: 0.9140\n",
      "Epoch 12/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1137 - accuracy: 0.8485 - auc: 0.9179\n",
      "Epoch 12: val_accuracy improved from 0.84672 to 0.84718, saving model to \\saved_models1_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.8487 - auc: 0.9180 - val_loss: 0.1154 - val_accuracy: 0.8472 - val_auc: 0.9153\n",
      "Epoch 13/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.8496 - auc: 0.9197\n",
      "Epoch 13: val_accuracy did not improve from 0.84718\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.8494 - auc: 0.9195 - val_loss: 0.1149 - val_accuracy: 0.8463 - val_auc: 0.9163\n",
      "Epoch 14/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.8506 - auc: 0.9212\n",
      "Epoch 14: val_accuracy did not improve from 0.84718\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.8498 - auc: 0.9211 - val_loss: 0.1144 - val_accuracy: 0.8463 - val_auc: 0.9177\n",
      "Epoch 15/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.8494 - auc: 0.9224\n",
      "Epoch 15: val_accuracy did not improve from 0.84718\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.8494 - auc: 0.9225 - val_loss: 0.1140 - val_accuracy: 0.8467 - val_auc: 0.9184\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.8472 - auc: 0.9153\n",
      "Epoch 1/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2283 - accuracy: 0.6843 - auc: 0.7944\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77655, saving model to \\saved_models1_1/model_2.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2282 - accuracy: 0.6846 - auc: 0.7946 - val_loss: 0.2101 - val_accuracy: 0.7765 - val_auc: 0.8581\n",
      "Epoch 2/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.8135 - auc: 0.8675\n",
      "Epoch 2: val_accuracy improved from 0.77655 to 0.83610, saving model to \\saved_models1_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1897 - accuracy: 0.8144 - auc: 0.8681 - val_loss: 0.1717 - val_accuracy: 0.8361 - val_auc: 0.8769\n",
      "Epoch 3/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.8406 - auc: 0.8780\n",
      "Epoch 3: val_accuracy improved from 0.83610 to 0.85134, saving model to \\saved_models1_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1571 - accuracy: 0.8406 - auc: 0.8780 - val_loss: 0.1451 - val_accuracy: 0.8513 - val_auc: 0.8843\n",
      "Epoch 4/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1382 - accuracy: 0.8458 - auc: 0.8833\n",
      "Epoch 4: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1382 - accuracy: 0.8457 - auc: 0.8834 - val_loss: 0.1315 - val_accuracy: 0.8513 - val_auc: 0.8891\n",
      "Epoch 5/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.8466 - auc: 0.8879\n",
      "Epoch 5: val_accuracy improved from 0.85134 to 0.85180, saving model to \\saved_models1_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1291 - accuracy: 0.8461 - auc: 0.8876 - val_loss: 0.1252 - val_accuracy: 0.8518 - val_auc: 0.8927\n",
      "Epoch 6/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1249 - accuracy: 0.8464 - auc: 0.8908\n",
      "Epoch 6: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1248 - accuracy: 0.8466 - auc: 0.8909 - val_loss: 0.1221 - val_accuracy: 0.8504 - val_auc: 0.8957\n",
      "Epoch 7/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.8468 - auc: 0.8941\n",
      "Epoch 7: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.8464 - auc: 0.8936 - val_loss: 0.1205 - val_accuracy: 0.8500 - val_auc: 0.8979\n",
      "Epoch 8/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.8466 - auc: 0.8960\n",
      "Epoch 8: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.8466 - auc: 0.8960 - val_loss: 0.1195 - val_accuracy: 0.8500 - val_auc: 0.8997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1207 - accuracy: 0.8467 - auc: 0.8980\n",
      "Epoch 9: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.8468 - auc: 0.8979 - val_loss: 0.1188 - val_accuracy: 0.8500 - val_auc: 0.9017\n",
      "Epoch 10/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.8464 - auc: 0.8996\n",
      "Epoch 10: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.8464 - auc: 0.8998 - val_loss: 0.1183 - val_accuracy: 0.8500 - val_auc: 0.9030\n",
      "Epoch 11/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1190 - accuracy: 0.8479 - auc: 0.9022\n",
      "Epoch 11: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1195 - accuracy: 0.8471 - auc: 0.9015 - val_loss: 0.1180 - val_accuracy: 0.8500 - val_auc: 0.9039\n",
      "Epoch 12/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1186 - accuracy: 0.8478 - auc: 0.9038\n",
      "Epoch 12: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.8473 - auc: 0.9030 - val_loss: 0.1176 - val_accuracy: 0.8504 - val_auc: 0.9053\n",
      "Epoch 13/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 0.8476 - auc: 0.9044\n",
      "Epoch 13: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1186 - accuracy: 0.8474 - auc: 0.9044 - val_loss: 0.1172 - val_accuracy: 0.8504 - val_auc: 0.9066\n",
      "Epoch 14/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1178 - accuracy: 0.8482 - auc: 0.9063\n",
      "Epoch 14: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.8477 - auc: 0.9057 - val_loss: 0.1169 - val_accuracy: 0.8504 - val_auc: 0.9074\n",
      "Epoch 15/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.8469 - auc: 0.9067\n",
      "Epoch 15: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.8474 - auc: 0.9071 - val_loss: 0.1163 - val_accuracy: 0.8509 - val_auc: 0.9089\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.8518 - auc: 0.8927\n",
      "Epoch 1/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.2337 - accuracy: 0.6598 - auc: 0.8143\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77054, saving model to \\saved_models1_1/model_3.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2332 - accuracy: 0.6637 - auc: 0.8166 - val_loss: 0.2199 - val_accuracy: 0.7705 - val_auc: 0.8636\n",
      "Epoch 2/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.2034 - accuracy: 0.8142 - auc: 0.8718\n",
      "Epoch 2: val_accuracy improved from 0.77054 to 0.83380, saving model to \\saved_models1_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2025 - accuracy: 0.8158 - auc: 0.8722 - val_loss: 0.1865 - val_accuracy: 0.8338 - val_auc: 0.8723\n",
      "Epoch 3/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1680 - accuracy: 0.8454 - auc: 0.8797\n",
      "Epoch 3: val_accuracy improved from 0.83380 to 0.83795, saving model to \\saved_models1_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1674 - accuracy: 0.8443 - auc: 0.8782 - val_loss: 0.1563 - val_accuracy: 0.8380 - val_auc: 0.8754\n",
      "Epoch 4/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1428 - accuracy: 0.8475 - auc: 0.8842\n",
      "Epoch 4: val_accuracy did not improve from 0.83795\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1427 - accuracy: 0.8471 - auc: 0.8838 - val_loss: 0.1399 - val_accuracy: 0.8380 - val_auc: 0.8781\n",
      "Epoch 5/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1307 - accuracy: 0.8470 - auc: 0.8879\n",
      "Epoch 5: val_accuracy improved from 0.83795 to 0.83887, saving model to \\saved_models1_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1305 - accuracy: 0.8472 - auc: 0.8879 - val_loss: 0.1328 - val_accuracy: 0.8389 - val_auc: 0.8805\n",
      "Epoch 6/15\n",
      "563/610 [==========================>...] - ETA: 0s - loss: 0.1249 - accuracy: 0.8476 - auc: 0.8916\n",
      "Epoch 6: val_accuracy did not improve from 0.83887\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.8473 - auc: 0.8908 - val_loss: 0.1298 - val_accuracy: 0.8389 - val_auc: 0.8828\n",
      "Epoch 7/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 0.8476 - auc: 0.8938\n",
      "Epoch 7: val_accuracy did not improve from 0.83887\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.8474 - auc: 0.8936 - val_loss: 0.1283 - val_accuracy: 0.8389 - val_auc: 0.8852\n",
      "Epoch 8/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1207 - accuracy: 0.8486 - auc: 0.8966\n",
      "Epoch 8: val_accuracy improved from 0.83887 to 0.84026, saving model to \\saved_models1_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1211 - accuracy: 0.8477 - auc: 0.8962 - val_loss: 0.1275 - val_accuracy: 0.8403 - val_auc: 0.8869\n",
      "Epoch 9/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1205 - accuracy: 0.8472 - auc: 0.8978\n",
      "Epoch 9: val_accuracy did not improve from 0.84026\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.8478 - auc: 0.8987 - val_loss: 0.1271 - val_accuracy: 0.8403 - val_auc: 0.8882\n",
      "Epoch 10/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1202 - accuracy: 0.8469 - auc: 0.8994\n",
      "Epoch 10: val_accuracy did not improve from 0.84026\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1195 - accuracy: 0.8476 - auc: 0.9006 - val_loss: 0.1267 - val_accuracy: 0.8403 - val_auc: 0.8899\n",
      "Epoch 11/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1190 - accuracy: 0.8478 - auc: 0.9025\n",
      "Epoch 11: val_accuracy did not improve from 0.84026\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.8479 - auc: 0.9024 - val_loss: 0.1263 - val_accuracy: 0.8393 - val_auc: 0.8913\n",
      "Epoch 12/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1178 - accuracy: 0.8480 - auc: 0.9053\n",
      "Epoch 12: val_accuracy did not improve from 0.84026\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.8472 - auc: 0.9042 - val_loss: 0.1261 - val_accuracy: 0.8389 - val_auc: 0.8925\n",
      "Epoch 13/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1179 - accuracy: 0.8478 - auc: 0.9060\n",
      "Epoch 13: val_accuracy did not improve from 0.84026\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.8477 - auc: 0.9059 - val_loss: 0.1259 - val_accuracy: 0.8375 - val_auc: 0.8934\n",
      "Epoch 14/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1176 - accuracy: 0.8474 - auc: 0.9073\n",
      "Epoch 14: val_accuracy did not improve from 0.84026\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1176 - accuracy: 0.8478 - auc: 0.9072 - val_loss: 0.1257 - val_accuracy: 0.8375 - val_auc: 0.8946\n",
      "Epoch 15/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1169 - accuracy: 0.8485 - auc: 0.9088\n",
      "Epoch 15: val_accuracy did not improve from 0.84026\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1172 - accuracy: 0.8482 - auc: 0.9085 - val_loss: 0.1256 - val_accuracy: 0.8366 - val_auc: 0.8954\n",
      "68/68 [==============================] - 0s 944us/step - loss: 0.1275 - accuracy: 0.8403 - auc: 0.8869\n",
      "Epoch 1/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.2339 - accuracy: 0.7242 - auc: 0.8109\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77839, saving model to \\saved_models1_1/model_4.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2326 - accuracy: 0.7301 - auc: 0.8167 - val_loss: 0.2177 - val_accuracy: 0.7784 - val_auc: 0.8428\n",
      "Epoch 2/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1940 - accuracy: 0.8414 - auc: 0.8713\n",
      "Epoch 2: val_accuracy improved from 0.77839 to 0.81625, saving model to \\saved_models1_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1940 - accuracy: 0.8413 - auc: 0.8710 - val_loss: 0.1824 - val_accuracy: 0.8163 - val_auc: 0.8498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1594 - accuracy: 0.8512 - auc: 0.8743\n",
      "Epoch 3: val_accuracy improved from 0.81625 to 0.81948, saving model to \\saved_models1_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1588 - accuracy: 0.8506 - auc: 0.8737 - val_loss: 0.1576 - val_accuracy: 0.8195 - val_auc: 0.8541\n",
      "Epoch 4/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.8506 - auc: 0.8766\n",
      "Epoch 4: val_accuracy improved from 0.81948 to 0.82087, saving model to \\saved_models1_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1378 - accuracy: 0.8507 - auc: 0.8768 - val_loss: 0.1464 - val_accuracy: 0.8209 - val_auc: 0.8583\n",
      "Epoch 5/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1286 - accuracy: 0.8505 - auc: 0.8805\n",
      "Epoch 5: val_accuracy did not improve from 0.82087\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.8507 - auc: 0.8808 - val_loss: 0.1421 - val_accuracy: 0.8204 - val_auc: 0.8622\n",
      "Epoch 6/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1235 - accuracy: 0.8518 - auc: 0.8841\n",
      "Epoch 6: val_accuracy did not improve from 0.82087\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.8506 - auc: 0.8830 - val_loss: 0.1405 - val_accuracy: 0.8204 - val_auc: 0.8656\n",
      "Epoch 7/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1226 - accuracy: 0.8499 - auc: 0.8854\n",
      "Epoch 7: val_accuracy did not improve from 0.82087\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.8505 - auc: 0.8859 - val_loss: 0.1398 - val_accuracy: 0.8199 - val_auc: 0.8683\n",
      "Epoch 8/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.8507 - auc: 0.8884\n",
      "Epoch 8: val_accuracy did not improve from 0.82087\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1212 - accuracy: 0.8507 - auc: 0.8883 - val_loss: 0.1395 - val_accuracy: 0.8199 - val_auc: 0.8717\n",
      "Epoch 9/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1213 - accuracy: 0.8497 - auc: 0.8889\n",
      "Epoch 9: val_accuracy improved from 0.82087 to 0.82179, saving model to \\saved_models1_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.8503 - auc: 0.8905 - val_loss: 0.1392 - val_accuracy: 0.8218 - val_auc: 0.8741\n",
      "Epoch 10/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1199 - accuracy: 0.8509 - auc: 0.8926\n",
      "Epoch 10: val_accuracy improved from 0.82179 to 0.82225, saving model to \\saved_models1_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1202 - accuracy: 0.8503 - auc: 0.8924 - val_loss: 0.1390 - val_accuracy: 0.8223 - val_auc: 0.8763\n",
      "Epoch 11/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1197 - accuracy: 0.8507 - auc: 0.8947\n",
      "Epoch 11: val_accuracy did not improve from 0.82225\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.8506 - auc: 0.8942 - val_loss: 0.1387 - val_accuracy: 0.8213 - val_auc: 0.8778\n",
      "Epoch 12/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1200 - accuracy: 0.8500 - auc: 0.8952\n",
      "Epoch 12: val_accuracy did not improve from 0.82225\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1195 - accuracy: 0.8510 - auc: 0.8957 - val_loss: 0.1385 - val_accuracy: 0.8218 - val_auc: 0.8790\n",
      "Epoch 13/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 0.8511 - auc: 0.8980\n",
      "Epoch 13: val_accuracy did not improve from 0.82225\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1192 - accuracy: 0.8501 - auc: 0.8972 - val_loss: 0.1382 - val_accuracy: 0.8213 - val_auc: 0.8805\n",
      "Epoch 14/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1191 - accuracy: 0.8506 - auc: 0.8985\n",
      "Epoch 14: val_accuracy did not improve from 0.82225\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.8508 - auc: 0.8985 - val_loss: 0.1379 - val_accuracy: 0.8213 - val_auc: 0.8809\n",
      "Epoch 15/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1184 - accuracy: 0.8512 - auc: 0.8999\n",
      "Epoch 15: val_accuracy did not improve from 0.82225\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.8507 - auc: 0.8997 - val_loss: 0.1376 - val_accuracy: 0.8218 - val_auc: 0.8822\n",
      "68/68 [==============================] - 0s 978us/step - loss: 0.1390 - accuracy: 0.8223 - auc: 0.8763\n",
      "Epoch 1/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.5782 - auc: 0.6675\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63296, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.5802 - auc: 0.6705 - val_loss: 0.2344 - val_accuracy: 0.6330 - val_auc: 0.7403\n",
      "Epoch 2/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.2250 - accuracy: 0.6734 - auc: 0.7636\n",
      "Epoch 2: val_accuracy improved from 0.63296 to 0.70591, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2244 - accuracy: 0.6758 - auc: 0.7643 - val_loss: 0.2127 - val_accuracy: 0.7059 - val_auc: 0.7832\n",
      "Epoch 3/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2004 - accuracy: 0.7280 - auc: 0.8041\n",
      "Epoch 3: val_accuracy improved from 0.70591 to 0.74977, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1995 - accuracy: 0.7302 - auc: 0.8066 - val_loss: 0.1855 - val_accuracy: 0.7498 - val_auc: 0.8276\n",
      "Epoch 4/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1736 - accuracy: 0.7694 - auc: 0.8461\n",
      "Epoch 4: val_accuracy improved from 0.74977 to 0.79594, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1727 - accuracy: 0.7719 - auc: 0.8480 - val_loss: 0.1591 - val_accuracy: 0.7959 - val_auc: 0.8669\n",
      "Epoch 5/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1517 - accuracy: 0.8046 - auc: 0.8753\n",
      "Epoch 5: val_accuracy improved from 0.79594 to 0.82825, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1504 - accuracy: 0.8067 - auc: 0.8776 - val_loss: 0.1391 - val_accuracy: 0.8283 - val_auc: 0.8903\n",
      "Epoch 6/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.8269 - auc: 0.8921\n",
      "Epoch 6: val_accuracy improved from 0.82825 to 0.84257, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1355 - accuracy: 0.8270 - auc: 0.8922 - val_loss: 0.1267 - val_accuracy: 0.8426 - val_auc: 0.9022\n",
      "Epoch 7/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1270 - accuracy: 0.8377 - auc: 0.9005\n",
      "Epoch 7: val_accuracy improved from 0.84257 to 0.85088, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1267 - accuracy: 0.8380 - auc: 0.9007 - val_loss: 0.1199 - val_accuracy: 0.8509 - val_auc: 0.9086\n",
      "Epoch 8/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.8421 - auc: 0.9060\n",
      "Epoch 8: val_accuracy improved from 0.85088 to 0.85411, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.8421 - auc: 0.9059 - val_loss: 0.1157 - val_accuracy: 0.8541 - val_auc: 0.9126\n",
      "Epoch 9/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1188 - accuracy: 0.8448 - auc: 0.9094\n",
      "Epoch 9: val_accuracy improved from 0.85411 to 0.85596, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1188 - accuracy: 0.8444 - auc: 0.9094 - val_loss: 0.1135 - val_accuracy: 0.8560 - val_auc: 0.9149\n",
      "Epoch 10/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.8454 - auc: 0.9121\n",
      "Epoch 10: val_accuracy improved from 0.85596 to 0.85826, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.8454 - auc: 0.9121 - val_loss: 0.1116 - val_accuracy: 0.8583 - val_auc: 0.9173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.8448 - auc: 0.9135\n",
      "Epoch 11: val_accuracy improved from 0.85826 to 0.85873, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8457 - auc: 0.9145 - val_loss: 0.1103 - val_accuracy: 0.8587 - val_auc: 0.9192\n",
      "Epoch 12/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1141 - accuracy: 0.8466 - auc: 0.9172\n",
      "Epoch 12: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8460 - auc: 0.9165 - val_loss: 0.1094 - val_accuracy: 0.8583 - val_auc: 0.9207\n",
      "Epoch 13/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.8470 - auc: 0.9183\n",
      "Epoch 13: val_accuracy improved from 0.85873 to 0.86057, saving model to \\saved_models1_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.8468 - auc: 0.9182 - val_loss: 0.1086 - val_accuracy: 0.8606 - val_auc: 0.9221\n",
      "Epoch 14/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1130 - accuracy: 0.8471 - auc: 0.9192\n",
      "Epoch 14: val_accuracy did not improve from 0.86057\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.8470 - auc: 0.9197 - val_loss: 0.1079 - val_accuracy: 0.8601 - val_auc: 0.9233\n",
      "Epoch 15/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1117 - accuracy: 0.8482 - auc: 0.9219\n",
      "Epoch 15: val_accuracy did not improve from 0.86057\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.8476 - auc: 0.9214 - val_loss: 0.1075 - val_accuracy: 0.8587 - val_auc: 0.9239\n",
      "68/68 [==============================] - 0s 967us/step - loss: 0.1086 - accuracy: 0.8606 - auc: 0.9221\n",
      "Epoch 1/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2439 - accuracy: 0.5708 - auc: 0.6592\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61588, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.5745 - auc: 0.6670 - val_loss: 0.2389 - val_accuracy: 0.6159 - val_auc: 0.7491\n",
      "Epoch 2/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2326 - accuracy: 0.6660 - auc: 0.7807\n",
      "Epoch 2: val_accuracy improved from 0.61588 to 0.69668, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2319 - accuracy: 0.6702 - auc: 0.7834 - val_loss: 0.2244 - val_accuracy: 0.6967 - val_auc: 0.8144\n",
      "Epoch 3/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.2126 - accuracy: 0.7448 - auc: 0.8364\n",
      "Epoch 3: val_accuracy improved from 0.69668 to 0.77054, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2119 - accuracy: 0.7460 - auc: 0.8368 - val_loss: 0.1992 - val_accuracy: 0.7705 - val_auc: 0.8564\n",
      "Epoch 4/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1833 - accuracy: 0.7987 - auc: 0.8677\n",
      "Epoch 4: val_accuracy improved from 0.77054 to 0.82318, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1824 - accuracy: 0.7993 - auc: 0.8673 - val_loss: 0.1672 - val_accuracy: 0.8232 - val_auc: 0.8765\n",
      "Epoch 5/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.8306 - auc: 0.8816\n",
      "Epoch 5: val_accuracy improved from 0.82318 to 0.83610, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1531 - accuracy: 0.8309 - auc: 0.8818 - val_loss: 0.1425 - val_accuracy: 0.8361 - val_auc: 0.8882\n",
      "Epoch 6/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1342 - accuracy: 0.8404 - auc: 0.8942\n",
      "Epoch 6: val_accuracy improved from 0.83610 to 0.84395, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1340 - accuracy: 0.8404 - auc: 0.8940 - val_loss: 0.1286 - val_accuracy: 0.8440 - val_auc: 0.8974\n",
      "Epoch 7/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1239 - accuracy: 0.8446 - auc: 0.9033\n",
      "Epoch 7: val_accuracy improved from 0.84395 to 0.84534, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1239 - accuracy: 0.8442 - auc: 0.9030 - val_loss: 0.1221 - val_accuracy: 0.8453 - val_auc: 0.9034\n",
      "Epoch 8/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1189 - accuracy: 0.8472 - auc: 0.9085\n",
      "Epoch 8: val_accuracy improved from 0.84534 to 0.84857, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.8462 - auc: 0.9082 - val_loss: 0.1187 - val_accuracy: 0.8486 - val_auc: 0.9073\n",
      "Epoch 9/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.8467 - auc: 0.9119\n",
      "Epoch 9: val_accuracy improved from 0.84857 to 0.84949, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.8471 - auc: 0.9121 - val_loss: 0.1171 - val_accuracy: 0.8495 - val_auc: 0.9102\n",
      "Epoch 10/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1146 - accuracy: 0.8472 - auc: 0.9153\n",
      "Epoch 10: val_accuracy improved from 0.84949 to 0.84995, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1149 - accuracy: 0.8467 - auc: 0.9149 - val_loss: 0.1157 - val_accuracy: 0.8500 - val_auc: 0.9128\n",
      "Epoch 11/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.8477 - auc: 0.9172\n",
      "Epoch 11: val_accuracy improved from 0.84995 to 0.85134, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.8477 - auc: 0.9175 - val_loss: 0.1150 - val_accuracy: 0.8513 - val_auc: 0.9149\n",
      "Epoch 12/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.8492 - auc: 0.9202\n",
      "Epoch 12: val_accuracy improved from 0.85134 to 0.85180, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1127 - accuracy: 0.8485 - auc: 0.9194 - val_loss: 0.1141 - val_accuracy: 0.8518 - val_auc: 0.9166\n",
      "Epoch 13/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1107 - accuracy: 0.8503 - auc: 0.9226\n",
      "Epoch 13: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.8484 - auc: 0.9214 - val_loss: 0.1134 - val_accuracy: 0.8518 - val_auc: 0.9183\n",
      "Epoch 14/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.8492 - auc: 0.9229\n",
      "Epoch 14: val_accuracy improved from 0.85180 to 0.85226, saving model to \\saved_models1_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1108 - accuracy: 0.8495 - auc: 0.9232 - val_loss: 0.1128 - val_accuracy: 0.8523 - val_auc: 0.9197\n",
      "Epoch 15/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1104 - accuracy: 0.8489 - auc: 0.9243\n",
      "Epoch 15: val_accuracy did not improve from 0.85226\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.8497 - auc: 0.9247 - val_loss: 0.1121 - val_accuracy: 0.8523 - val_auc: 0.9212\n",
      "68/68 [==============================] - 0s 953us/step - loss: 0.1128 - accuracy: 0.8523 - auc: 0.9197\n",
      "Epoch 1/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.6173 - auc: 0.6845\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69021, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2320 - accuracy: 0.6176 - auc: 0.6849 - val_loss: 0.2169 - val_accuracy: 0.6902 - val_auc: 0.7539\n",
      "Epoch 2/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.2046 - accuracy: 0.7043 - auc: 0.7845\n",
      "Epoch 2: val_accuracy improved from 0.69021 to 0.74377, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2036 - accuracy: 0.7066 - auc: 0.7866 - val_loss: 0.1889 - val_accuracy: 0.7438 - val_auc: 0.8169\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1753 - accuracy: 0.7607 - auc: 0.8420\n",
      "Epoch 3: val_accuracy improved from 0.74377 to 0.78209, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1747 - accuracy: 0.7614 - auc: 0.8426 - val_loss: 0.1613 - val_accuracy: 0.7821 - val_auc: 0.8631\n",
      "Epoch 4/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1503 - accuracy: 0.7977 - auc: 0.8779\n",
      "Epoch 4: val_accuracy improved from 0.78209 to 0.81671, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.7989 - auc: 0.8789 - val_loss: 0.1405 - val_accuracy: 0.8167 - val_auc: 0.8892\n",
      "Epoch 5/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1342 - accuracy: 0.8213 - auc: 0.8965\n",
      "Epoch 5: val_accuracy improved from 0.81671 to 0.82595, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1333 - accuracy: 0.8222 - auc: 0.8978 - val_loss: 0.1289 - val_accuracy: 0.8259 - val_auc: 0.9016\n",
      "Epoch 6/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1242 - accuracy: 0.8322 - auc: 0.9075\n",
      "Epoch 6: val_accuracy improved from 0.82595 to 0.83195, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1240 - accuracy: 0.8326 - auc: 0.9078 - val_loss: 0.1223 - val_accuracy: 0.8319 - val_auc: 0.9093\n",
      "Epoch 7/15\n",
      "563/610 [==========================>...] - ETA: 0s - loss: 0.1182 - accuracy: 0.8395 - auc: 0.9148\n",
      "Epoch 7: val_accuracy improved from 0.83195 to 0.83841, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.8384 - auc: 0.9145 - val_loss: 0.1181 - val_accuracy: 0.8384 - val_auc: 0.9139\n",
      "Epoch 8/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.8431 - auc: 0.9187\n",
      "Epoch 8: val_accuracy improved from 0.83841 to 0.84441, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.8439 - auc: 0.9192 - val_loss: 0.1151 - val_accuracy: 0.8444 - val_auc: 0.9172\n",
      "Epoch 9/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1124 - accuracy: 0.8463 - auc: 0.9224\n",
      "Epoch 9: val_accuracy improved from 0.84441 to 0.84765, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.8461 - auc: 0.9227 - val_loss: 0.1136 - val_accuracy: 0.8476 - val_auc: 0.9194\n",
      "Epoch 10/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1099 - accuracy: 0.8497 - auc: 0.9258\n",
      "Epoch 10: val_accuracy improved from 0.84765 to 0.84811, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.8485 - auc: 0.9253 - val_loss: 0.1122 - val_accuracy: 0.8481 - val_auc: 0.9217\n",
      "Epoch 11/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1089 - accuracy: 0.8494 - auc: 0.9273\n",
      "Epoch 11: val_accuracy did not improve from 0.84811\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.8496 - auc: 0.9275 - val_loss: 0.1113 - val_accuracy: 0.8476 - val_auc: 0.9231\n",
      "Epoch 12/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1085 - accuracy: 0.8491 - auc: 0.9281\n",
      "Epoch 12: val_accuracy improved from 0.84811 to 0.85180, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.8505 - auc: 0.9293 - val_loss: 0.1100 - val_accuracy: 0.8518 - val_auc: 0.9244\n",
      "Epoch 13/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1064 - accuracy: 0.8513 - auc: 0.9310\n",
      "Epoch 13: val_accuracy did not improve from 0.85180\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.8510 - auc: 0.9311 - val_loss: 0.1094 - val_accuracy: 0.8518 - val_auc: 0.9252\n",
      "Epoch 14/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.8524 - auc: 0.9325\n",
      "Epoch 14: val_accuracy improved from 0.85180 to 0.85226, saving model to \\saved_models1_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1053 - accuracy: 0.8525 - auc: 0.9325 - val_loss: 0.1086 - val_accuracy: 0.8523 - val_auc: 0.9271\n",
      "Epoch 15/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1043 - accuracy: 0.8522 - auc: 0.9340\n",
      "Epoch 15: val_accuracy did not improve from 0.85226\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.8523 - auc: 0.9341 - val_loss: 0.1076 - val_accuracy: 0.8513 - val_auc: 0.9283\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.8523 - auc: 0.9271\n",
      "Epoch 1/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.2405 - accuracy: 0.6357 - auc: 0.6912\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74838, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.6425 - auc: 0.7000 - val_loss: 0.2224 - val_accuracy: 0.7484 - val_auc: 0.8220\n",
      "Epoch 2/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.2031 - accuracy: 0.7727 - auc: 0.8450\n",
      "Epoch 2: val_accuracy improved from 0.74838 to 0.79640, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2016 - accuracy: 0.7743 - auc: 0.8458 - val_loss: 0.1784 - val_accuracy: 0.7964 - val_auc: 0.8714\n",
      "Epoch 3/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1626 - accuracy: 0.8043 - auc: 0.8780\n",
      "Epoch 3: val_accuracy improved from 0.79640 to 0.82825, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1616 - accuracy: 0.8059 - auc: 0.8787 - val_loss: 0.1441 - val_accuracy: 0.8283 - val_auc: 0.8952\n",
      "Epoch 4/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1377 - accuracy: 0.8227 - auc: 0.8955\n",
      "Epoch 4: val_accuracy improved from 0.82825 to 0.84441, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1377 - accuracy: 0.8229 - auc: 0.8956 - val_loss: 0.1261 - val_accuracy: 0.8444 - val_auc: 0.9100\n",
      "Epoch 5/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 0.8334 - auc: 0.9056\n",
      "Epoch 5: val_accuracy improved from 0.84441 to 0.85180, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1257 - accuracy: 0.8334 - auc: 0.9056 - val_loss: 0.1169 - val_accuracy: 0.8518 - val_auc: 0.9171\n",
      "Epoch 6/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.8389 - auc: 0.9116\n",
      "Epoch 6: val_accuracy improved from 0.85180 to 0.85688, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.8389 - auc: 0.9117 - val_loss: 0.1123 - val_accuracy: 0.8569 - val_auc: 0.9217\n",
      "Epoch 7/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.8414 - auc: 0.9152\n",
      "Epoch 7: val_accuracy improved from 0.85688 to 0.85734, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.8415 - auc: 0.9153 - val_loss: 0.1089 - val_accuracy: 0.8573 - val_auc: 0.9245\n",
      "Epoch 8/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.8441 - auc: 0.9184\n",
      "Epoch 8: val_accuracy improved from 0.85734 to 0.86242, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1140 - accuracy: 0.8437 - auc: 0.9182 - val_loss: 0.1074 - val_accuracy: 0.8624 - val_auc: 0.9264\n",
      "Epoch 9/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1121 - accuracy: 0.8448 - auc: 0.9210\n",
      "Epoch 9: val_accuracy did not improve from 0.86242\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.8442 - auc: 0.9203 - val_loss: 0.1057 - val_accuracy: 0.8606 - val_auc: 0.9284\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1114 - accuracy: 0.8462 - auc: 0.9222\n",
      "Epoch 10: val_accuracy improved from 0.86242 to 0.86380, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.8467 - auc: 0.9221 - val_loss: 0.1051 - val_accuracy: 0.8638 - val_auc: 0.9299\n",
      "Epoch 11/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.8474 - auc: 0.9235\n",
      "Epoch 11: val_accuracy did not improve from 0.86380\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1104 - accuracy: 0.8476 - auc: 0.9236 - val_loss: 0.1043 - val_accuracy: 0.8620 - val_auc: 0.9310\n",
      "Epoch 12/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1100 - accuracy: 0.8465 - auc: 0.9245\n",
      "Epoch 12: val_accuracy did not improve from 0.86380\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.8477 - auc: 0.9249 - val_loss: 0.1029 - val_accuracy: 0.8638 - val_auc: 0.9326\n",
      "Epoch 13/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1084 - accuracy: 0.8492 - auc: 0.9265\n",
      "Epoch 13: val_accuracy did not improve from 0.86380\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.8490 - auc: 0.9263 - val_loss: 0.1021 - val_accuracy: 0.8633 - val_auc: 0.9341\n",
      "Epoch 14/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1086 - accuracy: 0.8480 - auc: 0.9266\n",
      "Epoch 14: val_accuracy improved from 0.86380 to 0.86519, saving model to \\saved_models1_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.8493 - auc: 0.9278 - val_loss: 0.1014 - val_accuracy: 0.8652 - val_auc: 0.9351\n",
      "Epoch 15/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.8501 - auc: 0.9287\n",
      "Epoch 15: val_accuracy did not improve from 0.86519\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.8505 - auc: 0.9289 - val_loss: 0.1006 - val_accuracy: 0.8629 - val_auc: 0.9364\n",
      "68/68 [==============================] - 0s 983us/step - loss: 0.1014 - accuracy: 0.8652 - auc: 0.9351\n",
      "Epoch 1/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.2418 - accuracy: 0.6646 - auc: 0.7178\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78337, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.6717 - auc: 0.7271 - val_loss: 0.2293 - val_accuracy: 0.7834 - val_auc: 0.8576\n",
      "Epoch 2/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.2172 - accuracy: 0.7981 - auc: 0.8607\n",
      "Epoch 2: val_accuracy improved from 0.78337 to 0.81801, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2163 - accuracy: 0.7992 - auc: 0.8606 - val_loss: 0.1978 - val_accuracy: 0.8180 - val_auc: 0.8773\n",
      "Epoch 3/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1820 - accuracy: 0.8164 - auc: 0.8716\n",
      "Epoch 3: val_accuracy improved from 0.81801 to 0.83187, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1818 - accuracy: 0.8158 - auc: 0.8713 - val_loss: 0.1620 - val_accuracy: 0.8319 - val_auc: 0.8856\n",
      "Epoch 4/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.8303 - auc: 0.8820\n",
      "Epoch 4: val_accuracy improved from 0.83187 to 0.84157, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1530 - accuracy: 0.8301 - auc: 0.8811 - val_loss: 0.1392 - val_accuracy: 0.8416 - val_auc: 0.8938\n",
      "Epoch 5/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1370 - accuracy: 0.8420 - auc: 0.8877\n",
      "Epoch 5: val_accuracy improved from 0.84157 to 0.84573, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1365 - accuracy: 0.8427 - auc: 0.8881 - val_loss: 0.1273 - val_accuracy: 0.8457 - val_auc: 0.8998\n",
      "Epoch 6/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 0.8443 - auc: 0.8932\n",
      "Epoch 6: val_accuracy improved from 0.84573 to 0.84942, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1280 - accuracy: 0.8443 - auc: 0.8932 - val_loss: 0.1210 - val_accuracy: 0.8494 - val_auc: 0.9045\n",
      "Epoch 7/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.8454 - auc: 0.8961\n",
      "Epoch 7: val_accuracy improved from 0.84942 to 0.85035, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1237 - accuracy: 0.8454 - auc: 0.8963 - val_loss: 0.1177 - val_accuracy: 0.8503 - val_auc: 0.9069\n",
      "Epoch 8/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.8450 - auc: 0.8988\n",
      "Epoch 8: val_accuracy improved from 0.85035 to 0.85081, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1213 - accuracy: 0.8455 - auc: 0.8993 - val_loss: 0.1158 - val_accuracy: 0.8508 - val_auc: 0.9095\n",
      "Epoch 9/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.8456 - auc: 0.9013\n",
      "Epoch 9: val_accuracy improved from 0.85081 to 0.85127, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.8459 - auc: 0.9017 - val_loss: 0.1144 - val_accuracy: 0.8513 - val_auc: 0.9113\n",
      "Epoch 10/15\n",
      "562/610 [==========================>...] - ETA: 0s - loss: 0.1181 - accuracy: 0.8474 - auc: 0.9049\n",
      "Epoch 10: val_accuracy did not improve from 0.85127\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.8463 - auc: 0.9036 - val_loss: 0.1136 - val_accuracy: 0.8513 - val_auc: 0.9130\n",
      "Epoch 11/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 0.8461 - auc: 0.9044\n",
      "Epoch 11: val_accuracy improved from 0.85127 to 0.85219, saving model to \\saved_models1_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1181 - accuracy: 0.8469 - auc: 0.9054 - val_loss: 0.1131 - val_accuracy: 0.8522 - val_auc: 0.9147\n",
      "Epoch 12/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1173 - accuracy: 0.8473 - auc: 0.9075\n",
      "Epoch 12: val_accuracy did not improve from 0.85219\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1175 - accuracy: 0.8471 - auc: 0.9073 - val_loss: 0.1123 - val_accuracy: 0.8499 - val_auc: 0.9161\n",
      "Epoch 13/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1168 - accuracy: 0.8479 - auc: 0.9093\n",
      "Epoch 13: val_accuracy did not improve from 0.85219\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.8474 - auc: 0.9091 - val_loss: 0.1120 - val_accuracy: 0.8513 - val_auc: 0.9173\n",
      "Epoch 14/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1163 - accuracy: 0.8476 - auc: 0.9109\n",
      "Epoch 14: val_accuracy did not improve from 0.85219\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1164 - accuracy: 0.8477 - auc: 0.9108 - val_loss: 0.1116 - val_accuracy: 0.8508 - val_auc: 0.9186\n",
      "Epoch 15/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.8475 - auc: 0.9119\n",
      "Epoch 15: val_accuracy did not improve from 0.85219\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.8470 - auc: 0.9123 - val_loss: 0.1111 - val_accuracy: 0.8508 - val_auc: 0.9199\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.8522 - auc: 0.9147\n",
      "Epoch 1/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.2424 - accuracy: 0.5833 - auc: 0.6674\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64896, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2422 - accuracy: 0.5843 - auc: 0.6711 - val_loss: 0.2343 - val_accuracy: 0.6490 - val_auc: 0.7426\n",
      "Epoch 2/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.2263 - accuracy: 0.6858 - auc: 0.7679\n",
      "Epoch 2: val_accuracy improved from 0.64896 to 0.73303, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2257 - accuracy: 0.6879 - auc: 0.7684 - val_loss: 0.2104 - val_accuracy: 0.7330 - val_auc: 0.8069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1986 - accuracy: 0.7470 - auc: 0.8198\n",
      "Epoch 3: val_accuracy improved from 0.73303 to 0.76859, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1978 - accuracy: 0.7476 - auc: 0.8208 - val_loss: 0.1798 - val_accuracy: 0.7686 - val_auc: 0.8475\n",
      "Epoch 4/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1690 - accuracy: 0.7824 - auc: 0.8583\n",
      "Epoch 4: val_accuracy improved from 0.76859 to 0.80462, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1687 - accuracy: 0.7822 - auc: 0.8577 - val_loss: 0.1544 - val_accuracy: 0.8046 - val_auc: 0.8756\n",
      "Epoch 5/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.8068 - auc: 0.8830\n",
      "Epoch 5: val_accuracy improved from 0.80462 to 0.81940, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1467 - accuracy: 0.8075 - auc: 0.8838 - val_loss: 0.1369 - val_accuracy: 0.8194 - val_auc: 0.8953\n",
      "Epoch 6/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.8269 - auc: 0.8992\n",
      "Epoch 6: val_accuracy improved from 0.81940 to 0.83510, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1323 - accuracy: 0.8273 - auc: 0.8996 - val_loss: 0.1253 - val_accuracy: 0.8351 - val_auc: 0.9079\n",
      "Epoch 7/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1236 - accuracy: 0.8363 - auc: 0.9092\n",
      "Epoch 7: val_accuracy improved from 0.83510 to 0.83972, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.8358 - auc: 0.9092 - val_loss: 0.1188 - val_accuracy: 0.8397 - val_auc: 0.9144\n",
      "Epoch 8/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1189 - accuracy: 0.8403 - auc: 0.9143\n",
      "Epoch 8: val_accuracy improved from 0.83972 to 0.84388, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.8414 - auc: 0.9150 - val_loss: 0.1145 - val_accuracy: 0.8439 - val_auc: 0.9189\n",
      "Epoch 9/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1151 - accuracy: 0.8432 - auc: 0.9192\n",
      "Epoch 9: val_accuracy improved from 0.84388 to 0.84896, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.8431 - auc: 0.9188 - val_loss: 0.1124 - val_accuracy: 0.8490 - val_auc: 0.9213\n",
      "Epoch 10/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1126 - accuracy: 0.8464 - auc: 0.9222\n",
      "Epoch 10: val_accuracy improved from 0.84896 to 0.85035, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.8452 - auc: 0.9217 - val_loss: 0.1108 - val_accuracy: 0.8503 - val_auc: 0.9235\n",
      "Epoch 11/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1107 - accuracy: 0.8487 - auc: 0.9246\n",
      "Epoch 11: val_accuracy improved from 0.85035 to 0.85312, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.8470 - auc: 0.9238 - val_loss: 0.1092 - val_accuracy: 0.8531 - val_auc: 0.9253\n",
      "Epoch 12/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1102 - accuracy: 0.8484 - auc: 0.9254\n",
      "Epoch 12: val_accuracy did not improve from 0.85312\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.8480 - auc: 0.9255 - val_loss: 0.1081 - val_accuracy: 0.8531 - val_auc: 0.9267\n",
      "Epoch 13/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.8486 - auc: 0.9273\n",
      "Epoch 13: val_accuracy improved from 0.85312 to 0.85450, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8486 - auc: 0.9274 - val_loss: 0.1067 - val_accuracy: 0.8545 - val_auc: 0.9282\n",
      "Epoch 14/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1072 - accuracy: 0.8504 - auc: 0.9297\n",
      "Epoch 14: val_accuracy improved from 0.85450 to 0.85543, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.8491 - auc: 0.9288 - val_loss: 0.1058 - val_accuracy: 0.8554 - val_auc: 0.9296\n",
      "Epoch 15/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1065 - accuracy: 0.8512 - auc: 0.9306\n",
      "Epoch 15: val_accuracy improved from 0.85543 to 0.85681, saving model to \\saved_models1_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1069 - accuracy: 0.8502 - auc: 0.9304 - val_loss: 0.1051 - val_accuracy: 0.8568 - val_auc: 0.9308\n",
      "68/68 [==============================] - 0s 957us/step - loss: 0.1051 - accuracy: 0.8568 - auc: 0.9308\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY11 = []\n",
    "VALIDATION_AUC11 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names1].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names1].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names1):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep4')(deep_branch) # added this!\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model11 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model11.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models1_1/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history11 = model11.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model11.load_weights(\"\\saved_models1_1/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model11.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model11.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY11.append(results['accuracy'])\n",
    "    VALIDATION_AUC11.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history11.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history11.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history11.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history11.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8471837639808655 | 0.9153054356575012 |\n",
      "|  2   | 0.8518005609512329 | 0.8927249312400818 |\n",
      "|  3   | 0.8402585387229919 | 0.8869119882583618 |\n",
      "|  4   | 0.8222529888153076 | 0.8762747049331665 |\n",
      "|  5   | 0.8605724573135376 | 0.9220743179321289 |\n",
      "|  6   | 0.8522622585296631 | 0.9196503162384033 |\n",
      "|  7   | 0.8522622585296631 | 0.927057147026062  |\n",
      "|  8   | 0.8651893138885498 | 0.9351232051849365 |\n",
      "|  9   | 0.8521940112113953 | 0.9147030115127563 |\n",
      "|  10  | 0.8568129539489746 | 0.9307849407196045 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY11)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC11)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 8\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY11.index(max(VALIDATION_ACCURACY11))\n",
    "max_fold11 = idx + 1\n",
    "print(\"Best Fold:\", max_fold11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 944us/step - loss: 0.1392 - accuracy: 0.8042 - auc: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13915589451789856, 0.8042445778846741, 0.8877599239349365]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model11.load_weights(\"\\saved_models1_1/model_\"+str(max_fold11)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model11.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 819us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model11.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat11 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 1 - Even More Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.2423 - accuracy: 0.5873 - auc: 0.6480\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68098, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2414 - accuracy: 0.5938 - auc: 0.6574 - val_loss: 0.2284 - val_accuracy: 0.6810 - val_auc: 0.7711\n",
      "Epoch 2/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.2112 - accuracy: 0.7249 - auc: 0.8127\n",
      "Epoch 2: val_accuracy improved from 0.68098 to 0.74931, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2105 - accuracy: 0.7249 - auc: 0.8116 - val_loss: 0.1905 - val_accuracy: 0.7493 - val_auc: 0.8346\n",
      "Epoch 3/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1744 - accuracy: 0.7681 - auc: 0.8518\n",
      "Epoch 3: val_accuracy improved from 0.74931 to 0.78024, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1744 - accuracy: 0.7683 - auc: 0.8518 - val_loss: 0.1582 - val_accuracy: 0.7802 - val_auc: 0.8677\n",
      "Epoch 4/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1489 - accuracy: 0.7991 - auc: 0.8792\n",
      "Epoch 4: val_accuracy improved from 0.78024 to 0.80979, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1484 - accuracy: 0.8000 - auc: 0.8799 - val_loss: 0.1375 - val_accuracy: 0.8098 - val_auc: 0.8910\n",
      "Epoch 5/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1317 - accuracy: 0.8226 - auc: 0.8984\n",
      "Epoch 5: val_accuracy improved from 0.80979 to 0.83380, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1322 - accuracy: 0.8216 - auc: 0.8972 - val_loss: 0.1255 - val_accuracy: 0.8338 - val_auc: 0.9045\n",
      "Epoch 6/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1227 - accuracy: 0.8350 - auc: 0.9070\n",
      "Epoch 6: val_accuracy improved from 0.83380 to 0.84395, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.8342 - auc: 0.9066 - val_loss: 0.1177 - val_accuracy: 0.8440 - val_auc: 0.9130\n",
      "Epoch 7/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.8401 - auc: 0.9127\n",
      "Epoch 7: val_accuracy improved from 0.84395 to 0.84765, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1177 - accuracy: 0.8399 - auc: 0.9126 - val_loss: 0.1138 - val_accuracy: 0.8476 - val_auc: 0.9180\n",
      "Epoch 8/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1140 - accuracy: 0.8439 - auc: 0.9174\n",
      "Epoch 8: val_accuracy improved from 0.84765 to 0.84811, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.8434 - auc: 0.9169 - val_loss: 0.1116 - val_accuracy: 0.8481 - val_auc: 0.9215\n",
      "Epoch 9/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1124 - accuracy: 0.8449 - auc: 0.9198\n",
      "Epoch 9: val_accuracy improved from 0.84811 to 0.84857, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.8450 - auc: 0.9200 - val_loss: 0.1101 - val_accuracy: 0.8486 - val_auc: 0.9242\n",
      "Epoch 10/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1106 - accuracy: 0.8468 - auc: 0.9226\n",
      "Epoch 10: val_accuracy improved from 0.84857 to 0.84903, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.8472 - auc: 0.9227 - val_loss: 0.1086 - val_accuracy: 0.8490 - val_auc: 0.9262\n",
      "Epoch 11/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.8486 - auc: 0.9250\n",
      "Epoch 11: val_accuracy improved from 0.84903 to 0.85088, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1091 - accuracy: 0.8486 - auc: 0.9250 - val_loss: 0.1075 - val_accuracy: 0.8509 - val_auc: 0.9275\n",
      "Epoch 12/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1080 - accuracy: 0.8498 - auc: 0.9265\n",
      "Epoch 12: val_accuracy improved from 0.85088 to 0.85134, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.8500 - auc: 0.9267 - val_loss: 0.1063 - val_accuracy: 0.8513 - val_auc: 0.9293\n",
      "Epoch 13/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1072 - accuracy: 0.8488 - auc: 0.9278\n",
      "Epoch 13: val_accuracy improved from 0.85134 to 0.85226, saving model to \\saved_models1_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.8497 - auc: 0.9288 - val_loss: 0.1051 - val_accuracy: 0.8523 - val_auc: 0.9312\n",
      "Epoch 14/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1049 - accuracy: 0.8526 - auc: 0.9310\n",
      "Epoch 14: val_accuracy did not improve from 0.85226\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1051 - accuracy: 0.8524 - auc: 0.9308 - val_loss: 0.1044 - val_accuracy: 0.8509 - val_auc: 0.9328\n",
      "Epoch 15/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.8546 - auc: 0.9330\n",
      "Epoch 15: val_accuracy did not improve from 0.85226\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.8547 - auc: 0.9330 - val_loss: 0.1028 - val_accuracy: 0.8509 - val_auc: 0.9351\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.8523 - auc: 0.9312\n",
      "Epoch 1/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.5818 - auc: 0.6184\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65143, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2452 - accuracy: 0.5823 - auc: 0.6190 - val_loss: 0.2372 - val_accuracy: 0.6514 - val_auc: 0.7428\n",
      "Epoch 2/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.2250 - accuracy: 0.6896 - auc: 0.7734\n",
      "Epoch 2: val_accuracy improved from 0.65143 to 0.70268, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2243 - accuracy: 0.6906 - auc: 0.7749 - val_loss: 0.2095 - val_accuracy: 0.7027 - val_auc: 0.8042\n",
      "Epoch 3/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1939 - accuracy: 0.7361 - auc: 0.8231\n",
      "Epoch 3: val_accuracy improved from 0.70268 to 0.75392, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1934 - accuracy: 0.7370 - auc: 0.8241 - val_loss: 0.1771 - val_accuracy: 0.7539 - val_auc: 0.8526\n",
      "Epoch 4/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1645 - accuracy: 0.7804 - auc: 0.8643\n",
      "Epoch 4: val_accuracy improved from 0.75392 to 0.80194, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1641 - accuracy: 0.7814 - auc: 0.8645 - val_loss: 0.1500 - val_accuracy: 0.8019 - val_auc: 0.8830\n",
      "Epoch 5/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1434 - accuracy: 0.8137 - auc: 0.8866\n",
      "Epoch 5: val_accuracy improved from 0.80194 to 0.82872, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1430 - accuracy: 0.8139 - auc: 0.8870 - val_loss: 0.1330 - val_accuracy: 0.8287 - val_auc: 0.9014\n",
      "Epoch 6/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1305 - accuracy: 0.8281 - auc: 0.8986\n",
      "Epoch 6: val_accuracy improved from 0.82872 to 0.84072, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1300 - accuracy: 0.8293 - auc: 0.8994 - val_loss: 0.1228 - val_accuracy: 0.8407 - val_auc: 0.9106\n",
      "Epoch 7/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1224 - accuracy: 0.8365 - auc: 0.9073\n",
      "Epoch 7: val_accuracy improved from 0.84072 to 0.84626, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.8360 - auc: 0.9069 - val_loss: 0.1172 - val_accuracy: 0.8463 - val_auc: 0.9159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.8413 - auc: 0.9120\n",
      "Epoch 8: val_accuracy improved from 0.84626 to 0.84765, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.8413 - auc: 0.9120 - val_loss: 0.1140 - val_accuracy: 0.8476 - val_auc: 0.9197\n",
      "Epoch 9/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.8437 - auc: 0.9159\n",
      "Epoch 9: val_accuracy improved from 0.84765 to 0.84857, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1151 - accuracy: 0.8437 - auc: 0.9158 - val_loss: 0.1116 - val_accuracy: 0.8486 - val_auc: 0.9224\n",
      "Epoch 10/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1138 - accuracy: 0.8445 - auc: 0.9180\n",
      "Epoch 10: val_accuracy improved from 0.84857 to 0.85226, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1132 - accuracy: 0.8457 - auc: 0.9187 - val_loss: 0.1102 - val_accuracy: 0.8523 - val_auc: 0.9244\n",
      "Epoch 11/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.8474 - auc: 0.9211\n",
      "Epoch 11: val_accuracy did not improve from 0.85226\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8474 - auc: 0.9211 - val_loss: 0.1093 - val_accuracy: 0.8523 - val_auc: 0.9264\n",
      "Epoch 12/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.8484 - auc: 0.9233\n",
      "Epoch 12: val_accuracy improved from 0.85226 to 0.85365, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.8486 - auc: 0.9234 - val_loss: 0.1086 - val_accuracy: 0.8536 - val_auc: 0.9276\n",
      "Epoch 13/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.8496 - auc: 0.9254\n",
      "Epoch 13: val_accuracy did not improve from 0.85365\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1092 - accuracy: 0.8496 - auc: 0.9254 - val_loss: 0.1069 - val_accuracy: 0.8527 - val_auc: 0.9294\n",
      "Epoch 14/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.8504 - auc: 0.9274\n",
      "Epoch 14: val_accuracy did not improve from 0.85365\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.8506 - auc: 0.9275 - val_loss: 0.1056 - val_accuracy: 0.8536 - val_auc: 0.9314\n",
      "Epoch 15/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1067 - accuracy: 0.8514 - auc: 0.9294\n",
      "Epoch 15: val_accuracy improved from 0.85365 to 0.85596, saving model to \\saved_models1_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1067 - accuracy: 0.8516 - auc: 0.9293 - val_loss: 0.1046 - val_accuracy: 0.8560 - val_auc: 0.9335\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.8560 - auc: 0.9335\n",
      "Epoch 1/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2419 - accuracy: 0.6142 - auc: 0.7115\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69298, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2418 - accuracy: 0.6151 - auc: 0.7126 - val_loss: 0.2333 - val_accuracy: 0.6930 - val_auc: 0.8123\n",
      "Epoch 2/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.7532 - auc: 0.8467\n",
      "Epoch 2: val_accuracy improved from 0.69298 to 0.78116, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2216 - accuracy: 0.7532 - auc: 0.8467 - val_loss: 0.2096 - val_accuracy: 0.7812 - val_auc: 0.8505\n",
      "Epoch 3/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.8129 - auc: 0.8687\n",
      "Epoch 3: val_accuracy improved from 0.78116 to 0.81994, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1912 - accuracy: 0.8132 - auc: 0.8688 - val_loss: 0.1784 - val_accuracy: 0.8199 - val_auc: 0.8616\n",
      "Epoch 4/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.8360 - auc: 0.8793\n",
      "Epoch 4: val_accuracy improved from 0.81994 to 0.83333, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1598 - accuracy: 0.8364 - auc: 0.8795 - val_loss: 0.1537 - val_accuracy: 0.8333 - val_auc: 0.8678\n",
      "Epoch 5/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1393 - accuracy: 0.8438 - auc: 0.8863\n",
      "Epoch 5: val_accuracy did not improve from 0.83333\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1392 - accuracy: 0.8440 - auc: 0.8865 - val_loss: 0.1402 - val_accuracy: 0.8329 - val_auc: 0.8724\n",
      "Epoch 6/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.8458 - auc: 0.8915\n",
      "Epoch 6: val_accuracy improved from 0.83333 to 0.83610, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1287 - accuracy: 0.8458 - auc: 0.8916 - val_loss: 0.1338 - val_accuracy: 0.8361 - val_auc: 0.8757\n",
      "Epoch 7/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1233 - accuracy: 0.8468 - auc: 0.8961\n",
      "Epoch 7: val_accuracy improved from 0.83610 to 0.83657, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.8462 - auc: 0.8955 - val_loss: 0.1306 - val_accuracy: 0.8366 - val_auc: 0.8788\n",
      "Epoch 8/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.8477 - auc: 0.8990\n",
      "Epoch 8: val_accuracy did not improve from 0.83657\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1210 - accuracy: 0.8477 - auc: 0.8989 - val_loss: 0.1290 - val_accuracy: 0.8366 - val_auc: 0.8812\n",
      "Epoch 9/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1195 - accuracy: 0.8485 - auc: 0.9018\n",
      "Epoch 9: val_accuracy improved from 0.83657 to 0.83795, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.8481 - auc: 0.9017 - val_loss: 0.1280 - val_accuracy: 0.8380 - val_auc: 0.8835\n",
      "Epoch 10/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.8485 - auc: 0.9039\n",
      "Epoch 10: val_accuracy improved from 0.83795 to 0.83934, saving model to \\saved_models1_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1186 - accuracy: 0.8480 - auc: 0.9039 - val_loss: 0.1273 - val_accuracy: 0.8393 - val_auc: 0.8852\n",
      "Epoch 11/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.8483 - auc: 0.9056\n",
      "Epoch 11: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.8486 - auc: 0.9058 - val_loss: 0.1267 - val_accuracy: 0.8380 - val_auc: 0.8873\n",
      "Epoch 12/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1172 - accuracy: 0.8486 - auc: 0.9079\n",
      "Epoch 12: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1172 - accuracy: 0.8488 - auc: 0.9077 - val_loss: 0.1262 - val_accuracy: 0.8375 - val_auc: 0.8890\n",
      "Epoch 13/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1170 - accuracy: 0.8481 - auc: 0.9088\n",
      "Epoch 13: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.8487 - auc: 0.9092 - val_loss: 0.1258 - val_accuracy: 0.8384 - val_auc: 0.8907\n",
      "Epoch 14/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.8484 - auc: 0.9107\n",
      "Epoch 14: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.8486 - auc: 0.9107 - val_loss: 0.1255 - val_accuracy: 0.8380 - val_auc: 0.8924\n",
      "Epoch 15/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.8489 - auc: 0.9120\n",
      "Epoch 15: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8488 - auc: 0.9120 - val_loss: 0.1250 - val_accuracy: 0.8384 - val_auc: 0.8937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.8393 - auc: 0.8852\n",
      "Epoch 1/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2381 - accuracy: 0.5974 - auc: 0.7643\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67313, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.5974 - auc: 0.7645 - val_loss: 0.2298 - val_accuracy: 0.6731 - val_auc: 0.8234\n",
      "Epoch 2/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.7693 - auc: 0.8573\n",
      "Epoch 2: val_accuracy improved from 0.67313 to 0.78255, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2140 - accuracy: 0.7706 - auc: 0.8582 - val_loss: 0.2032 - val_accuracy: 0.7825 - val_auc: 0.8499\n",
      "Epoch 3/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1823 - accuracy: 0.8299 - auc: 0.8721\n",
      "Epoch 3: val_accuracy improved from 0.78255 to 0.81302, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1820 - accuracy: 0.8300 - auc: 0.8724 - val_loss: 0.1737 - val_accuracy: 0.8130 - val_auc: 0.8570\n",
      "Epoch 4/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1538 - accuracy: 0.8454 - auc: 0.8762\n",
      "Epoch 4: val_accuracy improved from 0.81302 to 0.81671, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1533 - accuracy: 0.8456 - auc: 0.8769 - val_loss: 0.1540 - val_accuracy: 0.8167 - val_auc: 0.8596\n",
      "Epoch 5/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.8497 - auc: 0.8804\n",
      "Epoch 5: val_accuracy improved from 0.81671 to 0.81764, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1362 - accuracy: 0.8497 - auc: 0.8803 - val_loss: 0.1450 - val_accuracy: 0.8176 - val_auc: 0.8614\n",
      "Epoch 6/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1277 - accuracy: 0.8499 - auc: 0.8832\n",
      "Epoch 6: val_accuracy did not improve from 0.81764\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1280 - accuracy: 0.8493 - auc: 0.8822 - val_loss: 0.1414 - val_accuracy: 0.8172 - val_auc: 0.8637\n",
      "Epoch 7/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1244 - accuracy: 0.8492 - auc: 0.8838\n",
      "Epoch 7: val_accuracy did not improve from 0.81764\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1243 - accuracy: 0.8495 - auc: 0.8838 - val_loss: 0.1400 - val_accuracy: 0.8176 - val_auc: 0.8654\n",
      "Epoch 8/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.8497 - auc: 0.8850\n",
      "Epoch 8: val_accuracy improved from 0.81764 to 0.81856, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.8498 - auc: 0.8852 - val_loss: 0.1395 - val_accuracy: 0.8186 - val_auc: 0.8671\n",
      "Epoch 9/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1215 - accuracy: 0.8500 - auc: 0.8866\n",
      "Epoch 9: val_accuracy improved from 0.81856 to 0.81948, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.8501 - auc: 0.8866 - val_loss: 0.1393 - val_accuracy: 0.8195 - val_auc: 0.8688\n",
      "Epoch 10/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.8501 - auc: 0.8881\n",
      "Epoch 10: val_accuracy did not improve from 0.81948\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1210 - accuracy: 0.8502 - auc: 0.8880 - val_loss: 0.1391 - val_accuracy: 0.8190 - val_auc: 0.8699\n",
      "Epoch 11/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.8505 - auc: 0.8896\n",
      "Epoch 11: val_accuracy improved from 0.81948 to 0.81994, saving model to \\saved_models1_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.8504 - auc: 0.8892 - val_loss: 0.1390 - val_accuracy: 0.8199 - val_auc: 0.8714\n",
      "Epoch 12/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1203 - accuracy: 0.8504 - auc: 0.8905\n",
      "Epoch 12: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.8505 - auc: 0.8904 - val_loss: 0.1389 - val_accuracy: 0.8199 - val_auc: 0.8726\n",
      "Epoch 13/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.8510 - auc: 0.8918\n",
      "Epoch 13: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.8506 - auc: 0.8915 - val_loss: 0.1388 - val_accuracy: 0.8199 - val_auc: 0.8739\n",
      "Epoch 14/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.8504 - auc: 0.8925\n",
      "Epoch 14: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1199 - accuracy: 0.8505 - auc: 0.8926 - val_loss: 0.1386 - val_accuracy: 0.8195 - val_auc: 0.8748\n",
      "Epoch 15/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1201 - accuracy: 0.8502 - auc: 0.8931\n",
      "Epoch 15: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1197 - accuracy: 0.8505 - auc: 0.8937 - val_loss: 0.1384 - val_accuracy: 0.8199 - val_auc: 0.8762\n",
      "68/68 [==============================] - 0s 986us/step - loss: 0.1390 - accuracy: 0.8199 - auc: 0.8714\n",
      "Epoch 1/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.5546 - auc: 0.6007\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58079, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.5557 - auc: 0.6025 - val_loss: 0.2398 - val_accuracy: 0.5808 - val_auc: 0.6887\n",
      "Epoch 2/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2326 - accuracy: 0.6389 - auc: 0.7362\n",
      "Epoch 2: val_accuracy improved from 0.58079 to 0.70637, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2325 - accuracy: 0.6397 - auc: 0.7364 - val_loss: 0.2222 - val_accuracy: 0.7064 - val_auc: 0.7709\n",
      "Epoch 3/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.7266 - auc: 0.7935\n",
      "Epoch 3: val_accuracy improved from 0.70637 to 0.74469, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.7265 - auc: 0.7936 - val_loss: 0.1957 - val_accuracy: 0.7447 - val_auc: 0.8175\n",
      "Epoch 4/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1816 - accuracy: 0.7694 - auc: 0.8399\n",
      "Epoch 4: val_accuracy improved from 0.74469 to 0.78209, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1815 - accuracy: 0.7694 - auc: 0.8400 - val_loss: 0.1678 - val_accuracy: 0.7821 - val_auc: 0.8574\n",
      "Epoch 5/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1553 - accuracy: 0.8058 - auc: 0.8745\n",
      "Epoch 5: val_accuracy improved from 0.78209 to 0.82687, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1553 - accuracy: 0.8061 - auc: 0.8740 - val_loss: 0.1446 - val_accuracy: 0.8269 - val_auc: 0.8851\n",
      "Epoch 6/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 0.8302 - auc: 0.8932\n",
      "Epoch 6: val_accuracy improved from 0.82687 to 0.83564, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1368 - accuracy: 0.8302 - auc: 0.8933 - val_loss: 0.1305 - val_accuracy: 0.8356 - val_auc: 0.8984\n",
      "Epoch 7/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.8411 - auc: 0.9025\n",
      "Epoch 7: val_accuracy improved from 0.83564 to 0.84580, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1264 - accuracy: 0.8404 - auc: 0.9021 - val_loss: 0.1229 - val_accuracy: 0.8458 - val_auc: 0.9050\n",
      "Epoch 8/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.8445 - auc: 0.9079\n",
      "Epoch 8: val_accuracy improved from 0.84580 to 0.84857, saving model to \\saved_models1_2/model_5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1210 - accuracy: 0.8440 - auc: 0.9070 - val_loss: 0.1187 - val_accuracy: 0.8486 - val_auc: 0.9091\n",
      "Epoch 9/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.8457 - auc: 0.9106\n",
      "Epoch 9: val_accuracy did not improve from 0.84857\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.8456 - auc: 0.9106 - val_loss: 0.1165 - val_accuracy: 0.8486 - val_auc: 0.9119\n",
      "Epoch 10/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.8463 - auc: 0.9131\n",
      "Epoch 10: val_accuracy improved from 0.84857 to 0.85365, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.8466 - auc: 0.9132 - val_loss: 0.1141 - val_accuracy: 0.8536 - val_auc: 0.9150\n",
      "Epoch 11/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.8471 - auc: 0.9152\n",
      "Epoch 11: val_accuracy did not improve from 0.85365\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.8474 - auc: 0.9156 - val_loss: 0.1128 - val_accuracy: 0.8523 - val_auc: 0.9173\n",
      "Epoch 12/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.8471 - auc: 0.9175\n",
      "Epoch 12: val_accuracy did not improve from 0.85365\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.8470 - auc: 0.9175 - val_loss: 0.1117 - val_accuracy: 0.8536 - val_auc: 0.9193\n",
      "Epoch 13/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.8478 - auc: 0.9193\n",
      "Epoch 13: val_accuracy improved from 0.85365 to 0.85457, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1127 - accuracy: 0.8478 - auc: 0.9194 - val_loss: 0.1107 - val_accuracy: 0.8546 - val_auc: 0.9215\n",
      "Epoch 14/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.8481 - auc: 0.9206\n",
      "Epoch 14: val_accuracy improved from 0.85457 to 0.85503, saving model to \\saved_models1_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.8486 - auc: 0.9210 - val_loss: 0.1103 - val_accuracy: 0.8550 - val_auc: 0.9222\n",
      "Epoch 15/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.8488 - auc: 0.9225\n",
      "Epoch 15: val_accuracy did not improve from 0.85503\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1107 - accuracy: 0.8491 - auc: 0.9227 - val_loss: 0.1090 - val_accuracy: 0.8546 - val_auc: 0.9241\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8550 - auc: 0.9222\n",
      "Epoch 1/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2493 - accuracy: 0.5158 - auc: 0.4983\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52816, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.5160 - auc: 0.5010 - val_loss: 0.2472 - val_accuracy: 0.5282 - val_auc: 0.6125\n",
      "Epoch 2/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.2445 - accuracy: 0.5399 - auc: 0.6581\n",
      "Epoch 2: val_accuracy improved from 0.52816 to 0.55586, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.5416 - auc: 0.6596 - val_loss: 0.2424 - val_accuracy: 0.5559 - val_auc: 0.7100\n",
      "Epoch 3/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.2383 - accuracy: 0.6173 - auc: 0.7386\n",
      "Epoch 3: val_accuracy improved from 0.55586 to 0.67636, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2381 - accuracy: 0.6206 - auc: 0.7394 - val_loss: 0.2342 - val_accuracy: 0.6764 - val_auc: 0.7726\n",
      "Epoch 4/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.7242 - auc: 0.7922\n",
      "Epoch 4: val_accuracy improved from 0.67636 to 0.73961, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2266 - accuracy: 0.7250 - auc: 0.7931 - val_loss: 0.2183 - val_accuracy: 0.7396 - val_auc: 0.8252\n",
      "Epoch 5/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.2065 - accuracy: 0.7666 - auc: 0.8438\n",
      "Epoch 5: val_accuracy improved from 0.73961 to 0.80240, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2056 - accuracy: 0.7688 - auc: 0.8443 - val_loss: 0.1917 - val_accuracy: 0.8024 - val_auc: 0.8687\n",
      "Epoch 6/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1775 - accuracy: 0.8251 - auc: 0.8666\n",
      "Epoch 6: val_accuracy improved from 0.80240 to 0.84580, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1771 - accuracy: 0.8256 - auc: 0.8666 - val_loss: 0.1622 - val_accuracy: 0.8458 - val_auc: 0.8780\n",
      "Epoch 7/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1523 - accuracy: 0.8432 - auc: 0.8727\n",
      "Epoch 7: val_accuracy improved from 0.84580 to 0.84903, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1521 - accuracy: 0.8431 - auc: 0.8730 - val_loss: 0.1417 - val_accuracy: 0.8490 - val_auc: 0.8807\n",
      "Epoch 8/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1380 - accuracy: 0.8441 - auc: 0.8751\n",
      "Epoch 8: val_accuracy improved from 0.84903 to 0.84995, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1373 - accuracy: 0.8448 - auc: 0.8760 - val_loss: 0.1311 - val_accuracy: 0.8500 - val_auc: 0.8824\n",
      "Epoch 9/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.8456 - auc: 0.8784\n",
      "Epoch 9: val_accuracy improved from 0.84995 to 0.85088, saving model to \\saved_models1_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1301 - accuracy: 0.8455 - auc: 0.8786 - val_loss: 0.1261 - val_accuracy: 0.8509 - val_auc: 0.8839\n",
      "Epoch 10/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.8451 - auc: 0.8795\n",
      "Epoch 10: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1267 - accuracy: 0.8456 - auc: 0.8802 - val_loss: 0.1236 - val_accuracy: 0.8509 - val_auc: 0.8855\n",
      "Epoch 11/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.8457 - auc: 0.8816\n",
      "Epoch 11: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1249 - accuracy: 0.8457 - auc: 0.8816 - val_loss: 0.1224 - val_accuracy: 0.8490 - val_auc: 0.8870\n",
      "Epoch 12/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1244 - accuracy: 0.8455 - auc: 0.8824\n",
      "Epoch 12: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1240 - accuracy: 0.8461 - auc: 0.8833 - val_loss: 0.1217 - val_accuracy: 0.8486 - val_auc: 0.8887\n",
      "Epoch 13/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.8469 - auc: 0.8848\n",
      "Epoch 13: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1234 - accuracy: 0.8468 - auc: 0.8848 - val_loss: 0.1212 - val_accuracy: 0.8490 - val_auc: 0.8901\n",
      "Epoch 14/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.8471 - auc: 0.8864\n",
      "Epoch 14: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.8472 - auc: 0.8863 - val_loss: 0.1209 - val_accuracy: 0.8486 - val_auc: 0.8915\n",
      "Epoch 15/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 0.8469 - auc: 0.8878\n",
      "Epoch 15: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1226 - accuracy: 0.8470 - auc: 0.8880 - val_loss: 0.1207 - val_accuracy: 0.8481 - val_auc: 0.8929\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.8509 - auc: 0.8839\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/610 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.6739 - auc: 0.7656\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75069, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2336 - accuracy: 0.6742 - auc: 0.7660 - val_loss: 0.2185 - val_accuracy: 0.7507 - val_auc: 0.8304\n",
      "Epoch 2/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.7807 - auc: 0.8449\n",
      "Epoch 2: val_accuracy improved from 0.75069 to 0.80240, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2033 - accuracy: 0.7807 - auc: 0.8450 - val_loss: 0.1862 - val_accuracy: 0.8024 - val_auc: 0.8593\n",
      "Epoch 3/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1715 - accuracy: 0.8162 - auc: 0.8686\n",
      "Epoch 3: val_accuracy improved from 0.80240 to 0.83010, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1712 - accuracy: 0.8166 - auc: 0.8689 - val_loss: 0.1572 - val_accuracy: 0.8301 - val_auc: 0.8768\n",
      "Epoch 4/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.8353 - auc: 0.8827\n",
      "Epoch 4: val_accuracy improved from 0.83010 to 0.84164, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1468 - accuracy: 0.8355 - auc: 0.8826 - val_loss: 0.1382 - val_accuracy: 0.8416 - val_auc: 0.8873\n",
      "Epoch 5/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1328 - accuracy: 0.8416 - auc: 0.8912\n",
      "Epoch 5: val_accuracy improved from 0.84164 to 0.84488, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1326 - accuracy: 0.8417 - auc: 0.8913 - val_loss: 0.1280 - val_accuracy: 0.8449 - val_auc: 0.8935\n",
      "Epoch 6/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.8443 - auc: 0.8977\n",
      "Epoch 6: val_accuracy improved from 0.84488 to 0.84718, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1252 - accuracy: 0.8441 - auc: 0.8975 - val_loss: 0.1227 - val_accuracy: 0.8472 - val_auc: 0.8978\n",
      "Epoch 7/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.8471 - auc: 0.9028\n",
      "Epoch 7: val_accuracy improved from 0.84718 to 0.84857, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1213 - accuracy: 0.8465 - auc: 0.9022 - val_loss: 0.1199 - val_accuracy: 0.8486 - val_auc: 0.9013\n",
      "Epoch 8/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.8475 - auc: 0.9062\n",
      "Epoch 8: val_accuracy improved from 0.84857 to 0.84949, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.8471 - auc: 0.9059 - val_loss: 0.1182 - val_accuracy: 0.8495 - val_auc: 0.9037\n",
      "Epoch 9/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.8469 - auc: 0.9086\n",
      "Epoch 9: val_accuracy improved from 0.84949 to 0.85088, saving model to \\saved_models1_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1176 - accuracy: 0.8473 - auc: 0.9089 - val_loss: 0.1170 - val_accuracy: 0.8509 - val_auc: 0.9060\n",
      "Epoch 10/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.8478 - auc: 0.9113\n",
      "Epoch 10: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.8479 - auc: 0.9113 - val_loss: 0.1163 - val_accuracy: 0.8504 - val_auc: 0.9077\n",
      "Epoch 11/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.8477 - auc: 0.9131\n",
      "Epoch 11: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8482 - auc: 0.9133 - val_loss: 0.1156 - val_accuracy: 0.8509 - val_auc: 0.9092\n",
      "Epoch 12/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.8484 - auc: 0.9153\n",
      "Epoch 12: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.8482 - auc: 0.9152 - val_loss: 0.1152 - val_accuracy: 0.8500 - val_auc: 0.9101\n",
      "Epoch 13/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.8485 - auc: 0.9163\n",
      "Epoch 13: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1140 - accuracy: 0.8487 - auc: 0.9164 - val_loss: 0.1150 - val_accuracy: 0.8495 - val_auc: 0.9117\n",
      "Epoch 14/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.8491 - auc: 0.9186\n",
      "Epoch 14: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1132 - accuracy: 0.8486 - auc: 0.9181 - val_loss: 0.1152 - val_accuracy: 0.8500 - val_auc: 0.9125\n",
      "Epoch 15/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.8499 - auc: 0.9197\n",
      "Epoch 15: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.8495 - auc: 0.9196 - val_loss: 0.1141 - val_accuracy: 0.8504 - val_auc: 0.9131\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.8509 - auc: 0.9060\n",
      "Epoch 1/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.7283 - auc: 0.7898\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80702, saving model to \\saved_models1_2/model_8.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2294 - accuracy: 0.7286 - auc: 0.7902 - val_loss: 0.2089 - val_accuracy: 0.8070 - val_auc: 0.8689\n",
      "Epoch 2/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1913 - accuracy: 0.8184 - auc: 0.8685\n",
      "Epoch 2: val_accuracy improved from 0.80702 to 0.84164, saving model to \\saved_models1_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1906 - accuracy: 0.8182 - auc: 0.8674 - val_loss: 0.1695 - val_accuracy: 0.8416 - val_auc: 0.8849\n",
      "Epoch 3/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.8359 - auc: 0.8803\n",
      "Epoch 3: val_accuracy improved from 0.84164 to 0.85319, saving model to \\saved_models1_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1579 - accuracy: 0.8358 - auc: 0.8795 - val_loss: 0.1420 - val_accuracy: 0.8532 - val_auc: 0.8915\n",
      "Epoch 4/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.8427 - auc: 0.8865\n",
      "Epoch 4: val_accuracy improved from 0.85319 to 0.85596, saving model to \\saved_models1_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1386 - accuracy: 0.8424 - auc: 0.8861 - val_loss: 0.1278 - val_accuracy: 0.8560 - val_auc: 0.8962\n",
      "Epoch 5/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1291 - accuracy: 0.8441 - auc: 0.8911\n",
      "Epoch 5: val_accuracy improved from 0.85596 to 0.85780, saving model to \\saved_models1_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1289 - accuracy: 0.8444 - auc: 0.8913 - val_loss: 0.1208 - val_accuracy: 0.8578 - val_auc: 0.9002\n",
      "Epoch 6/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.8443 - auc: 0.8950\n",
      "Epoch 6: val_accuracy did not improve from 0.85780\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.8444 - auc: 0.8952 - val_loss: 0.1172 - val_accuracy: 0.8573 - val_auc: 0.9031\n",
      "Epoch 7/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.8450 - auc: 0.8989\n",
      "Epoch 7: val_accuracy improved from 0.85780 to 0.85873, saving model to \\saved_models1_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.8449 - auc: 0.8990 - val_loss: 0.1150 - val_accuracy: 0.8587 - val_auc: 0.9061\n",
      "Epoch 8/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1200 - accuracy: 0.8451 - auc: 0.9016\n",
      "Epoch 8: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1199 - accuracy: 0.8453 - auc: 0.9021 - val_loss: 0.1138 - val_accuracy: 0.8583 - val_auc: 0.9081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.8452 - auc: 0.9048\n",
      "Epoch 9: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.8454 - auc: 0.9048 - val_loss: 0.1129 - val_accuracy: 0.8573 - val_auc: 0.9104\n",
      "Epoch 10/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.8464 - auc: 0.9068\n",
      "Epoch 10: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.8457 - auc: 0.9066 - val_loss: 0.1122 - val_accuracy: 0.8573 - val_auc: 0.9122\n",
      "Epoch 11/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1174 - accuracy: 0.8452 - auc: 0.9085\n",
      "Epoch 11: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.8461 - auc: 0.9089 - val_loss: 0.1118 - val_accuracy: 0.8569 - val_auc: 0.9136\n",
      "Epoch 12/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.8458 - auc: 0.9103\n",
      "Epoch 12: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1163 - accuracy: 0.8457 - auc: 0.9104 - val_loss: 0.1110 - val_accuracy: 0.8583 - val_auc: 0.9156\n",
      "Epoch 13/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.8463 - auc: 0.9124\n",
      "Epoch 13: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8461 - auc: 0.9122 - val_loss: 0.1103 - val_accuracy: 0.8573 - val_auc: 0.9176\n",
      "Epoch 14/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1146 - accuracy: 0.8469 - auc: 0.9140\n",
      "Epoch 14: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1148 - accuracy: 0.8465 - auc: 0.9139 - val_loss: 0.1096 - val_accuracy: 0.8587 - val_auc: 0.9189\n",
      "Epoch 15/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1141 - accuracy: 0.8464 - auc: 0.9154\n",
      "Epoch 15: val_accuracy did not improve from 0.85873\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.8465 - auc: 0.9156 - val_loss: 0.1092 - val_accuracy: 0.8578 - val_auc: 0.9198\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.8587 - auc: 0.9061\n",
      "Epoch 1/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.7045 - auc: 0.7540\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82217, saving model to \\saved_models1_2/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2378 - accuracy: 0.7060 - auc: 0.7559 - val_loss: 0.2224 - val_accuracy: 0.8222 - val_auc: 0.8682\n",
      "Epoch 2/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.8365 - auc: 0.8651\n",
      "Epoch 2: val_accuracy improved from 0.82217 to 0.85035, saving model to \\saved_models1_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2075 - accuracy: 0.8365 - auc: 0.8651 - val_loss: 0.1878 - val_accuracy: 0.8503 - val_auc: 0.8777\n",
      "Epoch 3/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.8461 - auc: 0.8690\n",
      "Epoch 3: val_accuracy did not improve from 0.85035\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1737 - accuracy: 0.8463 - auc: 0.8692 - val_loss: 0.1550 - val_accuracy: 0.8499 - val_auc: 0.8799\n",
      "Epoch 4/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1484 - accuracy: 0.8471 - auc: 0.8712\n",
      "Epoch 4: val_accuracy did not improve from 0.85035\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1481 - accuracy: 0.8463 - auc: 0.8711 - val_loss: 0.1355 - val_accuracy: 0.8499 - val_auc: 0.8813\n",
      "Epoch 5/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1348 - accuracy: 0.8467 - auc: 0.8739\n",
      "Epoch 5: val_accuracy did not improve from 0.85035\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1349 - accuracy: 0.8464 - auc: 0.8731 - val_loss: 0.1266 - val_accuracy: 0.8499 - val_auc: 0.8832\n",
      "Epoch 6/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1293 - accuracy: 0.8465 - auc: 0.8754\n",
      "Epoch 6: val_accuracy did not improve from 0.85035\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1291 - accuracy: 0.8467 - auc: 0.8758 - val_loss: 0.1225 - val_accuracy: 0.8490 - val_auc: 0.8846\n",
      "Epoch 7/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.8472 - auc: 0.8778\n",
      "Epoch 7: val_accuracy did not improve from 0.85035\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1264 - accuracy: 0.8469 - auc: 0.8777 - val_loss: 0.1206 - val_accuracy: 0.8490 - val_auc: 0.8862\n",
      "Epoch 8/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.8469 - auc: 0.8801\n",
      "Epoch 8: val_accuracy did not improve from 0.85035\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.8469 - auc: 0.8801 - val_loss: 0.1195 - val_accuracy: 0.8494 - val_auc: 0.8881\n",
      "Epoch 9/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1243 - accuracy: 0.8481 - auc: 0.8813\n",
      "Epoch 9: val_accuracy improved from 0.85035 to 0.85081, saving model to \\saved_models1_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1244 - accuracy: 0.8473 - auc: 0.8819 - val_loss: 0.1189 - val_accuracy: 0.8508 - val_auc: 0.8900\n",
      "Epoch 10/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1237 - accuracy: 0.8474 - auc: 0.8842\n",
      "Epoch 10: val_accuracy did not improve from 0.85081\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1239 - accuracy: 0.8472 - auc: 0.8837 - val_loss: 0.1185 - val_accuracy: 0.8508 - val_auc: 0.8916\n",
      "Epoch 11/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1236 - accuracy: 0.8472 - auc: 0.8857\n",
      "Epoch 11: val_accuracy did not improve from 0.85081\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.8473 - auc: 0.8857 - val_loss: 0.1181 - val_accuracy: 0.8508 - val_auc: 0.8928\n",
      "Epoch 12/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1229 - accuracy: 0.8482 - auc: 0.8877\n",
      "Epoch 12: val_accuracy did not improve from 0.85081\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1233 - accuracy: 0.8472 - auc: 0.8875 - val_loss: 0.1178 - val_accuracy: 0.8508 - val_auc: 0.8943\n",
      "Epoch 13/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1230 - accuracy: 0.8474 - auc: 0.8880\n",
      "Epoch 13: val_accuracy did not improve from 0.85081\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.8476 - auc: 0.8887 - val_loss: 0.1176 - val_accuracy: 0.8508 - val_auc: 0.8959\n",
      "Epoch 14/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1224 - accuracy: 0.8483 - auc: 0.8908\n",
      "Epoch 14: val_accuracy did not improve from 0.85081\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1227 - accuracy: 0.8478 - auc: 0.8904 - val_loss: 0.1173 - val_accuracy: 0.8508 - val_auc: 0.8967\n",
      "Epoch 15/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1226 - accuracy: 0.8476 - auc: 0.8914\n",
      "Epoch 15: val_accuracy did not improve from 0.85081\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.8477 - auc: 0.8916 - val_loss: 0.1171 - val_accuracy: 0.8508 - val_auc: 0.8979\n",
      "68/68 [==============================] - 0s 875us/step - loss: 0.1189 - accuracy: 0.8508 - auc: 0.8900\n",
      "Epoch 1/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2434 - accuracy: 0.6368 - auc: 0.6893\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79630, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2426 - accuracy: 0.6481 - auc: 0.7032 - val_loss: 0.2297 - val_accuracy: 0.7963 - val_auc: 0.8640\n",
      "Epoch 2/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.2167 - accuracy: 0.8235 - auc: 0.8627\n",
      "Epoch 2: val_accuracy improved from 0.79630 to 0.84804, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2158 - accuracy: 0.8249 - auc: 0.8634 - val_loss: 0.1976 - val_accuracy: 0.8480 - val_auc: 0.8812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1825 - accuracy: 0.8430 - auc: 0.8720\n",
      "Epoch 3: val_accuracy improved from 0.84804 to 0.84942, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1818 - accuracy: 0.8431 - auc: 0.8715 - val_loss: 0.1620 - val_accuracy: 0.8494 - val_auc: 0.8867\n",
      "Epoch 4/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1529 - accuracy: 0.8444 - auc: 0.8769\n",
      "Epoch 4: val_accuracy did not improve from 0.84942\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1523 - accuracy: 0.8443 - auc: 0.8770 - val_loss: 0.1384 - val_accuracy: 0.8490 - val_auc: 0.8913\n",
      "Epoch 5/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1363 - accuracy: 0.8443 - auc: 0.8808\n",
      "Epoch 5: val_accuracy improved from 0.84942 to 0.84988, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1360 - accuracy: 0.8444 - auc: 0.8813 - val_loss: 0.1271 - val_accuracy: 0.8499 - val_auc: 0.8947\n",
      "Epoch 6/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1287 - accuracy: 0.8443 - auc: 0.8853\n",
      "Epoch 6: val_accuracy improved from 0.84988 to 0.85173, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1284 - accuracy: 0.8447 - auc: 0.8854 - val_loss: 0.1219 - val_accuracy: 0.8517 - val_auc: 0.8981\n",
      "Epoch 7/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.8449 - auc: 0.8890\n",
      "Epoch 7: val_accuracy improved from 0.85173 to 0.85219, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1249 - accuracy: 0.8450 - auc: 0.8892 - val_loss: 0.1194 - val_accuracy: 0.8522 - val_auc: 0.9005\n",
      "Epoch 8/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1230 - accuracy: 0.8451 - auc: 0.8922\n",
      "Epoch 8: val_accuracy did not improve from 0.85219\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1231 - accuracy: 0.8451 - auc: 0.8921 - val_loss: 0.1179 - val_accuracy: 0.8517 - val_auc: 0.9033\n",
      "Epoch 9/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1215 - accuracy: 0.8464 - auc: 0.8955\n",
      "Epoch 9: val_accuracy improved from 0.85219 to 0.85358, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.8457 - auc: 0.8946 - val_loss: 0.1171 - val_accuracy: 0.8536 - val_auc: 0.9044\n",
      "Epoch 10/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.8458 - auc: 0.8968\n",
      "Epoch 10: val_accuracy did not improve from 0.85358\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1212 - accuracy: 0.8458 - auc: 0.8969 - val_loss: 0.1164 - val_accuracy: 0.8536 - val_auc: 0.9062\n",
      "Epoch 11/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1207 - accuracy: 0.8456 - auc: 0.8986\n",
      "Epoch 11: val_accuracy did not improve from 0.85358\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.8457 - auc: 0.8986 - val_loss: 0.1159 - val_accuracy: 0.8536 - val_auc: 0.9071\n",
      "Epoch 12/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1200 - accuracy: 0.8463 - auc: 0.9005\n",
      "Epoch 12: val_accuracy improved from 0.85358 to 0.85404, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.8463 - auc: 0.9003 - val_loss: 0.1155 - val_accuracy: 0.8540 - val_auc: 0.9080\n",
      "Epoch 13/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1191 - accuracy: 0.8470 - auc: 0.9025\n",
      "Epoch 13: val_accuracy did not improve from 0.85404\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1197 - accuracy: 0.8463 - auc: 0.9017 - val_loss: 0.1150 - val_accuracy: 0.8536 - val_auc: 0.9093\n",
      "Epoch 14/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.8464 - auc: 0.9029\n",
      "Epoch 14: val_accuracy improved from 0.85404 to 0.85450, saving model to \\saved_models1_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1192 - accuracy: 0.8463 - auc: 0.9029 - val_loss: 0.1146 - val_accuracy: 0.8545 - val_auc: 0.9094\n",
      "Epoch 15/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.8470 - auc: 0.9037\n",
      "Epoch 15: val_accuracy did not improve from 0.85450\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1188 - accuracy: 0.8469 - auc: 0.9040 - val_loss: 0.1143 - val_accuracy: 0.8545 - val_auc: 0.9102\n",
      "68/68 [==============================] - 0s 877us/step - loss: 0.1146 - accuracy: 0.8545 - auc: 0.9094\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY12 = []\n",
    "VALIDATION_AUC12 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names1].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names1].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names1):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep4')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep5')(deep_branch) # added this!\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model12 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model12.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models1_2/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history12 = model12.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model12.load_weights(\"\\saved_models1_2/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model12.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model12.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY12.append(results['accuracy'])\n",
    "    VALIDATION_AUC12.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history12.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history12.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history12.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history12.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8522622585296631 | 0.9311910271644592 |\n",
      "|  2   | 0.8559556603431702 | 0.933461606502533  |\n",
      "|  3   | 0.8393352031707764 | 0.885219931602478  |\n",
      "|  4   | 0.8199446201324463 | 0.8713917136192322 |\n",
      "|  5   | 0.8550323247909546 | 0.9221787452697754 |\n",
      "|  6   | 0.8508771657943726 | 0.8838908672332764 |\n",
      "|  7   | 0.8508771657943726 | 0.9060196876525879 |\n",
      "|  8   | 0.8587257862091064 | 0.9061406254768372 |\n",
      "|  9   | 0.850808322429657  | 0.890036940574646  |\n",
      "|  10  | 0.8545034527778625 | 0.9094327688217163 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY12)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC12)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 8\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY12.index(max(VALIDATION_ACCURACY12))\n",
    "max_fold12 = idx + 1\n",
    "print(\"Best Fold:\", max_fold12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 1000us/step - loss: 0.1466 - accuracy: 0.8031 - auc: 0.8629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.146638423204422, 0.8030573129653931, 0.8628939986228943]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model12.load_weights(\"\\saved_models1_2/model_\"+str(max_fold12)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model12.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 788us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model12.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat12 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Generalization Performance for W/D 1 - McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd1 = pd.DataFrame()\n",
    "wd1['Deep'] = list(chain.from_iterable(yhat1))\n",
    "wd1['Deeper'] = list(chain.from_iterable(yhat11))\n",
    "wd1['Deepest'] = list(chain.from_iterable(yhat12))\n",
    "wd1['Truth'] = list(chain.from_iterable(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5126\n",
       "D     982\n",
       "B     337\n",
       "C     293\n",
       "Name: Matrix1v2, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd1['Deep'] == wd1['Truth']) & (wd1['Deeper'] == wd1['Truth']), # both models are right (A)\n",
    "    (wd1['Deep'] == wd1['Truth']) & (wd1['Deeper'] != wd1['Truth']), # model 1 is right, model 2 is wrong (B)\n",
    "    (wd1['Deep'] != wd1['Truth']) & (wd1['Deeper'] == wd1['Truth']), # model 1 is wrong, model 2 is right (C)\n",
    "    (wd1['Deep'] != wd1['Truth']) & (wd1['Deeper'] != wd1['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd1['Matrix1v2'] = np.select(conditions, choices, default = '0')\n",
    "wd1.Matrix1v2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.935\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd1['Matrix1v2'] == 'B')\n",
    "C = sum(wd1['Matrix1v2'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2.935 < 3.841 ($\\alpha$ = 0.05 significance level), we fail to reject the null hypothesis that the models are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5121\n",
       "D     985\n",
       "B     342\n",
       "C     290\n",
       "Name: Matrix1v3, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd1['Deep'] == wd1['Truth']) & (wd1['Deepest'] == wd1['Truth']), # both models are right (A)\n",
    "    (wd1['Deep'] == wd1['Truth']) & (wd1['Deepest'] != wd1['Truth']), # model 1 is right, model 2 is wrong (B)\n",
    "    (wd1['Deep'] != wd1['Truth']) & (wd1['Deepest'] == wd1['Truth']), # model 1 is wrong, model 2 is right (C)\n",
    "    (wd1['Deep'] != wd1['Truth']) & (wd1['Deepest'] != wd1['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd1['Matrix1v3'] = np.select(conditions, choices, default = '0')\n",
    "wd1.Matrix1v3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.116\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd1['Matrix1v3'] == 'B')\n",
    "C = sum(wd1['Matrix1v3'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 4.116 > 3.841 ($\\alpha$ = 0.05 significance level), there is sufficient evidence to reject the null hypothesis that the models are the same and conclude that the Deep and Deepest Models of Network 1 are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      3112\n",
      "           1       0.82      0.83      0.82      3626\n",
      "\n",
      "    accuracy                           0.81      6738\n",
      "   macro avg       0.81      0.81      0.81      6738\n",
      "weighted avg       0.81      0.81      0.81      6738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      3112\n",
      "           1       0.83      0.80      0.81      3626\n",
      "\n",
      "    accuracy                           0.80      6738\n",
      "   macro avg       0.80      0.80      0.80      6738\n",
      "weighted avg       0.80      0.80      0.80      6738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mt.classification_report(y_test,yhat1))\n",
    "print(mt.classification_report(y_test,yhat12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of accuracy, the more shallow model (WD 1) is better than the model with two additional deep layers (WD 1.2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 2 - More Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.5480 - auc: 0.6283\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57202, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 8139s 3ms/step - loss: 0.2435 - accuracy: 0.5483 - auc: 0.6288 - val_loss: 0.2384 - val_accuracy: 0.5720 - val_auc: 0.6917\n",
      "Epoch 2/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2329 - accuracy: 0.5992 - auc: 0.7159\n",
      "Epoch 2: val_accuracy improved from 0.57202 to 0.67498, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.6001 - auc: 0.7150 - val_loss: 0.2220 - val_accuracy: 0.6750 - val_auc: 0.7642\n",
      "Epoch 3/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.2137 - accuracy: 0.6973 - auc: 0.7762\n",
      "Epoch 3: val_accuracy improved from 0.67498 to 0.74054, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.7007 - auc: 0.7791 - val_loss: 0.1974 - val_accuracy: 0.7405 - val_auc: 0.8210\n",
      "Epoch 4/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.7496 - auc: 0.8265\n",
      "Epoch 4: val_accuracy improved from 0.74054 to 0.77655, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.7502 - auc: 0.8270 - val_loss: 0.1730 - val_accuracy: 0.7765 - val_auc: 0.8581\n",
      "Epoch 5/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1668 - accuracy: 0.7773 - auc: 0.8579\n",
      "Epoch 5: val_accuracy improved from 0.77655 to 0.79917, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1664 - accuracy: 0.7780 - auc: 0.8586 - val_loss: 0.1537 - val_accuracy: 0.7992 - val_auc: 0.8795\n",
      "Epoch 6/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.7963 - auc: 0.8802\n",
      "Epoch 6: val_accuracy improved from 0.79917 to 0.81579, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1494 - accuracy: 0.7961 - auc: 0.8795 - val_loss: 0.1391 - val_accuracy: 0.8158 - val_auc: 0.8926\n",
      "Epoch 7/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1367 - accuracy: 0.8081 - auc: 0.8934\n",
      "Epoch 7: val_accuracy improved from 0.81579 to 0.82271, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1364 - accuracy: 0.8084 - auc: 0.8938 - val_loss: 0.1279 - val_accuracy: 0.8227 - val_auc: 0.9050\n",
      "Epoch 8/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.8192 - auc: 0.9049\n",
      "Epoch 8: val_accuracy improved from 0.82271 to 0.83149, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1270 - accuracy: 0.8191 - auc: 0.9051 - val_loss: 0.1208 - val_accuracy: 0.8315 - val_auc: 0.9130\n",
      "Epoch 9/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1208 - accuracy: 0.8288 - auc: 0.9127\n",
      "Epoch 9: val_accuracy improved from 0.83149 to 0.84026, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1204 - accuracy: 0.8293 - auc: 0.9132 - val_loss: 0.1156 - val_accuracy: 0.8403 - val_auc: 0.9194\n",
      "Epoch 10/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1164 - accuracy: 0.8327 - auc: 0.9184\n",
      "Epoch 10: val_accuracy improved from 0.84026 to 0.84211, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8344 - auc: 0.9194 - val_loss: 0.1119 - val_accuracy: 0.8421 - val_auc: 0.9240\n",
      "Epoch 11/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1115 - accuracy: 0.8400 - auc: 0.9247\n",
      "Epoch 11: val_accuracy improved from 0.84211 to 0.84672, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1118 - accuracy: 0.8399 - auc: 0.9242 - val_loss: 0.1086 - val_accuracy: 0.8467 - val_auc: 0.9281\n",
      "Epoch 12/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1085 - accuracy: 0.8432 - auc: 0.9284\n",
      "Epoch 12: val_accuracy did not improve from 0.84672\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1087 - accuracy: 0.8427 - auc: 0.9282 - val_loss: 0.1064 - val_accuracy: 0.8458 - val_auc: 0.9309\n",
      "Epoch 13/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1059 - accuracy: 0.8473 - auc: 0.9317\n",
      "Epoch 13: val_accuracy improved from 0.84672 to 0.85042, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.8475 - auc: 0.9318 - val_loss: 0.1045 - val_accuracy: 0.8504 - val_auc: 0.9334\n",
      "Epoch 14/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1028 - accuracy: 0.8518 - auc: 0.9352\n",
      "Epoch 14: val_accuracy improved from 0.85042 to 0.85180, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1031 - accuracy: 0.8511 - auc: 0.9349 - val_loss: 0.1024 - val_accuracy: 0.8518 - val_auc: 0.9358\n",
      "Epoch 15/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.8566 - auc: 0.9381\n",
      "Epoch 15: val_accuracy improved from 0.85180 to 0.85596, saving model to \\saved_models2_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1004 - accuracy: 0.8566 - auc: 0.9380 - val_loss: 0.1003 - val_accuracy: 0.8560 - val_auc: 0.9385\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.8560 - auc: 0.9385\n",
      "Epoch 1/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.5105 - auc: 0.5202\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51524, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2490 - accuracy: 0.5113 - auc: 0.5217 - val_loss: 0.2467 - val_accuracy: 0.5152 - val_auc: 0.6284\n",
      "Epoch 2/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.2425 - accuracy: 0.5421 - auc: 0.6513\n",
      "Epoch 2: val_accuracy improved from 0.51524 to 0.52724, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.5416 - auc: 0.6522 - val_loss: 0.2408 - val_accuracy: 0.5272 - val_auc: 0.6950\n",
      "Epoch 3/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.5877 - auc: 0.7001\n",
      "Epoch 3: val_accuracy improved from 0.52724 to 0.62512, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2340 - accuracy: 0.5904 - auc: 0.7018 - val_loss: 0.2301 - val_accuracy: 0.6251 - val_auc: 0.7292\n",
      "Epoch 4/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.2212 - accuracy: 0.6635 - auc: 0.7320\n",
      "Epoch 4: val_accuracy improved from 0.62512 to 0.70129, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2206 - accuracy: 0.6657 - auc: 0.7342 - val_loss: 0.2129 - val_accuracy: 0.7013 - val_auc: 0.7614\n",
      "Epoch 5/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.7008 - auc: 0.7677\n",
      "Epoch 5: val_accuracy improved from 0.70129 to 0.72761, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2027 - accuracy: 0.7006 - auc: 0.7682 - val_loss: 0.1918 - val_accuracy: 0.7276 - val_auc: 0.7991\n",
      "Epoch 6/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1816 - accuracy: 0.7324 - auc: 0.8096\n",
      "Epoch 6: val_accuracy improved from 0.72761 to 0.76223, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7326 - auc: 0.8098 - val_loss: 0.1688 - val_accuracy: 0.7622 - val_auc: 0.8410\n",
      "Epoch 7/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.7643 - auc: 0.8502\n",
      "Epoch 7: val_accuracy improved from 0.76223 to 0.79178, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1595 - accuracy: 0.7659 - auc: 0.8515 - val_loss: 0.1467 - val_accuracy: 0.7918 - val_auc: 0.8739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1423 - accuracy: 0.7915 - auc: 0.8797\n",
      "Epoch 8: val_accuracy improved from 0.79178 to 0.80840, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.7922 - auc: 0.8805 - val_loss: 0.1331 - val_accuracy: 0.8084 - val_auc: 0.8952\n",
      "Epoch 9/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1306 - accuracy: 0.8098 - auc: 0.8975\n",
      "Epoch 9: val_accuracy improved from 0.80840 to 0.82041, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1301 - accuracy: 0.8109 - auc: 0.8983 - val_loss: 0.1238 - val_accuracy: 0.8204 - val_auc: 0.9086\n",
      "Epoch 10/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1222 - accuracy: 0.8230 - auc: 0.9097\n",
      "Epoch 10: val_accuracy improved from 0.82041 to 0.82225, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.8226 - auc: 0.9096 - val_loss: 0.1190 - val_accuracy: 0.8223 - val_auc: 0.9168\n",
      "Epoch 11/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1170 - accuracy: 0.8311 - auc: 0.9168\n",
      "Epoch 11: val_accuracy improved from 0.82225 to 0.83887, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.8315 - auc: 0.9171 - val_loss: 0.1121 - val_accuracy: 0.8389 - val_auc: 0.9237\n",
      "Epoch 12/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1130 - accuracy: 0.8363 - auc: 0.9220\n",
      "Epoch 12: val_accuracy improved from 0.83887 to 0.84441, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.8362 - auc: 0.9220 - val_loss: 0.1094 - val_accuracy: 0.8444 - val_auc: 0.9273\n",
      "Epoch 13/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.8415 - auc: 0.9259\n",
      "Epoch 13: val_accuracy did not improve from 0.84441\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.8408 - auc: 0.9255 - val_loss: 0.1069 - val_accuracy: 0.8426 - val_auc: 0.9297\n",
      "Epoch 14/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1085 - accuracy: 0.8433 - auc: 0.9278\n",
      "Epoch 14: val_accuracy improved from 0.84441 to 0.85042, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.8432 - auc: 0.9276 - val_loss: 0.1059 - val_accuracy: 0.8504 - val_auc: 0.9315\n",
      "Epoch 15/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1071 - accuracy: 0.8474 - auc: 0.9295\n",
      "Epoch 15: val_accuracy improved from 0.85042 to 0.85272, saving model to \\saved_models2_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.8471 - auc: 0.9295 - val_loss: 0.1045 - val_accuracy: 0.8527 - val_auc: 0.9329\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.8527 - auc: 0.9329\n",
      "Epoch 1/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.5404 - auc: 0.5818\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55586, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2470 - accuracy: 0.5408 - auc: 0.5832 - val_loss: 0.2447 - val_accuracy: 0.5559 - val_auc: 0.6211\n",
      "Epoch 2/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.5435 - auc: 0.6807\n",
      "Epoch 2: val_accuracy improved from 0.55586 to 0.57110, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2412 - accuracy: 0.5445 - auc: 0.6815 - val_loss: 0.2377 - val_accuracy: 0.5711 - val_auc: 0.6813\n",
      "Epoch 3/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.6122 - auc: 0.7465\n",
      "Epoch 3: val_accuracy improved from 0.57110 to 0.65605, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2284 - accuracy: 0.6127 - auc: 0.7466 - val_loss: 0.2217 - val_accuracy: 0.6560 - val_auc: 0.7397\n",
      "Epoch 4/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.7093 - auc: 0.7938\n",
      "Epoch 4: val_accuracy improved from 0.65605 to 0.71099, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2065 - accuracy: 0.7106 - auc: 0.7946 - val_loss: 0.1999 - val_accuracy: 0.7110 - val_auc: 0.7925\n",
      "Epoch 5/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1832 - accuracy: 0.7536 - auc: 0.8365\n",
      "Epoch 5: val_accuracy improved from 0.71099 to 0.75300, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1823 - accuracy: 0.7552 - auc: 0.8377 - val_loss: 0.1781 - val_accuracy: 0.7530 - val_auc: 0.8348\n",
      "Epoch 6/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1611 - accuracy: 0.7842 - auc: 0.8689\n",
      "Epoch 6: val_accuracy improved from 0.75300 to 0.77424, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1607 - accuracy: 0.7847 - auc: 0.8689 - val_loss: 0.1607 - val_accuracy: 0.7742 - val_auc: 0.8610\n",
      "Epoch 7/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.8014 - auc: 0.8882\n",
      "Epoch 7: val_accuracy improved from 0.77424 to 0.78947, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1445 - accuracy: 0.8015 - auc: 0.8881 - val_loss: 0.1479 - val_accuracy: 0.7895 - val_auc: 0.8769\n",
      "Epoch 8/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.8121 - auc: 0.8996\n",
      "Epoch 8: val_accuracy improved from 0.78947 to 0.80194, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1331 - accuracy: 0.8125 - auc: 0.9001 - val_loss: 0.1388 - val_accuracy: 0.8019 - val_auc: 0.8882\n",
      "Epoch 9/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1258 - accuracy: 0.8205 - auc: 0.9083\n",
      "Epoch 9: val_accuracy improved from 0.80194 to 0.80332, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1253 - accuracy: 0.8213 - auc: 0.9087 - val_loss: 0.1338 - val_accuracy: 0.8033 - val_auc: 0.8947\n",
      "Epoch 10/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1204 - accuracy: 0.8290 - auc: 0.9138\n",
      "Epoch 10: val_accuracy improved from 0.80332 to 0.80702, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.8291 - auc: 0.9143 - val_loss: 0.1295 - val_accuracy: 0.8070 - val_auc: 0.9015\n",
      "Epoch 11/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.8354 - auc: 0.9190\n",
      "Epoch 11: val_accuracy improved from 0.80702 to 0.80794, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.8354 - auc: 0.9190 - val_loss: 0.1267 - val_accuracy: 0.8079 - val_auc: 0.9057\n",
      "Epoch 12/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1135 - accuracy: 0.8380 - auc: 0.9221\n",
      "Epoch 12: val_accuracy improved from 0.80794 to 0.81210, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.8382 - auc: 0.9224 - val_loss: 0.1239 - val_accuracy: 0.8121 - val_auc: 0.9093\n",
      "Epoch 13/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.8416 - auc: 0.9251\n",
      "Epoch 13: val_accuracy improved from 0.81210 to 0.81533, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1109 - accuracy: 0.8421 - auc: 0.9252 - val_loss: 0.1221 - val_accuracy: 0.8153 - val_auc: 0.9115\n",
      "Epoch 14/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1085 - accuracy: 0.8457 - auc: 0.9283\n",
      "Epoch 14: val_accuracy improved from 0.81533 to 0.81810, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.8449 - auc: 0.9278 - val_loss: 0.1195 - val_accuracy: 0.8181 - val_auc: 0.9150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.8461 - auc: 0.9296\n",
      "Epoch 15: val_accuracy improved from 0.81810 to 0.82271, saving model to \\saved_models2_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1070 - accuracy: 0.8464 - auc: 0.9299 - val_loss: 0.1189 - val_accuracy: 0.8227 - val_auc: 0.9160\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.8227 - auc: 0.9160\n",
      "Epoch 1/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.5499 - auc: 0.5527\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55494, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2478 - accuracy: 0.5499 - auc: 0.5528 - val_loss: 0.2462 - val_accuracy: 0.5549 - val_auc: 0.6005\n",
      "Epoch 2/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.5938 - auc: 0.6423\n",
      "Epoch 2: val_accuracy improved from 0.55494 to 0.61773, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.5938 - auc: 0.6425 - val_loss: 0.2382 - val_accuracy: 0.6177 - val_auc: 0.6877\n",
      "Epoch 3/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.2277 - accuracy: 0.6587 - auc: 0.7240\n",
      "Epoch 3: val_accuracy improved from 0.61773 to 0.69114, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2270 - accuracy: 0.6599 - auc: 0.7250 - val_loss: 0.2125 - val_accuracy: 0.6911 - val_auc: 0.7698\n",
      "Epoch 4/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.7281 - auc: 0.7998\n",
      "Epoch 4: val_accuracy improved from 0.69114 to 0.74931, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1907 - accuracy: 0.7293 - auc: 0.8016 - val_loss: 0.1713 - val_accuracy: 0.7493 - val_auc: 0.8375\n",
      "Epoch 5/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1531 - accuracy: 0.7793 - auc: 0.8637\n",
      "Epoch 5: val_accuracy improved from 0.74931 to 0.78024, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1530 - accuracy: 0.7795 - auc: 0.8639 - val_loss: 0.1463 - val_accuracy: 0.7802 - val_auc: 0.8731\n",
      "Epoch 6/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.8128 - auc: 0.8983\n",
      "Epoch 6: val_accuracy improved from 0.78024 to 0.79271, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1303 - accuracy: 0.8123 - auc: 0.8980 - val_loss: 0.1378 - val_accuracy: 0.7927 - val_auc: 0.8862\n",
      "Epoch 7/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1192 - accuracy: 0.8284 - auc: 0.9132\n",
      "Epoch 7: val_accuracy did not improve from 0.79271\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.8278 - auc: 0.9123 - val_loss: 0.1345 - val_accuracy: 0.7922 - val_auc: 0.8927\n",
      "Epoch 8/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.8349 - auc: 0.9203\n",
      "Epoch 8: val_accuracy improved from 0.79271 to 0.80194, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.8346 - auc: 0.9200 - val_loss: 0.1320 - val_accuracy: 0.8019 - val_auc: 0.8976\n",
      "Epoch 9/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1104 - accuracy: 0.8413 - auc: 0.9247\n",
      "Epoch 9: val_accuracy improved from 0.80194 to 0.80563, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1105 - accuracy: 0.8411 - auc: 0.9247 - val_loss: 0.1295 - val_accuracy: 0.8056 - val_auc: 0.9014\n",
      "Epoch 10/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.8454 - auc: 0.9284\n",
      "Epoch 10: val_accuracy improved from 0.80563 to 0.80933, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1078 - accuracy: 0.8453 - auc: 0.9282 - val_loss: 0.1275 - val_accuracy: 0.8093 - val_auc: 0.9044\n",
      "Epoch 11/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 0.8500 - auc: 0.9314\n",
      "Epoch 11: val_accuracy improved from 0.80933 to 0.81717, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1055 - accuracy: 0.8496 - auc: 0.9310 - val_loss: 0.1253 - val_accuracy: 0.8172 - val_auc: 0.9077\n",
      "Epoch 12/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1034 - accuracy: 0.8523 - auc: 0.9334\n",
      "Epoch 12: val_accuracy did not improve from 0.81717\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.8523 - auc: 0.9334 - val_loss: 0.1241 - val_accuracy: 0.8167 - val_auc: 0.9095\n",
      "Epoch 13/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.8564 - auc: 0.9360\n",
      "Epoch 13: val_accuracy improved from 0.81717 to 0.82548, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.8562 - auc: 0.9359 - val_loss: 0.1222 - val_accuracy: 0.8255 - val_auc: 0.9123\n",
      "Epoch 14/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.0995 - accuracy: 0.8589 - auc: 0.9382\n",
      "Epoch 14: val_accuracy did not improve from 0.82548\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.8590 - auc: 0.9383 - val_loss: 0.1256 - val_accuracy: 0.8126 - val_auc: 0.9122\n",
      "Epoch 15/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.0977 - accuracy: 0.8620 - auc: 0.9404\n",
      "Epoch 15: val_accuracy improved from 0.82548 to 0.83149, saving model to \\saved_models2_1/model_4.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.8633 - auc: 0.9409 - val_loss: 0.1181 - val_accuracy: 0.8315 - val_auc: 0.9178\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.8315 - auc: 0.9178\n",
      "Epoch 1/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.2483 - accuracy: 0.5473 - auc: 0.5560\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57525, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2483 - accuracy: 0.5479 - auc: 0.5572 - val_loss: 0.2462 - val_accuracy: 0.5753 - val_auc: 0.6087\n",
      "Epoch 2/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.5819 - auc: 0.6273\n",
      "Epoch 2: val_accuracy improved from 0.57525 to 0.61080, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.5822 - auc: 0.6269 - val_loss: 0.2419 - val_accuracy: 0.6108 - val_auc: 0.6607\n",
      "Epoch 3/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.2392 - accuracy: 0.6205 - auc: 0.6746\n",
      "Epoch 3: val_accuracy improved from 0.61080 to 0.65928, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2391 - accuracy: 0.6209 - auc: 0.6743 - val_loss: 0.2331 - val_accuracy: 0.6593 - val_auc: 0.7003\n",
      "Epoch 4/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.6619 - auc: 0.7141\n",
      "Epoch 4: val_accuracy improved from 0.65928 to 0.68513, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2273 - accuracy: 0.6624 - auc: 0.7145 - val_loss: 0.2172 - val_accuracy: 0.6851 - val_auc: 0.7411\n",
      "Epoch 5/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.6932 - auc: 0.7556\n",
      "Epoch 5: val_accuracy improved from 0.68513 to 0.71145, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2094 - accuracy: 0.6927 - auc: 0.7551 - val_loss: 0.1975 - val_accuracy: 0.7114 - val_auc: 0.7814\n",
      "Epoch 6/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1892 - accuracy: 0.7267 - auc: 0.7983\n",
      "Epoch 6: val_accuracy improved from 0.71145 to 0.75254, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1890 - accuracy: 0.7269 - auc: 0.7984 - val_loss: 0.1756 - val_accuracy: 0.7525 - val_auc: 0.8242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.7599 - auc: 0.8374\n",
      "Epoch 7: val_accuracy improved from 0.75254 to 0.78809, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.7597 - auc: 0.8374 - val_loss: 0.1552 - val_accuracy: 0.7881 - val_auc: 0.8632\n",
      "Epoch 8/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.7858 - auc: 0.8690\n",
      "Epoch 8: val_accuracy improved from 0.78809 to 0.80240, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1500 - accuracy: 0.7864 - auc: 0.8693 - val_loss: 0.1390 - val_accuracy: 0.8024 - val_auc: 0.8882\n",
      "Epoch 9/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.8052 - auc: 0.8905\n",
      "Epoch 9: val_accuracy improved from 0.80240 to 0.81579, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.8050 - auc: 0.8906 - val_loss: 0.1284 - val_accuracy: 0.8158 - val_auc: 0.9046\n",
      "Epoch 10/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.8200 - auc: 0.9051\n",
      "Epoch 10: val_accuracy improved from 0.81579 to 0.82733, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1261 - accuracy: 0.8200 - auc: 0.9051 - val_loss: 0.1207 - val_accuracy: 0.8273 - val_auc: 0.9142\n",
      "Epoch 11/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 0.8281 - auc: 0.9140\n",
      "Epoch 11: val_accuracy improved from 0.82733 to 0.83795, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1191 - accuracy: 0.8285 - auc: 0.9144 - val_loss: 0.1147 - val_accuracy: 0.8380 - val_auc: 0.9219\n",
      "Epoch 12/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1143 - accuracy: 0.8365 - auc: 0.9207\n",
      "Epoch 12: val_accuracy improved from 0.83795 to 0.84303, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1143 - accuracy: 0.8364 - auc: 0.9207 - val_loss: 0.1109 - val_accuracy: 0.8430 - val_auc: 0.9266\n",
      "Epoch 13/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.8426 - auc: 0.9248\n",
      "Epoch 13: val_accuracy improved from 0.84303 to 0.84395, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1109 - accuracy: 0.8426 - auc: 0.9247 - val_loss: 0.1075 - val_accuracy: 0.8440 - val_auc: 0.9302\n",
      "Epoch 14/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1082 - accuracy: 0.8458 - auc: 0.9279\n",
      "Epoch 14: val_accuracy improved from 0.84395 to 0.84672, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1085 - accuracy: 0.8452 - auc: 0.9276 - val_loss: 0.1069 - val_accuracy: 0.8467 - val_auc: 0.9314\n",
      "Epoch 15/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.8497 - auc: 0.9299\n",
      "Epoch 15: val_accuracy improved from 0.84672 to 0.85042, saving model to \\saved_models2_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1067 - accuracy: 0.8494 - auc: 0.9299 - val_loss: 0.1033 - val_accuracy: 0.8504 - val_auc: 0.9347\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.8504 - auc: 0.9347\n",
      "Epoch 1/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.5516 - auc: 0.6146\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62327, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2465 - accuracy: 0.5527 - auc: 0.6146 - val_loss: 0.2421 - val_accuracy: 0.6233 - val_auc: 0.6708\n",
      "Epoch 2/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.2359 - accuracy: 0.6607 - auc: 0.7130\n",
      "Epoch 2: val_accuracy improved from 0.62327 to 0.68975, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2356 - accuracy: 0.6611 - auc: 0.7136 - val_loss: 0.2279 - val_accuracy: 0.6898 - val_auc: 0.7453\n",
      "Epoch 3/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.2160 - accuracy: 0.7004 - auc: 0.7689\n",
      "Epoch 3: val_accuracy improved from 0.68975 to 0.72853, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.7020 - auc: 0.7702 - val_loss: 0.2020 - val_accuracy: 0.7285 - val_auc: 0.7965\n",
      "Epoch 4/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1899 - accuracy: 0.7409 - auc: 0.8117\n",
      "Epoch 4: val_accuracy improved from 0.72853 to 0.76870, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1890 - accuracy: 0.7421 - auc: 0.8139 - val_loss: 0.1760 - val_accuracy: 0.7687 - val_auc: 0.8365\n",
      "Epoch 5/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1659 - accuracy: 0.7735 - auc: 0.8494\n",
      "Epoch 5: val_accuracy improved from 0.76870 to 0.78393, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1657 - accuracy: 0.7730 - auc: 0.8493 - val_loss: 0.1544 - val_accuracy: 0.7839 - val_auc: 0.8687\n",
      "Epoch 6/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.7979 - auc: 0.8770\n",
      "Epoch 6: val_accuracy improved from 0.78393 to 0.80379, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1470 - accuracy: 0.7974 - auc: 0.8769 - val_loss: 0.1381 - val_accuracy: 0.8038 - val_auc: 0.8933\n",
      "Epoch 7/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.8121 - auc: 0.8950\n",
      "Epoch 7: val_accuracy improved from 0.80379 to 0.82502, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1332 - accuracy: 0.8125 - auc: 0.8956 - val_loss: 0.1277 - val_accuracy: 0.8250 - val_auc: 0.9036\n",
      "Epoch 8/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.8223 - auc: 0.9083\n",
      "Epoch 8: val_accuracy improved from 0.82502 to 0.82918, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.8222 - auc: 0.9082 - val_loss: 0.1207 - val_accuracy: 0.8292 - val_auc: 0.9127\n",
      "Epoch 9/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.8315 - auc: 0.9163\n",
      "Epoch 9: val_accuracy improved from 0.82918 to 0.83795, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1171 - accuracy: 0.8320 - auc: 0.9168 - val_loss: 0.1159 - val_accuracy: 0.8380 - val_auc: 0.9192\n",
      "Epoch 10/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.8380 - auc: 0.9225\n",
      "Epoch 10: val_accuracy improved from 0.83795 to 0.84257, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1125 - accuracy: 0.8386 - auc: 0.9226 - val_loss: 0.1123 - val_accuracy: 0.8426 - val_auc: 0.9225\n",
      "Epoch 11/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.8446 - auc: 0.9265\n",
      "Epoch 11: val_accuracy improved from 0.84257 to 0.84395, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.8445 - auc: 0.9265 - val_loss: 0.1111 - val_accuracy: 0.8440 - val_auc: 0.9244\n",
      "Epoch 12/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 0.8485 - auc: 0.9293\n",
      "Epoch 12: val_accuracy improved from 0.84395 to 0.84441, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.8486 - auc: 0.9293 - val_loss: 0.1096 - val_accuracy: 0.8444 - val_auc: 0.9266\n",
      "Epoch 13/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 0.8523 - auc: 0.9313\n",
      "Epoch 13: val_accuracy improved from 0.84441 to 0.84857, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1049 - accuracy: 0.8526 - auc: 0.9316 - val_loss: 0.1068 - val_accuracy: 0.8486 - val_auc: 0.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1033 - accuracy: 0.8549 - auc: 0.9333\n",
      "Epoch 14: val_accuracy did not improve from 0.84857\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.8548 - auc: 0.9336 - val_loss: 0.1057 - val_accuracy: 0.8476 - val_auc: 0.9319\n",
      "Epoch 15/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.8588 - auc: 0.9359\n",
      "Epoch 15: val_accuracy improved from 0.84857 to 0.84903, saving model to \\saved_models2_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.8585 - auc: 0.9358 - val_loss: 0.1048 - val_accuracy: 0.8490 - val_auc: 0.9333\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.8490 - auc: 0.9333\n",
      "Epoch 1/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2486 - accuracy: 0.5293 - auc: 0.5285\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55402, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2486 - accuracy: 0.5292 - auc: 0.5284 - val_loss: 0.2466 - val_accuracy: 0.5540 - val_auc: 0.5640\n",
      "Epoch 2/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.2440 - accuracy: 0.5782 - auc: 0.6246\n",
      "Epoch 2: val_accuracy improved from 0.55402 to 0.60526, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.5786 - auc: 0.6258 - val_loss: 0.2405 - val_accuracy: 0.6053 - val_auc: 0.6497\n",
      "Epoch 3/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.2330 - accuracy: 0.6386 - auc: 0.7029\n",
      "Epoch 3: val_accuracy improved from 0.60526 to 0.67128, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2327 - accuracy: 0.6386 - auc: 0.7027 - val_loss: 0.2237 - val_accuracy: 0.6713 - val_auc: 0.7233\n",
      "Epoch 4/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.6953 - auc: 0.7664\n",
      "Epoch 4: val_accuracy improved from 0.67128 to 0.71930, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2061 - accuracy: 0.6953 - auc: 0.7667 - val_loss: 0.1918 - val_accuracy: 0.7193 - val_auc: 0.7874\n",
      "Epoch 5/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1729 - accuracy: 0.7473 - auc: 0.8280\n",
      "Epoch 5: val_accuracy improved from 0.71930 to 0.75716, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1722 - accuracy: 0.7480 - auc: 0.8289 - val_loss: 0.1610 - val_accuracy: 0.7572 - val_auc: 0.8456\n",
      "Epoch 6/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1457 - accuracy: 0.7877 - auc: 0.8745\n",
      "Epoch 6: val_accuracy improved from 0.75716 to 0.79455, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.7874 - auc: 0.8738 - val_loss: 0.1400 - val_accuracy: 0.7946 - val_auc: 0.8813\n",
      "Epoch 7/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.8099 - auc: 0.8984\n",
      "Epoch 7: val_accuracy improved from 0.79455 to 0.81071, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.8101 - auc: 0.8984 - val_loss: 0.1287 - val_accuracy: 0.8107 - val_auc: 0.8992\n",
      "Epoch 8/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.8238 - auc: 0.9117\n",
      "Epoch 8: val_accuracy improved from 0.81071 to 0.82318, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1209 - accuracy: 0.8239 - auc: 0.9115 - val_loss: 0.1214 - val_accuracy: 0.8232 - val_auc: 0.9088\n",
      "Epoch 9/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.8324 - auc: 0.9193\n",
      "Epoch 9: val_accuracy improved from 0.82318 to 0.83010, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.8321 - auc: 0.9191 - val_loss: 0.1171 - val_accuracy: 0.8301 - val_auc: 0.9155\n",
      "Epoch 10/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.8379 - auc: 0.9238\n",
      "Epoch 10: val_accuracy improved from 0.83010 to 0.83472, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1116 - accuracy: 0.8381 - auc: 0.9241 - val_loss: 0.1154 - val_accuracy: 0.8347 - val_auc: 0.9191\n",
      "Epoch 11/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1090 - accuracy: 0.8411 - auc: 0.9275\n",
      "Epoch 11: val_accuracy improved from 0.83472 to 0.83841, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8412 - auc: 0.9276 - val_loss: 0.1123 - val_accuracy: 0.8384 - val_auc: 0.9216\n",
      "Epoch 12/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1060 - accuracy: 0.8469 - auc: 0.9314\n",
      "Epoch 12: val_accuracy improved from 0.83841 to 0.84257, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.8455 - auc: 0.9303 - val_loss: 0.1097 - val_accuracy: 0.8426 - val_auc: 0.9252\n",
      "Epoch 13/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.8483 - auc: 0.9327\n",
      "Epoch 13: val_accuracy did not improve from 0.84257\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1049 - accuracy: 0.8483 - auc: 0.9327 - val_loss: 0.1092 - val_accuracy: 0.8421 - val_auc: 0.9275\n",
      "Epoch 14/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.8510 - auc: 0.9348\n",
      "Epoch 14: val_accuracy improved from 0.84257 to 0.84349, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.8512 - auc: 0.9348 - val_loss: 0.1068 - val_accuracy: 0.8435 - val_auc: 0.9290\n",
      "Epoch 15/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1008 - accuracy: 0.8564 - auc: 0.9377\n",
      "Epoch 15: val_accuracy improved from 0.84349 to 0.84626, saving model to \\saved_models2_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.8553 - auc: 0.9368 - val_loss: 0.1063 - val_accuracy: 0.8463 - val_auc: 0.9301\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.8463 - auc: 0.9301\n",
      "Epoch 1/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.5386 - auc: 0.5889\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53555, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2450 - accuracy: 0.5386 - auc: 0.5889 - val_loss: 0.2421 - val_accuracy: 0.5355 - val_auc: 0.6533\n",
      "Epoch 2/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.2384 - accuracy: 0.5646 - auc: 0.6624\n",
      "Epoch 2: val_accuracy improved from 0.53555 to 0.59649, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.5656 - auc: 0.6639 - val_loss: 0.2324 - val_accuracy: 0.5965 - val_auc: 0.7152\n",
      "Epoch 3/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.2262 - accuracy: 0.6389 - auc: 0.7215\n",
      "Epoch 3: val_accuracy improved from 0.59649 to 0.68144, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2260 - accuracy: 0.6404 - auc: 0.7229 - val_loss: 0.2167 - val_accuracy: 0.6814 - val_auc: 0.7656\n",
      "Epoch 4/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.2096 - accuracy: 0.7040 - auc: 0.7728\n",
      "Epoch 4: val_accuracy improved from 0.68144 to 0.73084, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2090 - accuracy: 0.7058 - auc: 0.7741 - val_loss: 0.1976 - val_accuracy: 0.7308 - val_auc: 0.8106\n",
      "Epoch 5/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1892 - accuracy: 0.7444 - auc: 0.8213\n",
      "Epoch 5: val_accuracy improved from 0.73084 to 0.75946, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1890 - accuracy: 0.7451 - auc: 0.8221 - val_loss: 0.1778 - val_accuracy: 0.7595 - val_auc: 0.8463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.7775 - auc: 0.8561\n",
      "Epoch 6: val_accuracy improved from 0.75946 to 0.79086, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.7776 - auc: 0.8559 - val_loss: 0.1611 - val_accuracy: 0.7909 - val_auc: 0.8688\n",
      "Epoch 7/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1557 - accuracy: 0.7956 - auc: 0.8757\n",
      "Epoch 7: val_accuracy improved from 0.79086 to 0.80286, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1556 - accuracy: 0.7957 - auc: 0.8756 - val_loss: 0.1485 - val_accuracy: 0.8029 - val_auc: 0.8866\n",
      "Epoch 8/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.8079 - auc: 0.8893\n",
      "Epoch 8: val_accuracy improved from 0.80286 to 0.81533, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.8077 - auc: 0.8891 - val_loss: 0.1387 - val_accuracy: 0.8153 - val_auc: 0.8970\n",
      "Epoch 9/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.8183 - auc: 0.8985\n",
      "Epoch 9: val_accuracy improved from 0.81533 to 0.82318, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1367 - accuracy: 0.8183 - auc: 0.8985 - val_loss: 0.1316 - val_accuracy: 0.8232 - val_auc: 0.9074\n",
      "Epoch 10/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1307 - accuracy: 0.8249 - auc: 0.9049\n",
      "Epoch 10: val_accuracy improved from 0.82318 to 0.82364, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.8257 - auc: 0.9056 - val_loss: 0.1255 - val_accuracy: 0.8236 - val_auc: 0.9148\n",
      "Epoch 11/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1255 - accuracy: 0.8314 - auc: 0.9115\n",
      "Epoch 11: val_accuracy improved from 0.82364 to 0.83241, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1253 - accuracy: 0.8319 - auc: 0.9115 - val_loss: 0.1212 - val_accuracy: 0.8324 - val_auc: 0.9211\n",
      "Epoch 12/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.8370 - auc: 0.9162\n",
      "Epoch 12: val_accuracy improved from 0.83241 to 0.83564, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1212 - accuracy: 0.8369 - auc: 0.9160 - val_loss: 0.1166 - val_accuracy: 0.8356 - val_auc: 0.9253\n",
      "Epoch 13/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.8400 - auc: 0.9206\n",
      "Epoch 13: val_accuracy improved from 0.83564 to 0.84026, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1178 - accuracy: 0.8400 - auc: 0.9205 - val_loss: 0.1136 - val_accuracy: 0.8403 - val_auc: 0.9273\n",
      "Epoch 14/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.8430 - auc: 0.9237\n",
      "Epoch 14: val_accuracy improved from 0.84026 to 0.84811, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1148 - accuracy: 0.8435 - auc: 0.9241 - val_loss: 0.1106 - val_accuracy: 0.8481 - val_auc: 0.9307\n",
      "Epoch 15/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1121 - accuracy: 0.8473 - auc: 0.9269\n",
      "Epoch 15: val_accuracy improved from 0.84811 to 0.84903, saving model to \\saved_models2_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1121 - accuracy: 0.8472 - auc: 0.9269 - val_loss: 0.1082 - val_accuracy: 0.8490 - val_auc: 0.9341\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8490 - auc: 0.9341\n",
      "Epoch 1/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.2506 - accuracy: 0.5023 - auc: 0.4989\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54319, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2505 - accuracy: 0.5030 - auc: 0.4996 - val_loss: 0.2482 - val_accuracy: 0.5432 - val_auc: 0.5353\n",
      "Epoch 2/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2473 - accuracy: 0.5496 - auc: 0.5816\n",
      "Epoch 2: val_accuracy improved from 0.54319 to 0.56951, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.5495 - auc: 0.5815 - val_loss: 0.2453 - val_accuracy: 0.5695 - val_auc: 0.6154\n",
      "Epoch 3/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.2442 - accuracy: 0.5821 - auc: 0.6451\n",
      "Epoch 3: val_accuracy improved from 0.56951 to 0.60924, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.5857 - auc: 0.6476 - val_loss: 0.2410 - val_accuracy: 0.6092 - val_auc: 0.6694\n",
      "Epoch 4/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.2368 - accuracy: 0.6401 - auc: 0.6912\n",
      "Epoch 4: val_accuracy improved from 0.60924 to 0.66189, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.6415 - auc: 0.6927 - val_loss: 0.2296 - val_accuracy: 0.6619 - val_auc: 0.7196\n",
      "Epoch 5/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.6825 - auc: 0.7446\n",
      "Epoch 5: val_accuracy improved from 0.66189 to 0.70162, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2199 - accuracy: 0.6822 - auc: 0.7444 - val_loss: 0.2088 - val_accuracy: 0.7016 - val_auc: 0.7752\n",
      "Epoch 6/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1976 - accuracy: 0.7242 - auc: 0.7935\n",
      "Epoch 6: val_accuracy improved from 0.70162 to 0.74134, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1970 - accuracy: 0.7249 - auc: 0.7946 - val_loss: 0.1846 - val_accuracy: 0.7413 - val_auc: 0.8262\n",
      "Epoch 7/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.7617 - auc: 0.8366\n",
      "Epoch 7: val_accuracy improved from 0.74134 to 0.77598, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7618 - auc: 0.8368 - val_loss: 0.1628 - val_accuracy: 0.7760 - val_auc: 0.8586\n",
      "Epoch 8/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1563 - accuracy: 0.7862 - auc: 0.8643\n",
      "Epoch 8: val_accuracy improved from 0.77598 to 0.79954, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1562 - accuracy: 0.7865 - auc: 0.8644 - val_loss: 0.1472 - val_accuracy: 0.7995 - val_auc: 0.8817\n",
      "Epoch 9/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1424 - accuracy: 0.8059 - auc: 0.8847\n",
      "Epoch 9: val_accuracy improved from 0.79954 to 0.81016, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1425 - accuracy: 0.8045 - auc: 0.8845 - val_loss: 0.1354 - val_accuracy: 0.8102 - val_auc: 0.8964\n",
      "Epoch 10/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1322 - accuracy: 0.8180 - auc: 0.8994\n",
      "Epoch 10: val_accuracy improved from 0.81016 to 0.82309, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1317 - accuracy: 0.8188 - auc: 0.9001 - val_loss: 0.1266 - val_accuracy: 0.8231 - val_auc: 0.9080\n",
      "Epoch 11/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1226 - accuracy: 0.8280 - auc: 0.9128\n",
      "Epoch 11: val_accuracy improved from 0.82309 to 0.83372, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.8278 - auc: 0.9122 - val_loss: 0.1193 - val_accuracy: 0.8337 - val_auc: 0.9175\n",
      "Epoch 12/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.8396 - auc: 0.9223\n",
      "Epoch 12: val_accuracy improved from 0.83372 to 0.84434, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.8395 - auc: 0.9223 - val_loss: 0.1123 - val_accuracy: 0.8443 - val_auc: 0.9252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1083 - accuracy: 0.8488 - auc: 0.9307\n",
      "Epoch 13: val_accuracy improved from 0.84434 to 0.85127, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1088 - accuracy: 0.8482 - auc: 0.9298 - val_loss: 0.1066 - val_accuracy: 0.8513 - val_auc: 0.9311\n",
      "Epoch 14/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1030 - accuracy: 0.8560 - auc: 0.9360\n",
      "Epoch 14: val_accuracy improved from 0.85127 to 0.86328, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1030 - accuracy: 0.8554 - auc: 0.9360 - val_loss: 0.1022 - val_accuracy: 0.8633 - val_auc: 0.9368\n",
      "Epoch 15/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.8634 - auc: 0.9419\n",
      "Epoch 15: val_accuracy improved from 0.86328 to 0.87159, saving model to \\saved_models2_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.8637 - auc: 0.9420 - val_loss: 0.0970 - val_accuracy: 0.8716 - val_auc: 0.9422\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.8716 - auc: 0.9422\n",
      "Epoch 1/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.2510 - accuracy: 0.5232 - auc: 0.5337\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58383, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2507 - accuracy: 0.5274 - auc: 0.5377 - val_loss: 0.2460 - val_accuracy: 0.5838 - val_auc: 0.5902\n",
      "Epoch 2/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.6075 - auc: 0.6427\n",
      "Epoch 2: val_accuracy improved from 0.58383 to 0.65312, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.6076 - auc: 0.6430 - val_loss: 0.2376 - val_accuracy: 0.6531 - val_auc: 0.6875\n",
      "Epoch 3/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.6681 - auc: 0.7219\n",
      "Epoch 3: val_accuracy improved from 0.65312 to 0.70254, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2308 - accuracy: 0.6688 - auc: 0.7223 - val_loss: 0.2211 - val_accuracy: 0.7025 - val_auc: 0.7602\n",
      "Epoch 4/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.7179 - auc: 0.7843\n",
      "Epoch 4: val_accuracy improved from 0.70254 to 0.73811, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2094 - accuracy: 0.7178 - auc: 0.7842 - val_loss: 0.1963 - val_accuracy: 0.7381 - val_auc: 0.8141\n",
      "Epoch 5/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1851 - accuracy: 0.7518 - auc: 0.8268\n",
      "Epoch 5: val_accuracy improved from 0.73811 to 0.76905, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1846 - accuracy: 0.7527 - auc: 0.8276 - val_loss: 0.1728 - val_accuracy: 0.7691 - val_auc: 0.8507\n",
      "Epoch 6/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.7809 - auc: 0.8580\n",
      "Epoch 6: val_accuracy improved from 0.76905 to 0.79169, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1642 - accuracy: 0.7810 - auc: 0.8577 - val_loss: 0.1551 - val_accuracy: 0.7917 - val_auc: 0.8737\n",
      "Epoch 7/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.7999 - auc: 0.8795\n",
      "Epoch 7: val_accuracy improved from 0.79169 to 0.81016, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1492 - accuracy: 0.7999 - auc: 0.8795 - val_loss: 0.1413 - val_accuracy: 0.8102 - val_auc: 0.8939\n",
      "Epoch 8/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1377 - accuracy: 0.8136 - auc: 0.8952\n",
      "Epoch 8: val_accuracy improved from 0.81016 to 0.81986, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1375 - accuracy: 0.8140 - auc: 0.8950 - val_loss: 0.1324 - val_accuracy: 0.8199 - val_auc: 0.9050\n",
      "Epoch 9/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1294 - accuracy: 0.8240 - auc: 0.9048\n",
      "Epoch 9: val_accuracy improved from 0.81986 to 0.83002, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1287 - accuracy: 0.8252 - auc: 0.9058 - val_loss: 0.1237 - val_accuracy: 0.8300 - val_auc: 0.9145\n",
      "Epoch 10/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1218 - accuracy: 0.8335 - auc: 0.9134\n",
      "Epoch 10: val_accuracy improved from 0.83002 to 0.83603, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1217 - accuracy: 0.8329 - auc: 0.9135 - val_loss: 0.1182 - val_accuracy: 0.8360 - val_auc: 0.9194\n",
      "Epoch 11/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1164 - accuracy: 0.8391 - auc: 0.9193\n",
      "Epoch 11: val_accuracy improved from 0.83603 to 0.84711, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.8392 - auc: 0.9197 - val_loss: 0.1133 - val_accuracy: 0.8471 - val_auc: 0.9265\n",
      "Epoch 12/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1118 - accuracy: 0.8458 - auc: 0.9250\n",
      "Epoch 12: val_accuracy improved from 0.84711 to 0.84988, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8460 - auc: 0.9251 - val_loss: 0.1086 - val_accuracy: 0.8499 - val_auc: 0.9306\n",
      "Epoch 13/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1079 - accuracy: 0.8497 - auc: 0.9294\n",
      "Epoch 13: val_accuracy improved from 0.84988 to 0.85127, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.8500 - auc: 0.9298 - val_loss: 0.1052 - val_accuracy: 0.8513 - val_auc: 0.9341\n",
      "Epoch 14/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 0.8546 - auc: 0.9339\n",
      "Epoch 14: val_accuracy improved from 0.85127 to 0.85589, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1041 - accuracy: 0.8546 - auc: 0.9339 - val_loss: 0.1024 - val_accuracy: 0.8559 - val_auc: 0.9365\n",
      "Epoch 15/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.8589 - auc: 0.9376\n",
      "Epoch 15: val_accuracy improved from 0.85589 to 0.85681, saving model to \\saved_models2_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1009 - accuracy: 0.8589 - auc: 0.9374 - val_loss: 0.1000 - val_accuracy: 0.8568 - val_auc: 0.9397\n",
      "68/68 [==============================] - 0s 966us/step - loss: 0.1000 - accuracy: 0.8568 - auc: 0.9397\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY21 = []\n",
    "VALIDATION_AUC21 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names2].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names2].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names2):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep4')(deep_branch) # added this! \n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model21 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model21.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models2_1/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history21 = model21.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model21.load_weights(\"\\saved_models2_1/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model21.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model21.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY21.append(results['accuracy'])\n",
    "    VALIDATION_AUC21.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAEWCAYAAAAjJDDoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABTyklEQVR4nO3dd3xX9fX48dfJ3jskkBCW7I2R5V6IVsGqVdzWbWu1rdra7dcuO37Vam3dilZFRW1RUcGtBZQAssKQTSALyCQ7Ob8/7g1+iIxA8lnJeT4en8fnc+/njhMIh3Pf933fb1FVjDHGGGNMYAjxdwDGGGOMMeZrVpwZY4wxxgQQK86MMcYYYwKIFWfGGGOMMQHEijNjjDHGmABixZkxxhhjTACx4swEFRF5W0Su7uxtjTGmI0REReQY9/MjIvKr9mx7FOe5XETmHW2cJjiIjXNmvE1Eqj0WY4B6oNldvklVn/d9VMYYsz8ReQf4QlV/3Wb9dOBRIFtVmw6yrwIDVXVDO87Trm1FpC+wGQg/2HlN12QtZ8brVDWu9QVsA87zWLevMBORMP9FaYwxzASuEBFps/5K4HkrkIyvWHFm/EZEThGRAhH5qYgUAU+LSLKIvCkipSJS5n7O9tjnIxG53v18jYh8JiJ/dbfdLCJnH+W2/UTkExGpEpH3RORhEfm3D/84jDH+9x8gFTixdYWIJAPnAnNEZKGIlItIoYj8Q0QiDnQQEXlGRH7nsXyXu89OEbm2zbbfEpFlIlIpIttF5B6Prz9x38tFpFpEJrXmMo/9J4vIYhGpcN8ne3z3kYj8VkT+5+a2eSKSdvR/PMZXrDgz/pYJpAB9gBtxfiefdpdzgFrgH4fYfwKwDkgD/gw8eYCr3vZs+wLwBU5ivgfnStkY042oai3wMnCVx+qLgbVANfAjnPwxCTgd+N7hjikiU4E7gTOBgcAZbTbZ654vCfgWcIuInO9+d5L7nuTeaVjY5tgpwFvAgzi562/AWyKS6rHZZcB3gR5AhBuLCXBWnBl/awF+o6r1qlqrqrtV9VVVrVHVKuD3wMmH2H+rqj6uqs04tyR6AhlHsq2I5ADHAb9W1QZV/QyY01k/oDEmqMwELhKRKHf5KmCmqi5R1UWq2qSqW3D6oB0qN7W6GHhaVVep6l6ci799VPUjVV2pqi2qugJ4sZ3HBaeY+0pVn3PjehGnkDzPY5unVXW9R+E5pp3HNn5kxZnxt1JVrWtdEJEYEXlURLaKSCVOs36SiIQeZP+i1g+qWuN+jDvCbXsBezzWAWw/wp/DGNMFuBdnu4DzRWQAMB54QUQGud0sitzc9AecVrTD6cX++WSr55ciMkFEPnS7clQAN7fzuK3H3tpm3VYgy2O5yONzDQfPjyaAWHFm/K3t48J3AIOBCaqawNfN+ge7VdkZCoEUEYnxWNfbi+czxgS2Z3FazK4A3lXVYuBfOK1SA93c9HPal5cK2T+f5LT5/gWclvreqpoIPOJx3MMNp7ATpwuIpxxgRzviMgHMijMTaOJx+pmVu/0pfuPtE6rqViAPuEdEIkRkEvvfFjDGdC/P4vQNuwHnNic4uakSqBaRIcAt7TzWy8A1IjLMvQBsm9PicVru60RkPE4fsValOF0/+h/k2HOBQSJymYiEicglwDDgzXbGZgKUFWcm0DwAROPcVlgEvOOj816O08l3N/A74CWc8diMMd2M26dsARDL1/1P78QpnKqAx3FyRHuO9TZOXvsA2OC+e/oecK+IVAG/xinmWvetwel3+z/3KdGJbY69G+dJ0jtwctdPgHNVdVc7f1QToGwQWmMOQEReAtaqqtdb7owxxhhP1nJmDCAix4nIABEJcR99n44z5pExxhjjUzYiuzGOTOA1nLGCCoBbVHWZf0MyxhjTHdltTWOMMcaYAGK3NY0xxhhjAkiXua2Zlpamffv29XcYxhgfWrJkyS5VTfd3HJ3Bcpgx3cuh8leXKc769u1LXl6ev8MwxviQiLQdHT1oWQ4zpns5VP6y25rGGGOMMQHEijNjjDHGmADSZW5rGmMCi6pS09BMeW0j5TUNVNQ0Ul7bSFlNA+U1jVS468trGp1XrfP5r98ZzUmDukQ3MmNMgFFV9jY0s6uqntLqekqr6tnlvu/e20BjUwtNLeq8mltobFaaW5x1jc0tNDW737V4fN63nXLqkHT+eMGoDsdpxZkx5rAam1vcIqqBshqnwCrb63x21jWwZ28jFW6BVV7bSEVNIw3NLQc9ZlR4CEnRESTFhJMYHU7/tDiSYsJJiY3w4U9mjAlmLS1KQ3ML9U0tVNY2Ulpdf8DCy/ncQGlVPbWNzd84TohAckwEEWEhhIUKYSEhhIUIYaGt70J4SAgRYSFEhwjhHuvDQkL2fT+8V2Kn/FxWnBnTjdQ1NlNZ67RaVda577VNVLjrWlu1PIuvspoGquqaDnrMiLAQUmKcIispJpxjesS5BVcEye66xOivv0+OiSAxOpyo8FAf/uTGGF9ram5hb30zVfWNVNc3UV3XRFVdE1Xu5+r6Rqrrmqisa2JvfRP1TS00NLXQ0Oy+N7VQ736ub2ret87z+6aWQ4/VmhIbQVpcBOnxkYzLSSItLpL0+Mh9762fU2IjCA0RH/3JHJ4VZ8YEqYamFoor69hZXkthRR2lVfX7Ci6n6PL4XOcUYA1NB2/JAoiLDNvXepUUE0HftFiSYyKcV2w4STFOweUsO5+jw0MRCZykZozxvpYWZWNpNUu3lbFsWznby2qc4sujCDtQC1VbIk7eiYsMIzLMaZmKCAshItR5T4wIJyI0hMjwECJDv/m953JCVPh+BVdqXAThocHZtd6KM2MCUFNzCyVV9RRW1LKzvG6/96KKOnZW1LGrup62E3yECCREO7cJE6Kc98zEKGfZY13rNs52YSRGhxMfFU5EWHAmMmOMd1XUNvLl9nKWbi1j6bYyvtxevq9FPTE6nAHpsSTHRtA7JYb4qDC34AonLiqM+MgwZ5273vne+S4mPJSQAGqxChRWnBnjY3WNzRRX1lFcWe++O6+dFXUUuq1gJVX1NLdpro+NCKVnUjQ9E6MYkplAz6QoeiVG0zMpip6J0fRIiCQ+MsxasYwxHdLSonxVUs2ybU4htnRbORtKqgHnAnBQRjznjurFuJwkxvVJpn9arOWdTmbFmTGdpKm5hV3VDfsVXMWV9RS5n0vczxW1jd/YNzIshF5u4TV5QBq93IKrZ2LUvuIrIcoKL2NM5yuvaWDZ9nKWbStn2bYyvtxWTlW90yqWFBPOuJxkpo/uxbg+yYzunURcpJUO3mZ/wsa0U0NTCzvKaykoq2H7Hve9rJbte2rYWV7Lrup62vZNDQ0R0uMiyUiMok9qDOP7pZCZGEWP+EgyE6PISIgiIz6KhGgrvIwxna+lRdlVXc+O8lrnVea87yyvpcD93Hp7MkRgcGYC08b0YlxOMmNzkuhnrWJ+YcWZMa6m5hYKK+ooKKtle1kNBXtqvv5cVktRZd1+fbzCQoSs5Giyk6M5ZXA6mQlRZCQ6xVZGQhQZiZGkxkYG1BNAxpiupam5Zb+iq20BtrO87htD2sRHhZGV5OSu8f1SyE6OZkRWIqOyrVUsUNjfgul2Gppa2FBSzZrCStYUVrK2qIotu/dSWFG3Xz8vEeiZEEV2SgyTB6SRnRxN75QYeidHk50SQ2ZClBVexhifaW5RNpVWs6KggpU7KlhRUE5+YSV1jV8XXyLQIz6SXklOwXXWiEyykqKdV3I0vZKiSYgK9+NPYdrDijPTpe3Z27CvCMvfWUl+YSUbS6tpbHaKsIiwEAZnxDMuJ5neKdH0To4hOzmG3inR9EyMtqcXjTF+0dKibN1Tw4qCcqcYK6hg1c4Kahqc4SliIkIZ0SuRyyf0YXBmPNlu8ZWZGEVkmI0hGOysODNdQnOLsnnXXqcIc4uxNYWVFFfW79umR3wkQ3smcMrgHgztGc+wngn0S4slLEjHwTHGdA2qSkFZLSsKKlixo5yVbstYa1+wyLAQhvdK4OLc3ozMSmRUdiL90+Os5b4Ls+LMBKXCiloWbyljyZY9fLm9nHXFVfua9sNChGN6xHH8gDSG9kxwX/GkxkX6OWpjTHfX2iK2emcFq3ZUsnqnU4iV1zhPcUeEhjC0ZzzTx/RiVFYSI7MTGdgjzi4iuxkrzkzAa25R1hVVsWTrHqcg21rGjvJawGnaH5XtNO23FmHH9IizZn1jjN81NbewobSa1TsqWbWzgtU7nJb9aneYivBQYVBGPGePyGRkVhKjshMZlBFv3SmMf4ozEZkK/B0IBZ5Q1fvafJ8DzASS3G3uVtW5vo7T+EdNQxNfbi8nb0sZeVvLWLa1bN+YOxkJkeT2SeH6E/uR2yeFoT3j7YrSGON3dY3NrC+uYlVrIbazkrWFldS7U6ZFh4cytGc8F4zLYkSvRIb1SrBCzByUz4szEQkFHgbOBAqAxSIyR1XzPTb7JfCyqv5LRIYBc4G+vo7V+EZJZR15W8vI21LGkq17WLWzkuYWRQQG9Yhn2phe5PZNJreP88i3jbljjPG32oZm5uUX8cn6XazeWcGGkup9k3DHR4UxolciV03qw/BeiYzISqBfmvURM+3nj5az8cAGVd0EICKzgOmAZ3GmQIL7ORHY6dMIjVc1tyhLt5UxP7+Y9/KL2bRrL+B0eh3TO4mbT+5Pbp8UxuUkkxhjj3ybwGOt/91TS4uyeMseXl1awNyVRVTXN5EaG8HI7EROH9qDEb0SGZGVaBeRpsP8UZxlAds9lguACW22uQeYJyI/AGKBMw50IBG5EbgRICcnp9MDNZ2nrrGZz77axbz8It5fU8LuvQ2EhwoT+6dy6fgccvsmM7xXojXxm4Bnrf/dz5Zde3lt2Q5eW1pAQVktsRGhnD2yJxeOy2ZCvxSbuNt0ukB9IOBS4BlV/X8iMgl4TkRGqOp+wxyr6mPAYwC5ubl6gOMYPyrb28D7a0uY7zb91zY2Ex8ZxilDejBlWAYnD063wRBNMLLW/26goraRt1YU8trSAvK2liECJxyTxh1TBnHW8ExiIgL1v0/TFXTKb5eIHIPT2hUN/FVVFx5i8x1Ab4/lbHedp+uAqQCqulBEooA0oKQz4jXes31PDfPyi5mfX8TiLWU0tyiZCVFcdGw2Zw7LYGL/VGsdM8Gu01r/TWBpam7h0692MXtpAfPzi2loauGYHnH8dOoQzh/bi56J0f4O0XQTR1WciUiUqtZ5rPot8BP38xvAmEPsvhgYKCL9cIqyGcBlbbbZBpwOPCMiQ4EooPRoYjXepaqs3lnJvPxi5q0uYm1RFQCDM+K55eQBTBmewcisROt/YbqbdrX+W9eMwJC/s5LXlhbwny93squ6nuSYcC49rjcXHptt+cv4xdG2nL0hIs+p6rPuciNOfwoFmg+1o6o2icitwLs4HWWfUtXVInIvkKeqc4A7gMdF5EfuMa9RVbttGUAqahp5duEWZi3ezo7yWkIEcvuk8MtvDeXMYRn0SY31d4jGeEuntf5b1wz/qaxr5JW8AmYvKWBNYSXhocKpg3tw4bHZnDq4h7XwG7862uJsKnCLiLwD/AG4E7gN57bm5Yfb2X1qaW6bdb/2+JwPHH+UsRkvKqyo5clPN/PCF9uoaWjmpEHp3H7GQE4f0sNG4DfdhbX+B7Gd5bU8/b/NvPjFdqrrmxidncj/TRvOeaN7kRIb4e/wjAGOsjhT1WbgHyLyHPAr4Bbgl6q6sTODM4FjQ0kVj3y8if9+uYMWhWmje3HTyf0Zkplw+J2N6UKs9T84rdpRwROfbuLNFYUocM7IntxwYj9GZSf5OzRjvuFo+5xNAO4CGnBazmqB34vIDuC3qlreaREav1qytYxHPt7I/PxiosJDuHxCH647oR+9U2L8HZoxfmOt/8FBVflofSmPf7KJBRt3ExsRytWT+/Ld4/uSnWw5zASuo72t+ShwDhAHPK2qxwMzRORk4CXgrE6Kz/iBqvLRulL+9dFGvtiyh6SYcG4/fSBXT+5rzf7GmIBX39TMf7/cyROfbmJ9cTWZCVHcffYQLh2fQ2K0Dd9jAt/RFmdNOA8AxOK0ngGgqh8DH3c8LOMPjc0tvLliJ49+vIm1RVX0Sozi1+cOY8b43jamjzEm4JXXNPD859t4ZsEWSqvqGZIZz98uHs25o3pZB38TVI72f9zLgJtwCrOrOi8c4w81DU28vHg7j3+6mR3ltQzKiONvF4/mvNG9CLdJxY0xAW7b7hqe+t9mXlq8ndpG50Gl+y/uz/HHpNowGCYoHe0DAetxOryaIFa2t4GZC7cwc8EWymoaOa5vMvdOH86pg3vYdCTGmIC3bFsZj3+6iXdWFREaIkwbncX1J/ZjaE97UMkEN7tX1Q01NLXwzILNPPT+BqrqmzhjaA9uPnkAuX1T/B2aMcYcVkFZDffMWc17a0qIjwrjppMHcM3kvmQkRPk7NGM6hRVn3Yiq8t6aEn7/Vj5bdtdw2pAe/HTqEAZnxvs7NGOMOazG5hae/Gwzf3/vK0Tgp1OHcOWkPsRF2n9lpmvp0G+0iJwHvNV2ShITeNYVVfHbN/P5bMMujukRx8xrx3PyoHR/h2WMMe2St2UPv3h9FeuKq5gyLIN7pg2nV5LNdWm6po5eblwCPCAir+IMxLi2E2IynWjP3gb+Nn8dL3y+jfiocO45bxiXT+xjHf2NMUGhbG8Df3pnLbMWbycrKZrHr8rlzGEZ/g7LGK/qUHGmqleISALuJL8iosDTwIuqWtUZAZqj09jcwnMLt/LAe+vZ29DMlRP78MMzBpFs45QZY4KAqvLq0h38Ye4aKmobuemk/tx+xkAb1sd0Cx3+LVfVShGZjTOv5g+BbwN3iciDqvpQR49vjtyH60r43Zv5bCzdy4kD0/jVucMYlGH9yowxwWFDSRW/eH0Vn2/ew7icJH7/7ZH2BKbpVjra52wa8F3gGOBZYLyqlohIDJAPWHHmQxtKqvndW/l8tK6UfmmxPHl1LqcN6WHj/BhjgkJdYzP/+GADj36ykZiIMP54wUguye1tQ/uYbqejLWcXAver6ieeK1W1RkSu6+CxTTtV1DTywPvreW7hVqIjQvnlt4Zy1aS+NiK2MSZofLy+lF/9ZxXb9tRwwdgsfv6toaTFRfo7LGP8oqPF2T1AYeuCiEQDGaq6RVXf7+CxzWE0Nbfwwhfb+Nv89VTWNjJjfA53nDmIVEtoxpggUVxZx71v5vPWikL6p8fywg0TmDwgzd9hGeNXHS3OXgEmeyw3u+uO6+BxzWGs2lHBHS8vZ11xFZP6p/Lr84ZZnwxjTNBoblH+vWgrf313HfXNLfz4zEHcdHJ/IsNC/R2aMX7X0eIsTFU9Jz5vEBF7HNDL/rNsBz99dQUpsRE8csWxnDU8w/qVGWOCxsbSan780pcsL6jgxIFp/Hb6CPqmxfo7LGMCRkeLs1IRmaaqcwBEZDqwq+NhmQNpam7hT++s5fFPNzO+Xwr/vHyc9ckwxgQNVeXFL7bz2zfziQwP4e8zxjBtdC+7uDSmjY4WZzcDz4vIPwABtgNXHW4nEZkK/B0IBZ5Q1fvafH8/cKq7GAP0UNWkDsYa1MprGvjBi8v49KtdXDWpD786d5gNJGuMCRp79jbw01dXMD+/mBOOSeP/XTza5sI05iA6OgjtRmCiiMS5y9WH20dEQoGHgTOBAmCxiMxR1XyP4/7IY/sfAGM7EmewW1dUxQ3P5lFUUcefLhzJJcfl+DskY4xpt0/Wl3LHK8upqGnkl98ayrXH97PhMYw5hA4PQisi3wKGA1GtTdOqeu8hdhkPbFDVTe7+s4DpOOOiHcilwG86GmewemdVIT9+eTlxkWHMumki43KS/R2SMca0S11jM395dx1PfraZgT3imPnd8QzrZQ8uGXM4HR2E9hGc246nAk8AFwFfHGa3LJzbn60KgAkHOX4foB/wwUG+vxG4ESAnp2u1JrW0KA+8t54HP9jA2JwkHrniWLsFYIwJGuuLq7jtxWWsLari6kl9+Nk5Q4kKtycxjWmPjracTVbVUSKyQlX/T0T+H/B2ZwTmmgHMVtXmA32pqo8BjwHk5uZqJ57Xr6rqGvnRS1/y3poSLs7N5rfnj7DHy40xQUFVmblgC398ey3xUWE8dU0upw2xicqNORIdLc7q3PcaEekF7AZ6HmafHUBvj+Vsd92BzAC+36EIg8zG0mpufDaPrbtruHf6cK6c2MeeZDLGBIXSqnrumr2cj9aVcurgdP580WjS4+2JcmOOVEeLszdEJAn4C7AUUODxw+yzGBgoIv1wirIZwGVtNxKRIUAysLCDMQaND9eWcNuLywgPC+Hf109gYv9Uf4dkjDHt8sHaYu56ZQXV9U12YWlMBx11cSYiIcD7qloOvCoibwJRqlpxqP1UtUlEbgXexRlK4ylVXS0i9wJ5rWOm4RRts1S1y9yuPBhV5Z8fbeSv89YxrGcCj155LNnJMf4OyxhjDquusZk/zF3Dswu3MiQznhdvnMigjHh/h2VMUDvq4kxVW0TkYdxhLlS1Hqhv575zgblt1v26zfI9RxtbMKlpaOKuV1bw1spCpo3uxZ8uHEV0hPUvMyaQ2ViNjtU7K7h91pdsKKnm+hP6cdfUwdY/1phO0NHbmu+LyIXAa92hhauzbd9Tww3P5rG+uIqfnzOEG07sb7cBjAlwNlaj8zT5U//bzJ/fWUdSTDjPXTeeEwem+zssY7qMjhZnNwE/BppEpA5nlgBVVRvI5jAWbNjF915YSkuL8vR3x3PyIEtsxgSJbj1WY1NzC3e8spz/frmTKcMyuO/CUaTE2pTKxnSmjs4QYB0LjsKH60q46dkl9EmN4fGrcm3CX2OCS7cdq7GpuYUfvbycN5bv5K6zBvO9UwZYa78xXtDRQWhPOtB6Vf2kI8ftyj5aV8JNzy1hUGYcz183kcSYcH+HZIzxni4zVmNjcws/nPUlb60s5GdnD+Gmkwf4OyRjuqyO3ta8y+NzFE5z/xLgtA4et0v6eH0pNz63hIE94vj3dROsMDMmOHW7sRobmlq47cVlvLO6iF9+ayjXn9jf3yEZ06V19LbmeZ7LItIbeKAjx+yqPllfyg3P5nFMehzPXz+BpBjro2FMkOpWYzU2NLXw/ReWMj+/mF+fO4xrT+jn75CM6fJCOvl4BcDQTj5m0Pvsq13c8GweA6wwMyboqWoT0DpW4xrg5daxGkVkmsemQT9WY31TM997fgnz84v5v2nDrTAzxkc62ufsIZxZAcAp9MbgzBRgXP/bsIvrZi6mX1osz18/gWR7qsmYoNcdxmqsa2zme88v5YO1Jfz2/BFcObGPv0MyptvoaJ+zPI/PTcCLqvq/Dh6zy1jgFmZ9U53CzB43N8YEg7rGZm56bgkfry/lD98eyWUTAv9JUmO6ko4WZ7OButYnkUQkVERiVLWm46EFt4Ubd3PtzMXkpMTw/A0TSI2zyX+NMYGvrrGZG57N47MNu/jThSO55DgrzIzxtY72OXsfiPZYjgbe6+Axg96iTbu59pnF9E6O4YUbJpJmhZkxJgjUNjRz/UynMPvzhaOsMDPGTzrachalqtWtC6paLSLdesbuzzft5rtPLyYrOdoKM2NM0KhpaOK6Z/JYtHk3f71oNBcem+3vkIzptjracrZXRMa1LojIsUBtB48ZtBZv2cN3n1lMr6QoXrhhAunxVpgZYwLf3vomvvv0Yj7fvJv7Lx5jhZkxftbRlrMfAq+IyE6ceTUzgUs6GlQwytuyh2ue+oLMxChevGEiPeKj/B2SMcYcVnV9E9c+vZi8rXu4/5IxTB+T5e+QjOn2OjoI7WJ3oMXB7qp1qtrY8bCCy5Kte7j6qS/ISIhi1g0T6ZFghZkxJvBV1TXy3acXs2x7OQ9eOpZzR/Xyd0jGGDp4W1NEvg/EquoqVV0FxInI9zontOCwZGsZVz+1mB4JUbx4oxVmxpjgUFnXyNVPfcGX28v5hxVmxgSUjvY5u0FVy1sXVLUMuKGDxwwaS7eVcfVTX5AWF8GLN0wkwwozY0wQqKxr5Konv2BFQQX/uGwcZ4/s6e+QjDEeOtrnLFREpHV6EhEJBbrFSKtfbi/n6ie/IDUughdvnEhmohVmxpjAV9/UzNVPfcHqnRX864pjOXNYhr9DMsa00dGWs3eAl0TkdBE5HXjRXXdIIjJVRNaJyAYRufsg21wsIvkislpEXuhgnJ1qbVElVz75OcmxTotZz8Tow+9kjDEB4C/vrGPZtnIenDHWCjNjAlRHW85+CtwI3OIuzwceP9QObuvaw8CZOBOlLxaROaqa77HNQOBnwPGqWiYiPToYZ6eprm/ie/9eSlR4KC/eOJFeSVaYGWOCw0frSnjis81cNamP3co0JoB1qOVMVVtU9RFVvUhVLwLygYcOs9t4YIOqblLVBmAWML3NNjcAD7t92FDVko7E2VlUlZ+9tpItu/fy0KVjybLCzBgTJEqr6rnzleUMzojn5+cM9Xc4xphD6OhtTURkrIj8WUS2APcCaw+zSxaw3WO5wF3naRAwSET+JyKLRGTqQc59o4jkiUheaWnpUf4E7ffvz7fxxvKd3DFlMBP7p3r9fMYY0xlaWpQ7X1lOVV0TD146lqjwUH+HZIw5hKO6rSkig4BL3dcu4CVAVPXUToxrIHAKkA18IiIjPZ8MBVDVx4DHAHJzc7WTzn1AKwsq+O0b+ZwyOJ1bTh7gzVMZY0yneup/m/l4fSm/nT6cwZnx/g7HGHMYR9tythY4DThXVU9Q1YeA5nbuuwPo7bGc7a7zVADMUdVGVd0MrMcp1vyioraR772whLS4CO6/eAwhIeKvUIwx5ois2lHBn95Zy5nDMrhiYh9/h2OMaYejLc4uAAqBD0XkcfdJzfZWLIuBgSLST0QigBnAnDbb/Aen1QwRScO5zbnpKGPtEFXlrleWU1hex0OXjSM5tluMFGKM6QJqGpq4bdYyUmIj+NOFoxCxC0tjgsFRFWeq+h9VnQEMAT7EmWOzh4j8S0SmHGbfJuBW4F1gDfCyqq4WkXtFZJq72bvAbhHJd49/l6ruPppYO+rJzzYzL7+Yu88ewrF9kv0RgjHGHJV738hn86693H/JGFLswtKYoNHRuTX3Ai8AL4hIMvAdnOE15h1mv7nA3Dbrfu3xWYEfuy+/WbK1jPveXsuUYRlcd0I/f4ZijDFHZO7KQmYt3s73ThnA5AFp/g7HGHMEOvy0ZitVLVPVx1T19M46pj/t2dvArS8spWdSFH/5zmi7HWCMCRo7ymu5+9UVjOmdxI/OHOTvcIwxR6ijg9B2SS0tyo9f/pLd1Q28estkEqPD/R2SMca0S1NzCz+ctYwWhQdnjCU8tNOuwY0xPmL/ag/gXx9v5KN1pfzqvGGMzE70dzjGGNNu//hwA4u3lPG780eQkxrj73CMMUfBirM2Fm3azf+bt47zRvfiigk5/g7HGGPabfGWPTz4/ld8e2wW549tO7a3MSZYWHHmobSqnh+8uIy+qbH88YKR1s/MGBM0Kmob+eGsL8lOjuHe6cP9HY4xpgOsOHM1tyi3z1pGZW0j/7xiHHGR1h3PGHNgIjJVRNaJyAYRufsg21wsIvkislpEXvBmPKrKz19fSXFlHQ9eOpb4KOsna0wwswrE9ff3v2LBxt38+aJRDMlM8Hc4xpgAJSKhwMPAmTizmSwWkTmqmu+xzUDgZ8DxqlomIj28GdMreQW8taKQn0wdzJjeSd48lTHGB6zlDPhkfSkPffAVFx2bzcW5vQ+/gzGmOxsPbFDVTaraAMwCprfZ5gbgYVUtA1DVEm8Fs7G0mt/MWc3kAancfJLN+2tMV9Dti7Oiijp++NKXDOoRz2+nj/B3OMaYwJcFbPdYLnDXeRoEDBKR/4nIIhGZeqADiciNIpInInmlpaVHHEh9UzO3vbiMqPAQ7r/E5v01pqvo1sVZY3MLP3hxKXWNzTx8+TiiI0L9HZIxpmsIAwbizBF8KfC4iCS13cgduDtXVXPT09OP+CR/eWcdq3dW8ueLRpORENXBkI0xgaJbF2d/nbeOxVvK+OMFIzmmR5y/wzHGBIcdgGf/h2x3nacCYI6qNqrqZmA9TrHWaT5aV8ITn23myol9OHNYRmce2hjjZ922OHsvv5hHP97E5RNymD7GxgMyxrTbYmCgiPQTkQhgBjCnzTb/wWk1Q0TScG5zbuqsAEqr6rnzleUMzojnF98a2lmHNcYEiG5ZnG3fU8MdryxneK8EfnXuMH+HY4wJIqraBNwKvAusAV5W1dUicq+ITHM3exfYLSL5wIfAXaq6uzPO39Ki3PnKcqrqmnjw0rFEhVt3DGO6mm43lEZLi/KDF5fR0qL88/JxltiMMUdMVecCc9us+7XHZwV+7L461b8/38rH60v57fThDM6M7+zDG2MCQLcrzkJChNtPH0hTi9InNdbf4RhjzBE5a3gmZXsbuWJiH3+HYozxkm5XnAGcOsSr40EaY4zXZCREcfsZnfpsgTEmwHTLPmfGGGOMMYHKijNjjDHGmAAiTr/V4CcipcDWI9glDdjlpXAsBovBYvBNDH1U9chHbw1AR5jDgu3vyWKwGCyGbzpo/uoyxdmREpE8Vc21GCwGi8FiCDaB8GdkMVgMFoP3YrDbmsYYY4wxAcSKM2OMMcaYANKdi7PH/B0AFkMri8FhMTgCIYZAFwh/RhaDw2JwWAyOTomh2/Y5M8YYY4wJRN255cwYY4wxJuBYcWaMMcYYE0C6XXEmIlNFZJ2IbBCRu/1w/t4i8qGI5IvIahG53dcxeMQSKiLLRORNP50/SURmi8haEVkjIpP8EMOP3L+HVSLyoohE+eCcT4lIiYis8liXIiLzReQr9z3ZDzH8xf27WCEir4tIkq9j8PjuDhFREUnzZgzByHLYfrFYDrMc1iVzWLcqzkQkFHgYOBsYBlwqIsN8HEYTcIeqDgMmAt/3QwytbgfW+OncAH8H3lHVIcBoX8ciIlnAbUCuqo4AQoEZPjj1M8DUNuvuBt5X1YHA++6yr2OYD4xQ1VHAeuBnfogBEekNTAG2efn8Qcdy2DdYDrMc5qnL5LBuVZwB44ENqrpJVRuAWcB0XwagqoWqutT9XIXzjznLlzEAiEg28C3gCV+f2z1/InAS8CSAqjaoarkfQgkDokUkDIgBdnr7hKr6CbCnzerpwEz380zgfF/HoKrzVLXJXVwEZPs6Btf9wE8Ae1rpmyyHuSyH7WM57Ot1XSaHdbfiLAvY7rFcgB+SSisR6QuMBT73w+kfwPnlafHDuQH6AaXA0+5tiSdEJNaXAajqDuCvOFc3hUCFqs7zZQweMlS10P1cBGT4KY5W1wJv+/qkIjId2KGqy3197iBhOexrD2A5zHLYwQV1DutuxVnAEJE44FXgh6pa6eNznwuUqOoSX563jTBgHPAvVR0L7MX7zeD7cftETMdJsr2AWBG5wpcxHIg649v4rdVIRH6Bc+vqeR+fNwb4OfBrX57XHB3LYZbDDsZyWMdzWHcrznYAvT2Ws911PiUi4ThJ7XlVfc3X5weOB6aJyBac2yKnici/fRxDAVCgqq1X3LNxEp0vnQFsVtVSVW0EXgMm+ziGVsUi0hPAfS/xRxAicg1wLnC5+n4QxAE4/8ksd383s4GlIpLp4zgCmeUwh+Uwh+WwNrpKDutuxdliYKCI9BORCJyOk3N8GYCICE4fhTWq+jdfnruVqv5MVbNVtS/On8EHqurTqy1VLQK2i8hgd9XpQL4vY8C5FTBRRGLcv5fT8V/n4jnA1e7nq4H/+joAEZmKc5tomqrW+Pr8qrpSVXuoal/3d7MAGOf+rhiH5TAsh3mwHOahK+WwblWcuR0FbwXexfkFfllVV/s4jOOBK3Gu9L50X+f4OIZA8QPgeRFZAYwB/uDLk7tXvLOBpcBKnH8PXp/+Q0ReBBYCg0WkQESuA+4DzhSRr3Cuhu/zQwz/AOKB+e7v5SN+iMEcguWwgGM5zHKYV3KYTd9kjDHGGBNAulXLmTHGGGNMoLPizBhjjDEmgFhxZowxByCHmSZJRH4szhRGK0TkfRHp4/Fds0d/LJ922DfGBL8u0+csLS1N+/bt6+8wjDE+tGTJkl2qmt7Zx3WnSVoPnInzxNVi4FJVzffY5lTgc1WtEZFbgFNU9RL3u2pVjTuSc1oOM6Z7OVT+CvN1MN7St29f8vLy/B2GMcaHRGSrlw69b5ok9zyt0yTtK85U9UOP7RcBHRrKwXKYMd3LofKXV29r2m0BY0yQOtJpkq5j/6liokQkT0QWicj5B9tJRG50t8srLS3tUMDGmK7Da8WZe1vgYeBsYBhwqYgMa7PZMiDXnUF+NvBnj+9qVXWM+5rWmbEt2rSbdUVVdJVbusYY/3Gny8kF/uKxuo+q5gKXAQ+IyIAD7auqj6lqrqrmpqe37+5sYUUtH64rob6puaOhG2MClDdva/r8tkB73TNnNWuLqshKiua0IT04bWgPJvVPJSo81BenN8YEvnZNkyQiZwC/AE5W1frW9e6E1KjqJhH5CGdy8I2dEdgby3fyh7lriYsM45TB6UwZnskpg9NJiArvjMMbYwKAN4uzA90WmHCI7Q94WwBn8tL7VPU/bXcQkRuBGwFycnLaHdjMa8fz4doS3l9bwuwlBTy3aCvR4aEcf0wapw/twWlDepCRENXu4xljupx90yThFGUzcFrB9hGRscCjwFRVLfFYnwzUqGq9iKThjKjveVegQ66a1JdjesQxb3Ux760p5s0VhYSHCpMGpDFlWAZThmXQw/KXMUHNa09rishFOEnrenf5SmCCqt56gG2vwJmSZN/Vp4hkqeoOEekPfACcrqoHvfLMzc3Vo+lMW9fYzKJNu/lgbQnvrylhR3ktACOyEjhtSAanD+nByKxEQkLkiI9tjPEuEVni3j70xrHPAR4AQoGnVPX3InIvkKeqc0TkPWAkUOjusk1Vp4nIZJyirQWn68gDqvrk4c53NDmsuUVZtq2MefnFvLu6iK27nekEx+YkMWVYJlOGZzAg/YgeGjXG+Mih8pc3i7NJwD2qepa7/DMAVf1jm+3OAB7CKcwOOIu9iDwDvKmqsw92vqMtzjypKl+VVPP+mhI+WFvMkq1ltCikxUVy2pB0ThvSgxMGphMX2WUecjUmqHmzOPO1juaw1vw1b3UR8/KLWVFQAcCA9FimDM9kyrAMRmcn2YWmMQHCX8VZGM44Qafj3BZYDFzmOUmve1tgNk4L21ce69veFlgITPccY6itzijO2irb28DH60t5f20JH60roaquifBQYWL/VM4YmsH5Y7JIjLF+Hsb4ixVnB7ezvJb31hQzb3UxizbtpqlFyUiI5MxhGUwZlsmkAamEh9o45Mb4i1+KM/fEPrst4I3izFNjcwtLtpa5tz+L2Vi6l6jwEL49NptrJvdlcGa8185tjDkwK87ap6KmkQ/XlTAvv4iP1pVS09DMwB5x/O78EUzon+qVcxpjDs1vxZkvebs4ayt/ZyXPLtzC68t2UN/UwqT+qVw9uS9nDssg1G4bGOMTVpwdubrGZt5bU8wf565lR3ktFx2bzc/OHkJqXKTXz22M+ZoVZ15UtreBl/K289zCreworyUrKZorJ/VhxnG9SYqJ8Hk8xnQnVpwdvZqGJh76YAOPf7KJuKgwfnb2EL5zbG/rk2aMj1hx5gNNzS28t6aEmQu2sHDTbqLCQzh/TBZXT+7L0J4JfovLmK7MirOOW19cxS9fX8UXW/ZwbJ9kfv/tEQzJtJxljLdZceZja4sqmblgK68vK6CusYUJ/VL47vF9OWNoBmHWAdeYTmPFWedQVWYvKeAPc9dQWdfE9Sf04/YzBhITYU+mG+MtVpz5SXlNAy/nbWfmAueWZ6/EKK6Y1IcZx+WQEmu3PI3pKCvOOlfZ3gb+9M5aZi3eTlZSNL85bxhThmf6NSZjuiorzvysuUV5f00xzyzYwoKNu4kMC2H6mF7cfPIA+tsAkcYcNSvOvCNvyx5+8foq1hVXccbQDO6ZNozs5Bh/h2VMl3Ko/GX32HwgNESYMjyTF26YyLs/PIkLj83mjeWFnPvQZ7y5Yqe/wzPGmP3k9k3hzdtO4GdnD+F/G3Zx5t8+4ZGPN9LY3OLv0IzpFqw487HBmfH84dsj+fDOUxiSGc+tLyzjd2/mW9IzxgSU8NAQbjp5AO/dcTInDEzjvrfXcu6Dn7F4yx5/h2ZMl2fFmZ9kJkYx68ZJXDO5L098tpnLn/ickqo6f4dljDH7yUqK5vGrcnn8qlyq65v4ziML+cns5ezZ2+Dv0Izpso6oOBOREBGxZ6w7SURYCPdMG879l4xmRUE55z74GXl2VWqMCUBnDstg/o9P4uaTB/Da0h1Muf9jVhSU+zssY7qkwxZnIvKCiCSISCywCsgXkbu8H1r38e2x2bz+veOJjghlxmOLeOZ/m+kqD2oYY7qOmIgw7j57CG/edgJR4aFc+tgiFmzc5e+wjOly2tNyNkxVK4HzgbeBfsCV3gyqOxraM4E5t57AKYPTueeNfH700pfUNDT5OyxjjPmGIZkJzL55Mr2Sornm6cW8u7rI3yEZ06W0pzgLF5FwnOJsjqo2Atas4wWJ0eE8dmUud04ZxH+X7+TbDy9g8669/g7LGGO+ITMxipdvmsSwngnc8u8lvJK33d8hGdNltKc4exTYAsQCn4hIH6DSm0F1ZyEhwq2nDWTmd8dTXFXHtIc+Y35+sb/DMsaYb0iOjeD56ycweUAad81ewROfbvJ3SMZ0CYctzlT1QVXNUtVz1LEVONUHsXVrJw1K541bT6BvWiw3PJvHX99dR3OLNVgaYwJLbGQYT16TyzkjM/ndW2v467vrrM+sMR3UngcCbncfCBAReVJElgKn+SC2bq93Sgyv3DyJGcf15h8fbuCap7+wx9eNMQEnMiyUhy4dty9X/fI/q+xi0pgOaM9tzWvdBwKmAMk4DwPc59WozD5R4aHcd+Eo7rtgJJ9v3sN5D33G8u3l/g7LGGP2Exoi/PGCkdx88gCe/3wbt89aRkOTDa5tzNFoT3Em7vs5wHOqutpjnfGRGeNzmH3zJAC+88hCZn2xzc8RGWPM/kSEu88e4gy3saKQG57Ns6fOjTkK7SnOlojIPJzi7F0RiQfscsgPRmUn8cYPTmBC/xTufm0lP529wq5MjTEB5+aTB3DfBSP59KtSrnzyCypqGv0dkjFBpT3F2XXA3cBxqloDRADf9WpU5qBSYiN45rvjufXUY3gpbzvXPrOY6nq7MjXGBJYZ43N4+LJxrCyo4JLHFlJSadPTGdNe7XlaswXIBn4pIn8FJqvqCq9HZg4qNES486zB/OWiUSzctJsZjy2ktKre32EZ06WIyFQRWSciG0Tk7gN8/2MRyReRFSLyvjvMUOt3V4vIV+7rat9GHjjOHtmTp645jm17arjokYVs213j75CMCQrteVrzPuB2IN993SYif/B2YObwvpPbmyeuymVjyV4u/NcCttiAtcZ0ChEJBR4GzgaGAZeKyLA2my0DclV1FDAb+LO7bwrwG2ACMB74jYgk+yr2QHPCwDReuGEilXWNXPjIAtYW2TCZxhxOe25rngOcqapPqepTwFTg3PYc3K48ve/UIT144YYJVNU1ctEjC1hZUOHvkIzpCsYDG1R1k6o2ALOA6Z4bqOqHblcPgEU4dxgAzgLmq+oeVS0D5uPkzW5rTO8kXrlpEqEiXPzIQpZs3ePvkIwJaO0pzgCSPD4ntmcHu/L0nbE5ycy+ZTKRYaHMeGwhn35V6u+QjAl2WYDnfEQF7rqDuQ5n7uEj2ldEbhSRPBHJKy3t2v9uB2bE88rNk0iNi+SKJ77g4/Vd++c1piPaU5z9EVgmIs+IyExgCfD7duxnV54+NCA9jte+N5neKTFc+8xi/vvlDn+HZEy3ICJXALnAX450X1V9TFVzVTU3PT2984MLML1TYnj5pkn0S4vl+pmWp4w5mPY8EPAiMBF4DXgVmIQz1+bheP3KsztddbZHRkIUL900ibE5ydw+60ub586Yo7cD6O2xnO2u24+InAH8ApimqvVHsm93lR4fyaybJjLOzVOPfLzRpnsypo123dZU1UJVneO+ioBXOjOIo73y7G5Xne2RGB3Os9eOZ+pwZ567P85dQ4tNo2LMkVoMDBSRfiISAcwA5nhuICJjgUdxCrMSj6/eBaaISLLbHWOKu864EqLCefa68Zw7qif3vb2WX/93tU33ZIyH9vY5a6s9MwTYlaefRIWH8vDl47hiYg6PfrKJO19ZTmOzDVZrTHupahNwK05RtQZ4WVVXi8i9IjLN3ewvQBzwioh8KSJz3H33AL/FKfAWA/e664yHyLBQHpwxlptO6s9zi7Zy03NLqG1o9ndYxgQEOZrmZBHZpqo5h9kmDFgPnI5TWC0GLnOnf2rdZizOgwBTVfUrj/UpOH3bxrmrlgLHHirB5ebmal5e3hH/LF2ZqvKPDzbw/+av5+RB6fzz8nHERob5OyxjOo2ILFHVXH/H0Rm6cw57duEWfjNnNaOyk3jy6lzS4iL9HZIxXneo/HXQ/6lF5A3gQJWbAKmHO6mqNolI65VnKPBU65UnkKeqc9j/yhNgm6pOU9U9ItJ65Ql25XlURIQfnD6Q9PhIfv76Si57fBFPXXMcqZb4jDEB5KpJfclMiOK2Wcu44J8LmHntePqlxfo7LGP85qAtZyJy8qF2VNWPvRLRUerOV53tMT+/mFtfWEqvpGievXY8vVNi/B2SMR1mLWddy7JtZVw3Mw9V5Ymrj+PYPjaCkum6DpW/DtrnTFU/PtTLe+EabzhzWAbPXz+BPXsbuOBfC8jfaaN0G2MCy9icZF67ZTKJ0eFc9vgi3llV5O+QjPGLo30gwASh3L4pvHLzJMJChEseXciCjbv8HZIxxuynb1osr94ymWG9Erjl+SU887/N/g7JGJ+z4qybGZQRz6u3TCYzMYprnlrM68sK/B2SMcbsJzUukheun8gZQzO45418fv9Wvg0JZLoVK866oV5J0bxy8yTG5CTxo5eWc/erK+wRdmNMQImOCOWRK47l6kl9ePzTzfzgxWXUNVqeMt3DYcdVOMhTmxVAHvCoqtZ5IzDjXUkxETx//QTun7+ef360kaXbynj4snEMzIj3d2jGGANAaIhwz7ThZCVH84e5aympquPxq3JJionwd2jGeFV7Ws42AdXA4+6rEqgCBrnLJkiFh4bwk6lDmHnteHZXN3DePz7j5bztNpWKMSZgiAg3njSAhy4dy/LtFVz4rwVs31Nz+B2NCWLtKc4mq+plqvqG+7oCOE5Vv8/Xg8SaIHbyoHTevv1ExvZO5iezV/Djl5dTXd/k77CMMWaf80b34rnrxlNaVc+3/7mAlQUV/g7JGK9pT3EWJyL7ZgNwP8e5iw1eicr4XI+EKP59/QR+dMYg/vvlDqY99Bmrd1ryM8YEjgn9U3nte5OJDAvhkscW8sHaYn+HZIxXtKc4uwP4TEQ+FJGPgE+BO0UkFpjpzeCMb4WGCLefMZDnr59IdX0T3/7nAp5btNVucxpjAsYxPeJ5/XuT6Z8ey7XP5HHPnNXUNFhLv+laDlucqepcYCDwQ+B2YLCqvqWqe1X1Ae+GZ/xh0oBU3r79RCb1T+VX/1nF919YSmVdo7/DMsYYwGnpf/mmSVwzuS/PLNjCWQ98YuM2mi6lvUNpHAsMB0YDF4vIVd4LyQSC1LhInr7mOO4+ewjvri7mWw9+yvLt5f4OyxhjAIiJCOOeacN5+aZJhIpw2eOf88v/rLT+sqZLOGxxJiLPAX8FTgCOc19dYi47c2ghIcLNJw/g5Zsm0dICFz2ygCc+3WS3OY0xAWN8vxTevv0krj+hH89/vo2z7v+Ez76yVjQT3NrTcpYLHK+q31PVH7iv27wdmAkcx/ZJ5q3bTuDUwT343VtruOHZPMr22rMgxpjAEB0Ryi/PHcbsmycRGR7CFU9+zs9eW0GVdccwQao9xdkqINPbgZjAlhQTwaNXHss95w3jk/W7OOfBT8nbssffYRljzD7H9klh7m0nctNJ/Xlp8XbOuv8TPl5f6u+wjDli7SnO0oB8EXlXROa0vrwdmAk8IsI1x/fj1VsmExEWwiWPLeIfH3xFQ1OLv0MzxhgAosJD+dk5Q3n1lsnERIZx9VNfcNcry6motVY0EzzkcP2HROTkA61X1Y+9EtFRys3N1by8PH+H0W1U1TXy89dX8cbynfRJjeEnZw3hnJGZiIi/QzPdiIgsUdUu0QfWcljnq2ts5sH3v+LRTzaRFhfBHy8YyWlDMvwdljHAofPXYYuzYGGJzfdUlY/Wl3Lf3LWsK65iTO8kfvGtoRzXN8XfoZluwooz0x4rCsq565UVrCuu4oJxWfzm3OEkxoT7OyzTzR0qfx30tqaIfOa+V4lIpcerSkQqvRWsCR4iwqmDezD39hP580WjKKyo5TuPLOSGZ/PYUFLt7/CMMQaAUdlJzPnB8dx22jHM+XInZ9z/MfPzbXYBE7gOWpyp6gnue7yqJni84lU1wXchmkAXGiJcnNubj+48lbvOGszCjbs564FP+MXrKympqvN3eMYYQ2RYKD+eMpj/fP940uIiueHZPG6ftYzSqnp/h2bMN7RrEFoRCRWRXiKS0/rydmAm+ERHhPL9U4/h47tO4YoJOby0eDun/OUj/v7eV+y1gSFNkBGRqSKyTkQ2iMjdB/j+JBFZKiJNInJRm++aReRL92UPUAWQEVmJ/Pf7x/OjMwbx1opCTvrzh/zpnbWU19jwQCZwtOeBgB8AvwGKgdbH8lRVR3k5tiNi/TUCz+Zde/nLu2uZu7KI9PhIfnTGIC7OzSYstL0TUxhzaN7qcyYiocB64EygAFgMXKqq+R7b9AUSgDuBOao62+O7alWNO5JzWg7zvU2l1Tzw3le8sWIncRFh3HBSf649oR9xkWH+Ds10A0fV58xD63yaw1V1pPtqV2FmV57dW7+0WP55+bG8estk+qTE8PPXVzL175/yXn6xzTJgAt14YIOqblLVBmAWMN1zA1Xdoqor+Pqi1QSZ/ulxPHjpWN6+/UQmDkjlb/PXc+KfPuCxTzZS19js7/BMN9ae4mw7UHGkB3avPB8GzgaGAZeKyLA2m20DrgFeOMAhalV1jPuadqTnN4Hj2D7JvHLzJB698lhaWpTrn81jxmOLbK5OE8iycHJfqwJ3XXtFiUieiCwSkfM7NTLT6YZkJvD4Vbn89/vHMyIrkT/MXctJf/6QZxdusXEcjV+0p+12E/CRiLwF7Os5qap/O8x++648AUSk9cpz320BVd3ifme//V2ciHDW8ExOG9KDWYu38/f31jP94f9x7qie/PCMgRzTI97fIRrTmfqo6g4R6Q98ICIrVXVj241E5EbgRoCcHOvK62+jeyfx3HUT+HzTbv46bx2//u9qHv14E7efMZALxmZZlwzjM+35TdsGzAcigHiP1+F4/cpTRG50t8krLbUpOoJBeGgIV07sw0d3ncptpx3D+2tKOONvn3DFE58zP7+Y5ha73WkCwg6gt8dytruuXVR1h/u+CfgIGHuQ7R5T1VxVzU1PTz/6aE2nmtA/lZdvmsTMa8eTGhfBT2avYMr9nzBn+U5aLEcZHzhsy5mq/p8vAjmAw155qupjwGPgdKb1R5Dm6MRFhvHjKYO5enJfZi3ezr8XbeWGZ/PITo7myol9uOS43iTFRPg7TNN9LQYGikg/nKJsBnBZe3YUkWSgRlXrRSQNOB74s9ciNV4hIpw8KJ2TBqYxL7+Yv81bz20vLuOfH27gx2cO4sxhGTYjivGagxZnIvKAqv5QRN4AvlH4tKMfWKddeYrIRzhXnt+4LWCCW2pcJN8/9RhuOqk/8/OLeXrBFv749lruf28954/J4urJfRna04bVM76lqk0icivwLhAKPKWqq0XkXiBPVeeIyHHA60AycJ6I/J+qDgeGAo+63TVCgPs8n/I0waW1S8YZQzN4c8VOHnjvK258bgmjeydx55RBnHBMmhVpptMddCgNETlWVZcc7dyaIhKG8yj66ThF2WLgMlVdfYBtnwHebH0U/QBXnguB6YdKcPYYetexprCSZxdu4fVlO6hrbGF8vxSumdyXKcMyrM+H2Y9N32R8ram5hVeXFvDg+xvYUV7LmN5JTB/Ti7NH9CQzMcrf4Zkg4re5NUXkHOABvr7y/P0hrjzrgCJVHS4ik4FHcR5RDwEeUNUnD3UuS2xdT3lNAy/nbefZhVspKKulZ2IUl0/I4dLxOaTGRfo7PBMArDgz/lLf1MysL7bzwufbWFdcBUBun2TOGdmTs0dm0jMx2s8RmkDXoeJMRAYCf8QZDmPfZYGq9u/MIDvKElvX1dyifLC2hJkLtvDZhl1EhIZw7uieXDO5L6Oyk/wdnvEjK85MINhQUs3clYXMXVnI2iKnUBuXk8Q5I3tyzsie9EqyQs18U0eLs89wZgi4HzgP+C4Qoqq/7uxAO8ISW/ewoaSKmQu28urSAmoamhmbk8SVE/tw5rAM4qPC/R2e8TErzkyg2VhazdsrC3lrZRFrCisBGJuTxLdG9uTskT3JskLNuDpanC1R1WPdpyVHeq7zQqxHzRJb91JZ18irSwp4duFWNu/aS0RoCCcMTGPq8EzOGJZBSqw96dkdWHFmAtmm0mreXlXEWysKyXcLtTG9nUJt6ohMeqfE+DlC408dLc4WACcAs4EPcDr336eqgzs70I6wxNY9tbQoS7eV8c6qIt5eVcSO8lpCQ4QJ/VKYOiKTKcMyrZNuF2bFmQkWW3btZe4q59bnqh1OoTY6O3HfrU8r1LqfjhZnxwFrgCTgtzgT/f5FVRd1cpwdYonNqCqrd1a6hVohG0v3Ak7fj6kjMpk6vCc5qZYAuxIrzkww2rp7L3NXFjF3ZSErdzizI47ISuDsEU6L2oD0OD9HaHzhqIszd37MP6nqnd4KrrNYYjNtbSip4p1VRbyzumjflerQngmcPSKTqSMyGdgjzsYnCnJWnJlgt31PDW+vKuTtVUUs21YOwOCMeKaOyOSckT0ZlGF5qqs6quJMRMLcgRgXqepEr0bYCSyxmUPZvqeGd1cX8c6qIpZsK0MV+qfFctaITM4ekcmIXomEhFgCDDZWnJmupLCidl8XjcVb9uzLU62F2vBeCVaodSFHW5wtVdVxIvIvnDkxXwH2tn6vqq95I9ijZYnNtFdJZR3v5hfz7qoiFm7aTXOLkhIbwcT+KUzsn8rE/qnWqhYkrDgzXVVJVR3zVhfzjkeeyk6O5hz3YYIx2Ul2QRnkOlqcPe2xWgEBVFWv7fxQj54lNnM0yvY28P7aEhZs3MWijbvZWVEHQGpshFOoDUhlUv8UBqRbsRaIrDgz3UHZ3gbm5xfz9qpCPtuwi8ZmpWdiFGcNd1r+c/umEGqFWtA52uKsAPgbbjHmvrdSVf1bZwfaEZbYTEepKtv31LJw0y4WbdrDwo27Kap0irW0uEgm9k9h0gCnZa1/WqwVawHAijPT3VTUNvLB2mLeXlnEx+tLqW9qIT4qjFHZiYzMSmJ0diKjeifRKzHKclSAO1T+OujE5zhTLsWxf1HWyntzPhnjJyJCTmoMOak5XHJcDqrK1t01LNq0m4WbdrNw427eXFEIQI/4SCb2T91XrPVNjbFEaIzxusTocL49Nptvj81mb30TH64rYcHG3awsqODJzzbR2Oz895waG+EUbNluwZadRHq8TXsXLA5VnBWq6r0+i8SYACMi9E2LpW9aLDPGO8Xa5l17nVY1t2Cbs3wnAOnxkYx2r1xHZicwMssSoTHGu2Ijwzh3VC/OHdULgLrGZtYWVbGyoJzlBRWsKCjn4/WltLjNKT0ToxjlFmqjshMZlZVEYozNrBKIDlWcWTOAMR5EhP7pcfRPj+OyCU6xtmnXXhZu3M2SrWWs3FHB+2tLUI9EODIrcd/V68isRJu5wBjjNVHhoYzpncSY3klc6a7bW9/E6p2VrCgoZ4VbsL27unjfPn1SYxiVncSwngkM6RnPsJ4J9IiPtDsBfnao4ux0n0VhTBASEQakxzEgPY4rJvYBoLq+idU7KljZ+iqoYF7+14kwKynaLdacq9aRWYl25WqM8ZrYyDDG90thfL+UfesqahpZuaOCFTvKWbG9gqVby3jDvQsAkBIbwZDMeIb2TNj3PjAjjsiwUH/8CN3SQYszVd3jy0CM6QriIsOY0D+VCf1T962rrGtklVuordhRwaodFby9qmjf9zkpMYzMTmRoZjzH9IhnUEYcfVJj7ekrY4xXJMaEc8LANE4YmLZvXUVNI2uLKllTWMmawirWFlXy/OdbqWtsASA0RBiQHusWbAkMdVvZ0q2VzSsO1XJmjOkECVHhTB6QxuQBXyfC8poGVu2oZMWOclYWVLB8ezlvuQ8bAESEhTAgPY6BPeIYlBHHwIx4BmXEk5MSY0WbMabTJcaEf+PCsrlF2bJ7r1uwVbK2sIrFm/fw3y/3b2Ub2jOeIZkJDM6MZ2im08oWFW6tbB1hxZkxfpAUE/GNK9fq+iY2lFTzVXEVX5VUs764iiVby/Y9dABfF22DMpzCzYo2Y4y3OK1lTteN1ocOwGllW1P0dcG2pqiSfy/aSn2T08oWItA3LZYhmfEMznD6sg3JjKd3cowNnNtOVpwZEyDiIsP2deb1dKCiLW9L2X5XrxFhIfRPi6VfWix9UmPplxZD31TnSVPr3GuM6UyJMeH7ZlNp1dyibN29l7VFVawtqmJdUSWrd1by9qqifQ9JxUSEMigjnqE94xmcEc/gTKdPW7I9KPUNVpwZE+AOV7StL65iQ0k1G0uqWVdcxXtriveNdQROQmwt2PqkxtLPLdr6psZYfxFjTKcIDfn6afZzRvbct35vfRPri6tY5xZta4ucgu3FL7bv2yYjIZLBmQnkpESTnRxDdvLX76mxEd0yR1lxZkyQOljR1tTcQmFFHZt37WXL7r1s3rWXrbtrWFtYxbzVxTS1fF24xbqFW1+3pS0nJYbeKTH0To6hZ1IU4aEhPv6pjDFdSWxkGGNzkhmbk7xvnapSUlXvFGuFlawrqmJ9SRXLt5dTUdu43/5R4SFkJe1ftGUlR7ufo0mP65oXmFacGdPFhIWGOAVWSgwnkb7fd03NLewor91XsLUWcPk7K3l3dTHNHoVbaIiQmRBF75Roeie7RZvH5/S4SOs/Yow5YiJCRkIUGQlRnDxo/xxVVdfIjvJaCvbUUlBWQ0FZLQVltewor2VFQTllNfsXb5FhIWQlR5OV5Lxaj5uZGOm8J0SREoStb1acGdONhIWG0CfV6ZfWVmuL2/Y9NWwvq2H7nlr3vYaP1pdSWlW/3/atSbF3cozb4uZc1fZKiqZXUhRpscFdvInIVODvOFPZPaGq97X5/iTgAWAUMENVZ3t8dzXwS3fxd6o60ydBGxPk4qPCGZIZzpDMhAN+X13fxI6yrwu3HeXO5+17allTWMXuvfW0nTI8IjSE9PhIMhOdYs2zeGst4DITowLqCVOvFmeW3IwJHp4tbgdS19i8Lwm2Fm2tn5dtK6Oyrmm/7SNCQ+iZFEWvxGh6JUWTlRRFr6Roenp8jokIzOtDEQkFHgbOBAqAxSIyR1XzPTbbBlwD3Nlm3xTgN0AuzjzES9x9y3wRuzFdWVxkGIMz4xmcGX/A7xubWyipqqe4so7iijqKKp1XSWU9RRV1rCms5MN1JdQ0NH9j34SoMNLjI0mLiyQtPpL0uEjS4iKc5bhI57t4Z523B+T1Wma05GZM1xIVHsoxPZyBcg+koraRHWW17CyvZWeFc0W7s7yOwvJaFm7cRVFlHS1trmiTYsK/UbydNTyTvmnfbNnzsfHABlXdBCAis4DpwL78papb3O9a2ux7FjC/dSBvEZkPTAVe9H7YxnRv4aEh+25xHoyqUl3fRHFlHUUV9RRV1jnFXGUdu6rr2VXVwJqdlXxSXU9Vm4vOVvFRYW7xFklavFPApcdFMjwrgdOGZHT45/DmZaslN2O6kcTocBKjwxnW68C3I5qaWyiuqneKt/LW4s0p4ArKavh8826q6poYlBEfCMVZFrDdY7kAmNCBfbMOtKGI3AjcCJCTk3PkURpjjpiIEB8VTnxU+EEvNlvVNTaze28DpVX17Kqqd4q36np2VTdQWu2sW1dUxf+qd1NR28i5o3oGfHHm9eRmic2Y4BHWjivayrpGIrrRE6Kq+hjwGEBubq4eZnNjjI9FhYceNm+1qm9q3jcQb0cFdRZU1cdUNVdVc9PT0w+/gzEmoCVEhQdKp9wdQG+P5Wx3nbf3NcYEqciwUBKiwjvlWN4sziy5GWOC1WJgoIj0E5EIYAYwp537vgtMEZFkEUkGprjrjDGmXbxZnFlyM8YEJVVtAm7FyTtrgJdVdbWI3Csi0wBE5DgRKQC+AzwqIqvdffcAv8XJgYuBe1v7zxpjTHuIth0QpDMPLnIOzlAZocBTqvp7EbkXyFPVOSJyHPA6kAzUAUWqOtzd91rg5+6hfq+qTx/mXKXA1iMILw3YdSQ/jxdYDBaDxdCxGPqoapfo03CEOSzY/p4sBovBYvimg+YvrxZngUxE8lQ112KwGCwGiyHYBMKfkcVgMVgM3oshqB8IMMYYY4zpaqw4M8YYY4wJIN25OHvM3wFgMbSyGBwWgyMQYgh0gfBnZDE4LAaHxeDolBi6bZ8zY4wxxphA1J1bzowxxhhjAo4VZ8YYY4wxAaTbFWciMlVE1onIBhG52w/n7y0iH4pIvoisFpHbfR2DRyyhIrJMRN700/mTRGS2iKwVkTUiMskPMfzI/XtYJSIvikiUD875lIiUiMgqj3UpIjJfRL5y35P9EMNf3L+LFSLyuogk+ToGj+/uEBEVkTRvxhCMLIftF4vlMMthXTKHdaviTERCgYeBs4FhwKUiMszHYTQBd6jqMGAi8H0/xNDqdpzRz/3l78A7qjoEGO3rWEQkC7gNyFXVETiDJc/wwamfAaa2WXc38L6qDgTed5d9HcN8YISqjgLWAz/zQwyISG+cWUG2efn8Qcdy2DdYDrMc5qnL5LBuVZwB44ENqrpJVRuAWcB0XwagqoWqutT9XIXzjznLlzEAiEg28C3gCV+f2z1/InAS8CSAqjaoarkfQgkDokUkDIgBdnr7hKr6CdB2Op/pwEz380zgfF/HoKrz3GmLABbhzGnr0xhc9wM/AexppW+yHOayHLaP5bCv13WZHNbdirMsYLvHcgF+SCqtRKQvMBb43A+nfwDnl6fFD+cG6AeUAk+7tyWeEJFYXwagqjuAv+Jc3RQCFao6z5cxeMhQ1UL3cxGQ4ac4Wl0LvO3rk4rIdGCHqi739bmDhOWwrz2A5TDLYQcX1DmsuxVnAUNE4oBXgR+qaqWPz30uUKKqS3x53jbCgHHAv1R1LLAX7zeD78ftEzEdJ8n2AmJF5ApfxnAg6oxv47dWIxH5Bc6tq+d9fN4YnPl0f+3L85qjYznMctjBWA7reA7rbsXZDqC3x3K2u86nRCQcJ6k9r6qv+fr8wPHANBHZgnNb5DQR+bePYygAClS19Yp7Nk6i86UzgM2qWqqqjcBrwGQfx9CqWER6ArjvJf4IQkSuAc4FLlffD4I4AOc/meXu72Y2sFREMn0cRyCzHOawHOawHNZGV8lh3a04WwwMFJF+IhKB03Fyji8DEBHB6aOwRlX/5stzt1LVn6lqtqr2xfkz+EBVfXq1papFwHYRGeyuOh3I92UMOLcCJopIjPv3cjr+61w8B7ja/Xw18F9fByAiU3FuE01T1Rpfn19VV6pqD1Xt6/5uFgDj3N8V47AchuUwD5bDPHSlHNatijO3o+CtwLs4v8Avq+pqH4dxPHAlzpXel+7rHB/HECh+ADwvIiuAMcAffHly94p3NrAUWInz78Hr03+IyIvAQmCwiBSIyHXAfcCZIvIVztXwfX6I4R9APDDf/b18xA8xmEOwHBZwLIdZDvNKDrPpm4wxxhhjAki3ajkzxhhjjAl0VpwZY4wxxgQQK86MMcYYYwKIFWfGGGOMMQHEijNjjDHGmABixZnpskTkFBF5099xGGPMkbL81b1ZcWaMMcYYE0CsODN+JyJXiMgX7qCBj4pIqIhUi8j9IrJaRN4XkXR32zEiskhEVojI6+7ccojIMSLynogsF5GlIjLAPXyciMwWkbUi8rw7ijYicp+I5LvH+auffnRjTJCz/GW8wYoz41ciMhS4BDheVccAzcDlQCyQp6rDgY+B37i7PAv8VFVH4YyI3br+eeBhVR2NM7dcobt+LPBDYBjQHzheRFKBbwPD3eP8zps/ozGma7L8ZbzFijPjb6cDxwKLReRLd7k/0AK85G7zb+AEEUkEklT1Y3f9TOAkEYkHslT1dQBVrfOYV+0LVS1Q1RbgS6AvUAHUAU+KyAWAz+dgM8Z0CZa/jFdYcWb8TYCZqjrGfQ1W1XsOsN3RzjNW7/G5GQhz5yccjzMn3bnAO0d5bGNM92b5y3iFFWfG394HLhKRHgAikiIifXB+Ny9yt7kM+ExVK4AyETnRXX8l8LGqVgEFInK+e4xIEYk52AlFJA5IVNW5wI+A0V74uYwxXZ/lL+MVYf4OwHRvqpovIr8E5olICNAIfB/YC4x3vyvB6dcBcDXwiJu8NgHfdddfCTwqIve6x/jOIU4bD/xXRKJwrnx/3Mk/ljGmG7D8ZbxFVI+2tdUY7xGRalWN83ccxhhzpCx/mY6y25rGGGOMMQHEWs6MMcYYYwKItZwZY4wxxgQQK86MMcYYYwKIFWfGGGOMMQHEijNjjDHGmABixZkxxhhjTAD5/0Jq8ZJSVy+9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history21.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history21.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history21.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history21.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8559556603431702 | 0.9385308027267456 |\n",
      "|  2   | 0.8527238965034485 | 0.9329344630241394 |\n",
      "|  3   | 0.8227146863937378 | 0.9160408973693848 |\n",
      "|  4   | 0.8314865827560425 | 0.9177548289299011 |\n",
      "|  5   | 0.8504155278205872 | 0.9346563816070557 |\n",
      "|  6   | 0.8490304946899414 | 0.9332733154296875 |\n",
      "|  7   | 0.8462603688240051 | 0.9301101565361023 |\n",
      "|  8   | 0.8490304946899414 | 0.9341230392456055 |\n",
      "|  9   | 0.8715935349464417 | 0.9421837329864502 |\n",
      "|  10  | 0.8568129539489746 | 0.9396765828132629 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY21)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC21)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 9\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY21.index(max(VALIDATION_ACCURACY21))\n",
    "max_fold21 = idx + 1\n",
    "print(\"Best Fold:\", max_fold21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 954us/step - loss: 0.1442 - accuracy: 0.7943 - auc: 0.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14418970048427582, 0.7943009734153748, 0.8778643608093262]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model21.load_weights(\"\\saved_models2_1/model_\"+str(max_fold21)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model21.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 801us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model21.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat21 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 2 - Even More Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.2492 - accuracy: 0.5304 - auc: 0.5018\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54524, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.5291 - auc: 0.5032 - val_loss: 0.2475 - val_accuracy: 0.5452 - val_auc: 0.5620\n",
      "Epoch 2/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.5366 - auc: 0.5776\n",
      "Epoch 2: val_accuracy improved from 0.54524 to 0.55078, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2475 - accuracy: 0.5368 - auc: 0.5783 - val_loss: 0.2459 - val_accuracy: 0.5508 - val_auc: 0.6258\n",
      "Epoch 3/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.2461 - accuracy: 0.5372 - auc: 0.6264\n",
      "Epoch 3: val_accuracy improved from 0.55078 to 0.55633, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.5375 - auc: 0.6262 - val_loss: 0.2444 - val_accuracy: 0.5563 - val_auc: 0.6563\n",
      "Epoch 4/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.2446 - accuracy: 0.5548 - auc: 0.6527\n",
      "Epoch 4: val_accuracy improved from 0.55633 to 0.58126, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.5556 - auc: 0.6535 - val_loss: 0.2427 - val_accuracy: 0.5813 - val_auc: 0.6715\n",
      "Epoch 5/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.2429 - accuracy: 0.5820 - auc: 0.6651\n",
      "Epoch 5: val_accuracy improved from 0.58126 to 0.61958, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.5831 - auc: 0.6659 - val_loss: 0.2408 - val_accuracy: 0.6196 - val_auc: 0.6808\n",
      "Epoch 6/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.2409 - accuracy: 0.6127 - auc: 0.6731\n",
      "Epoch 6: val_accuracy improved from 0.61958 to 0.63435, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2408 - accuracy: 0.6132 - auc: 0.6739 - val_loss: 0.2385 - val_accuracy: 0.6343 - val_auc: 0.6857\n",
      "Epoch 7/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2385 - accuracy: 0.6245 - auc: 0.6794\n",
      "Epoch 7: val_accuracy improved from 0.63435 to 0.64728, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2384 - accuracy: 0.6246 - auc: 0.6795 - val_loss: 0.2358 - val_accuracy: 0.6473 - val_auc: 0.6915\n",
      "Epoch 8/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.6341 - auc: 0.6860\n",
      "Epoch 8: val_accuracy improved from 0.64728 to 0.65282, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2355 - accuracy: 0.6338 - auc: 0.6862 - val_loss: 0.2325 - val_accuracy: 0.6528 - val_auc: 0.6981\n",
      "Epoch 9/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.2320 - accuracy: 0.6427 - auc: 0.6933\n",
      "Epoch 9: val_accuracy improved from 0.65282 to 0.66159, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2318 - accuracy: 0.6440 - auc: 0.6949 - val_loss: 0.2281 - val_accuracy: 0.6616 - val_auc: 0.7079\n",
      "Epoch 10/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.6515 - auc: 0.7090\n",
      "Epoch 10: val_accuracy improved from 0.66159 to 0.67175, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2263 - accuracy: 0.6515 - auc: 0.7090 - val_loss: 0.2214 - val_accuracy: 0.6717 - val_auc: 0.7245\n",
      "Epoch 11/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.2174 - accuracy: 0.6700 - auc: 0.7331\n",
      "Epoch 11: val_accuracy improved from 0.67175 to 0.69344, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2172 - accuracy: 0.6702 - auc: 0.7332 - val_loss: 0.2095 - val_accuracy: 0.6934 - val_auc: 0.7547\n",
      "Epoch 12/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.2014 - accuracy: 0.7044 - auc: 0.7733\n",
      "Epoch 12: val_accuracy improved from 0.69344 to 0.73361, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2009 - accuracy: 0.7051 - auc: 0.7745 - val_loss: 0.1888 - val_accuracy: 0.7336 - val_auc: 0.8014\n",
      "Epoch 13/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.7477 - auc: 0.8256\n",
      "Epoch 13: val_accuracy improved from 0.73361 to 0.76916, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.7484 - auc: 0.8262 - val_loss: 0.1622 - val_accuracy: 0.7692 - val_auc: 0.8487\n",
      "Epoch 14/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.7863 - auc: 0.8645\n",
      "Epoch 14: val_accuracy improved from 0.76916 to 0.79686, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1515 - accuracy: 0.7865 - auc: 0.8646 - val_loss: 0.1423 - val_accuracy: 0.7969 - val_auc: 0.8765\n",
      "Epoch 15/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.8057 - auc: 0.8879\n",
      "Epoch 15: val_accuracy improved from 0.79686 to 0.80794, saving model to \\saved_models2_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1355 - accuracy: 0.8061 - auc: 0.8879 - val_loss: 0.1315 - val_accuracy: 0.8079 - val_auc: 0.8943\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.8079 - auc: 0.8943\n",
      "Epoch 1/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.5699 - auc: 0.5878\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60988, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2471 - accuracy: 0.5706 - auc: 0.5892 - val_loss: 0.2445 - val_accuracy: 0.6099 - val_auc: 0.6508\n",
      "Epoch 2/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.6444 - auc: 0.6919\n",
      "Epoch 2: val_accuracy improved from 0.60988 to 0.65928, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2391 - accuracy: 0.6447 - auc: 0.6922 - val_loss: 0.2329 - val_accuracy: 0.6593 - val_auc: 0.7332\n",
      "Epoch 3/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.7026 - auc: 0.7643\n",
      "Epoch 3: val_accuracy improved from 0.65928 to 0.73176, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2204 - accuracy: 0.7030 - auc: 0.7644 - val_loss: 0.2042 - val_accuracy: 0.7318 - val_auc: 0.8021\n",
      "Epoch 4/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1885 - accuracy: 0.7496 - auc: 0.8224\n",
      "Epoch 4: val_accuracy improved from 0.73176 to 0.76824, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1883 - accuracy: 0.7498 - auc: 0.8218 - val_loss: 0.1715 - val_accuracy: 0.7682 - val_auc: 0.8481\n",
      "Epoch 5/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.7784 - auc: 0.8560\n",
      "Epoch 5: val_accuracy improved from 0.76824 to 0.79825, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1616 - accuracy: 0.7793 - auc: 0.8570 - val_loss: 0.1504 - val_accuracy: 0.7982 - val_auc: 0.8760\n",
      "Epoch 6/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1453 - accuracy: 0.8004 - auc: 0.8795\n",
      "Epoch 6: val_accuracy improved from 0.79825 to 0.81579, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1448 - accuracy: 0.8014 - auc: 0.8808 - val_loss: 0.1369 - val_accuracy: 0.8158 - val_auc: 0.8913\n",
      "Epoch 7/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1339 - accuracy: 0.8136 - auc: 0.8953\n",
      "Epoch 7: val_accuracy improved from 0.81579 to 0.82595, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.8144 - auc: 0.8962 - val_loss: 0.1274 - val_accuracy: 0.8259 - val_auc: 0.9039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.8237 - auc: 0.9066\n",
      "Epoch 8: val_accuracy improved from 0.82595 to 0.82872, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1255 - accuracy: 0.8237 - auc: 0.9066 - val_loss: 0.1209 - val_accuracy: 0.8287 - val_auc: 0.9127\n",
      "Epoch 9/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.8288 - auc: 0.9150\n",
      "Epoch 9: val_accuracy improved from 0.82872 to 0.83518, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1194 - accuracy: 0.8288 - auc: 0.9150 - val_loss: 0.1157 - val_accuracy: 0.8352 - val_auc: 0.9189\n",
      "Epoch 10/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.8366 - auc: 0.9210\n",
      "Epoch 10: val_accuracy improved from 0.83518 to 0.84395, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8364 - auc: 0.9209 - val_loss: 0.1116 - val_accuracy: 0.8440 - val_auc: 0.9253\n",
      "Epoch 11/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1097 - accuracy: 0.8440 - auc: 0.9270\n",
      "Epoch 11: val_accuracy improved from 0.84395 to 0.84718, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.8431 - auc: 0.9265 - val_loss: 0.1084 - val_accuracy: 0.8472 - val_auc: 0.9303\n",
      "Epoch 12/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1064 - accuracy: 0.8460 - auc: 0.9314\n",
      "Epoch 12: val_accuracy improved from 0.84718 to 0.84857, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.8467 - auc: 0.9312 - val_loss: 0.1046 - val_accuracy: 0.8486 - val_auc: 0.9343\n",
      "Epoch 13/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.8531 - auc: 0.9351\n",
      "Epoch 13: val_accuracy improved from 0.84857 to 0.85596, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1027 - accuracy: 0.8538 - auc: 0.9356 - val_loss: 0.1011 - val_accuracy: 0.8560 - val_auc: 0.9383\n",
      "Epoch 14/15\n",
      "563/610 [==========================>...] - ETA: 0s - loss: 0.0987 - accuracy: 0.8595 - auc: 0.9401\n",
      "Epoch 14: val_accuracy improved from 0.85596 to 0.86242, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.8591 - auc: 0.9398 - val_loss: 0.0986 - val_accuracy: 0.8624 - val_auc: 0.9424\n",
      "Epoch 15/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.8660 - auc: 0.9444\n",
      "Epoch 15: val_accuracy improved from 0.86242 to 0.86842, saving model to \\saved_models2_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.8658 - auc: 0.9444 - val_loss: 0.0938 - val_accuracy: 0.8684 - val_auc: 0.9464\n",
      "68/68 [==============================] - 0s 990us/step - loss: 0.0938 - accuracy: 0.8684 - auc: 0.9464\n",
      "Epoch 1/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.5428 - auc: 0.5597\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54940, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2478 - accuracy: 0.5428 - auc: 0.5597 - val_loss: 0.2459 - val_accuracy: 0.5494 - val_auc: 0.6036\n",
      "Epoch 2/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.5436 - auc: 0.6418\n",
      "Epoch 2: val_accuracy improved from 0.54940 to 0.55540, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2450 - accuracy: 0.5440 - auc: 0.6427 - val_loss: 0.2425 - val_accuracy: 0.5554 - val_auc: 0.6778\n",
      "Epoch 3/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.2401 - accuracy: 0.5639 - auc: 0.7070\n",
      "Epoch 3: val_accuracy improved from 0.55540 to 0.60988, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2399 - accuracy: 0.5657 - auc: 0.7094 - val_loss: 0.2353 - val_accuracy: 0.6099 - val_auc: 0.7307\n",
      "Epoch 4/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.6472 - auc: 0.7612\n",
      "Epoch 4: val_accuracy improved from 0.60988 to 0.69160, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2273 - accuracy: 0.6473 - auc: 0.7614 - val_loss: 0.2177 - val_accuracy: 0.6916 - val_auc: 0.7715\n",
      "Epoch 5/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.2028 - accuracy: 0.7266 - auc: 0.8052\n",
      "Epoch 5: val_accuracy improved from 0.69160 to 0.73592, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2026 - accuracy: 0.7266 - auc: 0.8051 - val_loss: 0.1936 - val_accuracy: 0.7359 - val_auc: 0.8047\n",
      "Epoch 6/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.7616 - auc: 0.8396\n",
      "Epoch 6: val_accuracy improved from 0.73592 to 0.76270, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1767 - accuracy: 0.7622 - auc: 0.8401 - val_loss: 0.1734 - val_accuracy: 0.7627 - val_auc: 0.8314\n",
      "Epoch 7/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.7881 - auc: 0.8649\n",
      "Epoch 7: val_accuracy improved from 0.76270 to 0.78255, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1566 - accuracy: 0.7880 - auc: 0.8649 - val_loss: 0.1583 - val_accuracy: 0.7825 - val_auc: 0.8535\n",
      "Epoch 8/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1423 - accuracy: 0.8047 - auc: 0.8833\n",
      "Epoch 8: val_accuracy improved from 0.78255 to 0.79086, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1419 - accuracy: 0.8053 - auc: 0.8840 - val_loss: 0.1471 - val_accuracy: 0.7909 - val_auc: 0.8723\n",
      "Epoch 9/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.8187 - auc: 0.8977\n",
      "Epoch 9: val_accuracy improved from 0.79086 to 0.79778, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1312 - accuracy: 0.8185 - auc: 0.8977 - val_loss: 0.1380 - val_accuracy: 0.7978 - val_auc: 0.8881\n",
      "Epoch 10/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.8267 - auc: 0.9073\n",
      "Epoch 10: val_accuracy improved from 0.79778 to 0.80794, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.8271 - auc: 0.9078 - val_loss: 0.1325 - val_accuracy: 0.8079 - val_auc: 0.8962\n",
      "Epoch 11/15\n",
      "563/610 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.8330 - auc: 0.9154\n",
      "Epoch 11: val_accuracy improved from 0.80794 to 0.81440, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.8331 - auc: 0.9156 - val_loss: 0.1281 - val_accuracy: 0.8144 - val_auc: 0.9028\n",
      "Epoch 12/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1139 - accuracy: 0.8389 - auc: 0.9210\n",
      "Epoch 12: val_accuracy improved from 0.81440 to 0.81487, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1141 - accuracy: 0.8382 - auc: 0.9209 - val_loss: 0.1258 - val_accuracy: 0.8149 - val_auc: 0.9075\n",
      "Epoch 13/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1099 - accuracy: 0.8440 - auc: 0.9262\n",
      "Epoch 13: val_accuracy improved from 0.81487 to 0.81856, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.8418 - auc: 0.9249 - val_loss: 0.1226 - val_accuracy: 0.8186 - val_auc: 0.9118\n",
      "Epoch 14/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1082 - accuracy: 0.8439 - auc: 0.9285\n",
      "Epoch 14: val_accuracy improved from 0.81856 to 0.82225, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1083 - accuracy: 0.8436 - auc: 0.9283 - val_loss: 0.1209 - val_accuracy: 0.8223 - val_auc: 0.9140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.8485 - auc: 0.9310\n",
      "Epoch 15: val_accuracy improved from 0.82225 to 0.82318, saving model to \\saved_models2_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.8490 - auc: 0.9313 - val_loss: 0.1188 - val_accuracy: 0.8232 - val_auc: 0.9169\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.8232 - auc: 0.9169\n",
      "Epoch 1/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2494 - accuracy: 0.5320 - auc: 0.5451\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56140, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.5331 - auc: 0.5462 - val_loss: 0.2472 - val_accuracy: 0.5614 - val_auc: 0.5948\n",
      "Epoch 2/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2446 - accuracy: 0.5948 - auc: 0.6423\n",
      "Epoch 2: val_accuracy improved from 0.56140 to 0.60849, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.5949 - auc: 0.6422 - val_loss: 0.2431 - val_accuracy: 0.6085 - val_auc: 0.6649\n",
      "Epoch 3/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.6439 - auc: 0.6977\n",
      "Epoch 3: val_accuracy improved from 0.60849 to 0.66667, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2383 - accuracy: 0.6442 - auc: 0.6979 - val_loss: 0.2336 - val_accuracy: 0.6667 - val_auc: 0.7146\n",
      "Epoch 4/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.6795 - auc: 0.7410\n",
      "Epoch 4: val_accuracy improved from 0.66667 to 0.69437, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2243 - accuracy: 0.6802 - auc: 0.7413 - val_loss: 0.2148 - val_accuracy: 0.6944 - val_auc: 0.7606\n",
      "Epoch 5/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.2034 - accuracy: 0.7160 - auc: 0.7875\n",
      "Epoch 5: val_accuracy improved from 0.69437 to 0.72761, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2030 - accuracy: 0.7164 - auc: 0.7878 - val_loss: 0.1924 - val_accuracy: 0.7276 - val_auc: 0.8067\n",
      "Epoch 6/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.7534 - auc: 0.8318\n",
      "Epoch 6: val_accuracy improved from 0.72761 to 0.74977, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1791 - accuracy: 0.7541 - auc: 0.8326 - val_loss: 0.1717 - val_accuracy: 0.7498 - val_auc: 0.8428\n",
      "Epoch 7/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1576 - accuracy: 0.7848 - auc: 0.8646\n",
      "Epoch 7: val_accuracy improved from 0.74977 to 0.77562, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.7859 - auc: 0.8661 - val_loss: 0.1561 - val_accuracy: 0.7756 - val_auc: 0.8651\n",
      "Epoch 8/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.8033 - auc: 0.8871\n",
      "Epoch 8: val_accuracy improved from 0.77562 to 0.78763, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1403 - accuracy: 0.8036 - auc: 0.8874 - val_loss: 0.1447 - val_accuracy: 0.7876 - val_auc: 0.8802\n",
      "Epoch 9/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.8162 - auc: 0.9019\n",
      "Epoch 9: val_accuracy improved from 0.78763 to 0.79640, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1287 - accuracy: 0.8165 - auc: 0.9023 - val_loss: 0.1367 - val_accuracy: 0.7964 - val_auc: 0.8903\n",
      "Epoch 10/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.8267 - auc: 0.9121\n",
      "Epoch 10: val_accuracy improved from 0.79640 to 0.80563, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.8272 - auc: 0.9123 - val_loss: 0.1312 - val_accuracy: 0.8056 - val_auc: 0.8986\n",
      "Epoch 11/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.8347 - auc: 0.9196\n",
      "Epoch 11: val_accuracy improved from 0.80563 to 0.81117, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1151 - accuracy: 0.8347 - auc: 0.9195 - val_loss: 0.1265 - val_accuracy: 0.8112 - val_auc: 0.9060\n",
      "Epoch 12/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.8381 - auc: 0.9248\n",
      "Epoch 12: val_accuracy improved from 0.81117 to 0.81487, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1106 - accuracy: 0.8388 - auc: 0.9255 - val_loss: 0.1236 - val_accuracy: 0.8149 - val_auc: 0.9103\n",
      "Epoch 13/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.8463 - auc: 0.9294\n",
      "Epoch 13: val_accuracy improved from 0.81487 to 0.81810, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1070 - accuracy: 0.8469 - auc: 0.9300 - val_loss: 0.1207 - val_accuracy: 0.8181 - val_auc: 0.9140\n",
      "Epoch 14/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1034 - accuracy: 0.8520 - auc: 0.9343\n",
      "Epoch 14: val_accuracy improved from 0.81810 to 0.82179, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.8518 - auc: 0.9342 - val_loss: 0.1176 - val_accuracy: 0.8218 - val_auc: 0.9188\n",
      "Epoch 15/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.8556 - auc: 0.9379\n",
      "Epoch 15: val_accuracy improved from 0.82179 to 0.82641, saving model to \\saved_models2_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.8556 - auc: 0.9379 - val_loss: 0.1144 - val_accuracy: 0.8264 - val_auc: 0.9228\n",
      "68/68 [==============================] - 0s 999us/step - loss: 0.1144 - accuracy: 0.8264 - auc: 0.9228\n",
      "Epoch 1/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2490 - accuracy: 0.5317 - auc: 0.5335\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53740, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.5319 - auc: 0.5337 - val_loss: 0.2484 - val_accuracy: 0.5374 - val_auc: 0.5494\n",
      "Epoch 2/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.5376 - auc: 0.5760\n",
      "Epoch 2: val_accuracy improved from 0.53740 to 0.53786, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2477 - accuracy: 0.5381 - auc: 0.5771 - val_loss: 0.2473 - val_accuracy: 0.5379 - val_auc: 0.5961\n",
      "Epoch 3/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.2464 - accuracy: 0.5448 - auc: 0.6265\n",
      "Epoch 3: val_accuracy improved from 0.53786 to 0.56371, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2463 - accuracy: 0.5459 - auc: 0.6281 - val_loss: 0.2452 - val_accuracy: 0.5637 - val_auc: 0.6504\n",
      "Epoch 4/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.5878 - auc: 0.6878\n",
      "Epoch 4: val_accuracy improved from 0.56371 to 0.63296, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.5878 - auc: 0.6878 - val_loss: 0.2407 - val_accuracy: 0.6330 - val_auc: 0.7168\n",
      "Epoch 5/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.6705 - auc: 0.7458\n",
      "Epoch 5: val_accuracy improved from 0.63296 to 0.70083, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2359 - accuracy: 0.6711 - auc: 0.7463 - val_loss: 0.2284 - val_accuracy: 0.7008 - val_auc: 0.7743\n",
      "Epoch 6/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.7262 - auc: 0.7904\n",
      "Epoch 6: val_accuracy improved from 0.70083 to 0.74608, saving model to \\saved_models2_2/model_5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2161 - accuracy: 0.7263 - auc: 0.7905 - val_loss: 0.2006 - val_accuracy: 0.7461 - val_auc: 0.8139\n",
      "Epoch 7/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1886 - accuracy: 0.7566 - auc: 0.8241\n",
      "Epoch 7: val_accuracy improved from 0.74608 to 0.76962, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1878 - accuracy: 0.7578 - auc: 0.8244 - val_loss: 0.1761 - val_accuracy: 0.7696 - val_auc: 0.8397\n",
      "Epoch 8/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1674 - accuracy: 0.7808 - auc: 0.8490\n",
      "Epoch 8: val_accuracy improved from 0.76962 to 0.78670, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1664 - accuracy: 0.7827 - auc: 0.8509 - val_loss: 0.1582 - val_accuracy: 0.7867 - val_auc: 0.8620\n",
      "Epoch 9/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1509 - accuracy: 0.8000 - auc: 0.8728\n",
      "Epoch 9: val_accuracy improved from 0.78670 to 0.80194, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1510 - accuracy: 0.7999 - auc: 0.8726 - val_loss: 0.1456 - val_accuracy: 0.8019 - val_auc: 0.8834\n",
      "Epoch 10/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1390 - accuracy: 0.8140 - auc: 0.8896\n",
      "Epoch 10: val_accuracy improved from 0.80194 to 0.80979, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1389 - accuracy: 0.8142 - auc: 0.8897 - val_loss: 0.1352 - val_accuracy: 0.8098 - val_auc: 0.8983\n",
      "Epoch 11/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.8240 - auc: 0.9019\n",
      "Epoch 11: val_accuracy improved from 0.80979 to 0.82041, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1296 - accuracy: 0.8238 - auc: 0.9020 - val_loss: 0.1257 - val_accuracy: 0.8204 - val_auc: 0.9114\n",
      "Epoch 12/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1223 - accuracy: 0.8314 - auc: 0.9115\n",
      "Epoch 12: val_accuracy improved from 0.82041 to 0.83056, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.8320 - auc: 0.9112 - val_loss: 0.1187 - val_accuracy: 0.8306 - val_auc: 0.9195\n",
      "Epoch 13/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1166 - accuracy: 0.8380 - auc: 0.9189\n",
      "Epoch 13: val_accuracy improved from 0.83056 to 0.84118, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1166 - accuracy: 0.8379 - auc: 0.9186 - val_loss: 0.1125 - val_accuracy: 0.8412 - val_auc: 0.9264\n",
      "Epoch 14/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1118 - accuracy: 0.8444 - auc: 0.9245\n",
      "Epoch 14: val_accuracy improved from 0.84118 to 0.84949, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.8438 - auc: 0.9241 - val_loss: 0.1083 - val_accuracy: 0.8495 - val_auc: 0.9318\n",
      "Epoch 15/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1084 - accuracy: 0.8491 - auc: 0.9286\n",
      "Epoch 15: val_accuracy improved from 0.84949 to 0.85042, saving model to \\saved_models2_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.8493 - auc: 0.9284 - val_loss: 0.1056 - val_accuracy: 0.8504 - val_auc: 0.9349\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.8504 - auc: 0.9349\n",
      "Epoch 1/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.2479 - accuracy: 0.5335 - auc: 0.5485\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52770, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.5362 - auc: 0.5529 - val_loss: 0.2460 - val_accuracy: 0.5277 - val_auc: 0.6151\n",
      "Epoch 2/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.5387 - auc: 0.6491\n",
      "Epoch 2: val_accuracy improved from 0.52770 to 0.55078, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2431 - accuracy: 0.5384 - auc: 0.6489 - val_loss: 0.2401 - val_accuracy: 0.5508 - val_auc: 0.6937\n",
      "Epoch 3/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.5811 - auc: 0.7152\n",
      "Epoch 3: val_accuracy improved from 0.55078 to 0.63019, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2334 - accuracy: 0.5822 - auc: 0.7154 - val_loss: 0.2265 - val_accuracy: 0.6302 - val_auc: 0.7422\n",
      "Epoch 4/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.6851 - auc: 0.7637\n",
      "Epoch 4: val_accuracy improved from 0.63019 to 0.72622, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2154 - accuracy: 0.6850 - auc: 0.7637 - val_loss: 0.2062 - val_accuracy: 0.7262 - val_auc: 0.7865\n",
      "Epoch 5/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1939 - accuracy: 0.7375 - auc: 0.8105\n",
      "Epoch 5: val_accuracy improved from 0.72622 to 0.75069, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1934 - accuracy: 0.7382 - auc: 0.8116 - val_loss: 0.1826 - val_accuracy: 0.7507 - val_auc: 0.8337\n",
      "Epoch 6/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.7728 - auc: 0.8553\n",
      "Epoch 6: val_accuracy improved from 0.75069 to 0.78393, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1703 - accuracy: 0.7734 - auc: 0.8557 - val_loss: 0.1615 - val_accuracy: 0.7839 - val_auc: 0.8673\n",
      "Epoch 7/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.7992 - auc: 0.8818\n",
      "Epoch 7: val_accuracy improved from 0.78393 to 0.80609, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1517 - accuracy: 0.7991 - auc: 0.8818 - val_loss: 0.1466 - val_accuracy: 0.8061 - val_auc: 0.8882\n",
      "Epoch 8/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.8117 - auc: 0.8977\n",
      "Epoch 8: val_accuracy improved from 0.80609 to 0.81071, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1389 - accuracy: 0.8117 - auc: 0.8977 - val_loss: 0.1364 - val_accuracy: 0.8107 - val_auc: 0.8989\n",
      "Epoch 9/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.8217 - auc: 0.9083\n",
      "Epoch 9: val_accuracy improved from 0.81071 to 0.81994, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.8218 - auc: 0.9083 - val_loss: 0.1293 - val_accuracy: 0.8199 - val_auc: 0.9073\n",
      "Epoch 10/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 0.8314 - auc: 0.9158\n",
      "Epoch 10: val_accuracy improved from 0.81994 to 0.83241, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1229 - accuracy: 0.8311 - auc: 0.9156 - val_loss: 0.1241 - val_accuracy: 0.8324 - val_auc: 0.9129\n",
      "Epoch 11/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1175 - accuracy: 0.8390 - auc: 0.9211\n",
      "Epoch 11: val_accuracy improved from 0.83241 to 0.83518, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.8384 - auc: 0.9209 - val_loss: 0.1200 - val_accuracy: 0.8352 - val_auc: 0.9178\n",
      "Epoch 12/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1139 - accuracy: 0.8433 - auc: 0.9251\n",
      "Epoch 12: val_accuracy improved from 0.83518 to 0.83703, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.8444 - auc: 0.9259 - val_loss: 0.1166 - val_accuracy: 0.8370 - val_auc: 0.9214\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1096 - accuracy: 0.8480 - auc: 0.9298\n",
      "Epoch 13: val_accuracy improved from 0.83703 to 0.84072, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.8481 - auc: 0.9296 - val_loss: 0.1135 - val_accuracy: 0.8407 - val_auc: 0.9249\n",
      "Epoch 14/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.8529 - auc: 0.9335\n",
      "Epoch 14: val_accuracy improved from 0.84072 to 0.84257, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1065 - accuracy: 0.8529 - auc: 0.9334 - val_loss: 0.1117 - val_accuracy: 0.8426 - val_auc: 0.9277\n",
      "Epoch 15/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1035 - accuracy: 0.8561 - auc: 0.9367\n",
      "Epoch 15: val_accuracy improved from 0.84257 to 0.84441, saving model to \\saved_models2_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1033 - accuracy: 0.8566 - auc: 0.9368 - val_loss: 0.1083 - val_accuracy: 0.8444 - val_auc: 0.9305\n",
      "68/68 [==============================] - 0s 979us/step - loss: 0.1083 - accuracy: 0.8444 - auc: 0.9305\n",
      "Epoch 1/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.2490 - accuracy: 0.5247 - auc: 0.5322\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56325, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.5266 - auc: 0.5362 - val_loss: 0.2466 - val_accuracy: 0.5633 - val_auc: 0.5897\n",
      "Epoch 2/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.5495 - auc: 0.6202\n",
      "Epoch 2: val_accuracy did not improve from 0.56325\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.5497 - auc: 0.6210 - val_loss: 0.2442 - val_accuracy: 0.5623 - val_auc: 0.6471\n",
      "Epoch 3/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.5677 - auc: 0.6726\n",
      "Epoch 3: val_accuracy improved from 0.56325 to 0.58957, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.5677 - auc: 0.6726 - val_loss: 0.2402 - val_accuracy: 0.5896 - val_auc: 0.6902\n",
      "Epoch 4/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.2370 - accuracy: 0.6157 - auc: 0.7112\n",
      "Epoch 4: val_accuracy improved from 0.58957 to 0.65097, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2364 - accuracy: 0.6184 - auc: 0.7138 - val_loss: 0.2302 - val_accuracy: 0.6510 - val_auc: 0.7301\n",
      "Epoch 5/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.2206 - accuracy: 0.6792 - auc: 0.7507\n",
      "Epoch 5: val_accuracy improved from 0.65097 to 0.70729, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2198 - accuracy: 0.6806 - auc: 0.7525 - val_loss: 0.2061 - val_accuracy: 0.7073 - val_auc: 0.7717\n",
      "Epoch 6/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1892 - accuracy: 0.7286 - auc: 0.8009\n",
      "Epoch 6: val_accuracy improved from 0.70729 to 0.75069, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1889 - accuracy: 0.7285 - auc: 0.8016 - val_loss: 0.1745 - val_accuracy: 0.7507 - val_auc: 0.8232\n",
      "Epoch 7/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1599 - accuracy: 0.7680 - auc: 0.8491\n",
      "Epoch 7: val_accuracy improved from 0.75069 to 0.78163, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1596 - accuracy: 0.7687 - auc: 0.8496 - val_loss: 0.1502 - val_accuracy: 0.7816 - val_auc: 0.8641\n",
      "Epoch 8/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1404 - accuracy: 0.7982 - auc: 0.8807\n",
      "Epoch 8: val_accuracy improved from 0.78163 to 0.80471, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1398 - accuracy: 0.7989 - auc: 0.8817 - val_loss: 0.1347 - val_accuracy: 0.8047 - val_auc: 0.8894\n",
      "Epoch 9/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.8184 - auc: 0.9028\n",
      "Epoch 9: val_accuracy improved from 0.80471 to 0.81902, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1262 - accuracy: 0.8183 - auc: 0.9028 - val_loss: 0.1254 - val_accuracy: 0.8190 - val_auc: 0.9035\n",
      "Epoch 10/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.8305 - auc: 0.9160\n",
      "Epoch 10: val_accuracy improved from 0.81902 to 0.82087, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.8305 - auc: 0.9162 - val_loss: 0.1198 - val_accuracy: 0.8209 - val_auc: 0.9126\n",
      "Epoch 11/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.8412 - auc: 0.9252\n",
      "Epoch 11: val_accuracy improved from 0.82087 to 0.83657, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1103 - accuracy: 0.8415 - auc: 0.9254 - val_loss: 0.1138 - val_accuracy: 0.8366 - val_auc: 0.9203\n",
      "Epoch 12/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1054 - accuracy: 0.8487 - auc: 0.9316\n",
      "Epoch 12: val_accuracy improved from 0.83657 to 0.84257, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.8490 - auc: 0.9325 - val_loss: 0.1125 - val_accuracy: 0.8426 - val_auc: 0.9250\n",
      "Epoch 13/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.8580 - auc: 0.9388\n",
      "Epoch 13: val_accuracy improved from 0.84257 to 0.84580, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.8580 - auc: 0.9388 - val_loss: 0.1048 - val_accuracy: 0.8458 - val_auc: 0.9320\n",
      "Epoch 14/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.0951 - accuracy: 0.8649 - auc: 0.9439\n",
      "Epoch 14: val_accuracy improved from 0.84580 to 0.84949, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.8656 - auc: 0.9442 - val_loss: 0.1039 - val_accuracy: 0.8495 - val_auc: 0.9367\n",
      "Epoch 15/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.0899 - accuracy: 0.8740 - auc: 0.9497\n",
      "Epoch 15: val_accuracy improved from 0.84949 to 0.85780, saving model to \\saved_models2_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0899 - accuracy: 0.8744 - auc: 0.9495 - val_loss: 0.0967 - val_accuracy: 0.8578 - val_auc: 0.9418\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.8578 - auc: 0.9418\n",
      "Epoch 1/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.5516 - auc: 0.5619\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57018, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.5520 - auc: 0.5625 - val_loss: 0.2468 - val_accuracy: 0.5702 - val_auc: 0.6204\n",
      "Epoch 2/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.5780 - auc: 0.6438\n",
      "Epoch 2: val_accuracy improved from 0.57018 to 0.62142, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2449 - accuracy: 0.5790 - auc: 0.6445 - val_loss: 0.2424 - val_accuracy: 0.6214 - val_auc: 0.6911\n",
      "Epoch 3/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.2391 - accuracy: 0.6365 - auc: 0.6962\n",
      "Epoch 3: val_accuracy improved from 0.62142 to 0.67867, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2387 - accuracy: 0.6392 - auc: 0.6974 - val_loss: 0.2317 - val_accuracy: 0.6787 - val_auc: 0.7340\n",
      "Epoch 4/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2238 - accuracy: 0.6800 - auc: 0.7361\n",
      "Epoch 4: val_accuracy improved from 0.67867 to 0.70822, saving model to \\saved_models2_2/model_8.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2236 - accuracy: 0.6803 - auc: 0.7367 - val_loss: 0.2095 - val_accuracy: 0.7082 - val_auc: 0.7685\n",
      "Epoch 5/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2007 - accuracy: 0.7116 - auc: 0.7775\n",
      "Epoch 5: val_accuracy improved from 0.70822 to 0.73638, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2004 - accuracy: 0.7121 - auc: 0.7784 - val_loss: 0.1856 - val_accuracy: 0.7364 - val_auc: 0.8054\n",
      "Epoch 6/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.7489 - auc: 0.8222\n",
      "Epoch 6: val_accuracy improved from 0.73638 to 0.76731, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1765 - accuracy: 0.7492 - auc: 0.8226 - val_loss: 0.1645 - val_accuracy: 0.7673 - val_auc: 0.8440\n",
      "Epoch 7/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1566 - accuracy: 0.7780 - auc: 0.8566\n",
      "Epoch 7: val_accuracy improved from 0.76731 to 0.78855, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1552 - accuracy: 0.7808 - auc: 0.8595 - val_loss: 0.1467 - val_accuracy: 0.7886 - val_auc: 0.8731\n",
      "Epoch 8/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.8021 - auc: 0.8851\n",
      "Epoch 8: val_accuracy improved from 0.78855 to 0.80979, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1390 - accuracy: 0.8019 - auc: 0.8850 - val_loss: 0.1342 - val_accuracy: 0.8098 - val_auc: 0.8935\n",
      "Epoch 9/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1290 - accuracy: 0.8152 - auc: 0.8996\n",
      "Epoch 9: val_accuracy improved from 0.80979 to 0.82687, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1281 - accuracy: 0.8166 - auc: 0.9011 - val_loss: 0.1247 - val_accuracy: 0.8269 - val_auc: 0.9065\n",
      "Epoch 10/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.8270 - auc: 0.9126\n",
      "Epoch 10: val_accuracy improved from 0.82687 to 0.83333, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1202 - accuracy: 0.8269 - auc: 0.9125 - val_loss: 0.1175 - val_accuracy: 0.8333 - val_auc: 0.9170\n",
      "Epoch 11/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1149 - accuracy: 0.8349 - auc: 0.9198\n",
      "Epoch 11: val_accuracy improved from 0.83333 to 0.83795, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.8352 - auc: 0.9202 - val_loss: 0.1127 - val_accuracy: 0.8380 - val_auc: 0.9234\n",
      "Epoch 12/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.8415 - auc: 0.9260\n",
      "Epoch 12: val_accuracy improved from 0.83795 to 0.84211, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.8416 - auc: 0.9259 - val_loss: 0.1099 - val_accuracy: 0.8421 - val_auc: 0.9286\n",
      "Epoch 13/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1076 - accuracy: 0.8462 - auc: 0.9295\n",
      "Epoch 13: val_accuracy did not improve from 0.84211\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.8477 - auc: 0.9306 - val_loss: 0.1072 - val_accuracy: 0.8412 - val_auc: 0.9340\n",
      "Epoch 14/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.8530 - auc: 0.9349\n",
      "Epoch 14: val_accuracy improved from 0.84211 to 0.85042, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.8531 - auc: 0.9350 - val_loss: 0.1009 - val_accuracy: 0.8504 - val_auc: 0.9390\n",
      "Epoch 15/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.8605 - auc: 0.9392\n",
      "Epoch 15: val_accuracy improved from 0.85042 to 0.85457, saving model to \\saved_models2_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0997 - accuracy: 0.8599 - auc: 0.9390 - val_loss: 0.0983 - val_accuracy: 0.8546 - val_auc: 0.9422\n",
      "68/68 [==============================] - 0s 978us/step - loss: 0.0983 - accuracy: 0.8546 - auc: 0.9422\n",
      "Epoch 1/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.2446 - accuracy: 0.5370 - auc: 0.6105\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56259, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.5367 - auc: 0.6153 - val_loss: 0.2376 - val_accuracy: 0.5626 - val_auc: 0.6947\n",
      "Epoch 2/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.2337 - accuracy: 0.5959 - auc: 0.7189\n",
      "Epoch 2: val_accuracy improved from 0.56259 to 0.67390, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2333 - accuracy: 0.6003 - auc: 0.7205 - val_loss: 0.2224 - val_accuracy: 0.6739 - val_auc: 0.7584\n",
      "Epoch 3/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.6972 - auc: 0.7723\n",
      "Epoch 3: val_accuracy improved from 0.67390 to 0.73811, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2153 - accuracy: 0.6973 - auc: 0.7720 - val_loss: 0.2001 - val_accuracy: 0.7381 - val_auc: 0.8024\n",
      "Epoch 4/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.7403 - auc: 0.8158\n",
      "Epoch 4: val_accuracy improved from 0.73811 to 0.76952, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.7404 - auc: 0.8161 - val_loss: 0.1761 - val_accuracy: 0.7695 - val_auc: 0.8398\n",
      "Epoch 5/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1686 - accuracy: 0.7735 - auc: 0.8522\n",
      "Epoch 5: val_accuracy improved from 0.76952 to 0.78753, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1676 - accuracy: 0.7751 - auc: 0.8531 - val_loss: 0.1558 - val_accuracy: 0.7875 - val_auc: 0.8669\n",
      "Epoch 6/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.7952 - auc: 0.8784\n",
      "Epoch 6: val_accuracy improved from 0.78753 to 0.80554, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1477 - accuracy: 0.7952 - auc: 0.8784 - val_loss: 0.1403 - val_accuracy: 0.8055 - val_auc: 0.8850\n",
      "Epoch 7/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.8106 - auc: 0.8961\n",
      "Epoch 7: val_accuracy improved from 0.80554 to 0.81247, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1335 - accuracy: 0.8105 - auc: 0.8961 - val_loss: 0.1299 - val_accuracy: 0.8125 - val_auc: 0.8984\n",
      "Epoch 8/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 0.8200 - auc: 0.9070\n",
      "Epoch 8: val_accuracy improved from 0.81247 to 0.82217, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1245 - accuracy: 0.8205 - auc: 0.9076 - val_loss: 0.1233 - val_accuracy: 0.8222 - val_auc: 0.9075\n",
      "Epoch 9/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.8272 - auc: 0.9150\n",
      "Epoch 9: val_accuracy improved from 0.82217 to 0.82587, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.8272 - auc: 0.9149 - val_loss: 0.1192 - val_accuracy: 0.8259 - val_auc: 0.9134\n",
      "Epoch 10/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1148 - accuracy: 0.8334 - auc: 0.9199\n",
      "Epoch 10: val_accuracy improved from 0.82587 to 0.83048, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.8333 - auc: 0.9199 - val_loss: 0.1159 - val_accuracy: 0.8305 - val_auc: 0.9183\n",
      "Epoch 11/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.8384 - auc: 0.9236\n",
      "Epoch 11: val_accuracy did not improve from 0.83048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1119 - accuracy: 0.8383 - auc: 0.9236 - val_loss: 0.1133 - val_accuracy: 0.8300 - val_auc: 0.9213\n",
      "Epoch 12/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1091 - accuracy: 0.8431 - auc: 0.9271\n",
      "Epoch 12: val_accuracy improved from 0.83048 to 0.83510, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.8427 - auc: 0.9264 - val_loss: 0.1114 - val_accuracy: 0.8351 - val_auc: 0.9251\n",
      "Epoch 13/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1077 - accuracy: 0.8447 - auc: 0.9288\n",
      "Epoch 13: val_accuracy improved from 0.83510 to 0.83695, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.8449 - auc: 0.9291 - val_loss: 0.1090 - val_accuracy: 0.8370 - val_auc: 0.9275\n",
      "Epoch 14/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1053 - accuracy: 0.8483 - auc: 0.9317\n",
      "Epoch 14: val_accuracy improved from 0.83695 to 0.83788, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.8479 - auc: 0.9316 - val_loss: 0.1076 - val_accuracy: 0.8379 - val_auc: 0.9294\n",
      "Epoch 15/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1028 - accuracy: 0.8528 - auc: 0.9346\n",
      "Epoch 15: val_accuracy improved from 0.83788 to 0.83880, saving model to \\saved_models2_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.8507 - auc: 0.9337 - val_loss: 0.1054 - val_accuracy: 0.8388 - val_auc: 0.9324\n",
      "68/68 [==============================] - 0s 995us/step - loss: 0.1054 - accuracy: 0.8388 - auc: 0.9324\n",
      "Epoch 1/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2487 - accuracy: 0.5347 - auc: 0.5364\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54827, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.5347 - auc: 0.5378 - val_loss: 0.2471 - val_accuracy: 0.5483 - val_auc: 0.5850\n",
      "Epoch 2/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2471 - accuracy: 0.5342 - auc: 0.5959\n",
      "Epoch 2: val_accuracy did not improve from 0.54827\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2471 - accuracy: 0.5338 - auc: 0.5966 - val_loss: 0.2455 - val_accuracy: 0.5473 - val_auc: 0.6327\n",
      "Epoch 3/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.5383 - auc: 0.6444\n",
      "Epoch 3: val_accuracy improved from 0.54827 to 0.55566, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.5383 - auc: 0.6444 - val_loss: 0.2431 - val_accuracy: 0.5557 - val_auc: 0.6757\n",
      "Epoch 4/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.5654 - auc: 0.6886\n",
      "Epoch 4: val_accuracy improved from 0.55566 to 0.60970, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2423 - accuracy: 0.5667 - auc: 0.6873 - val_loss: 0.2388 - val_accuracy: 0.6097 - val_auc: 0.7202\n",
      "Epoch 5/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.6294 - auc: 0.7244\n",
      "Epoch 5: val_accuracy improved from 0.60970 to 0.67621, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2366 - accuracy: 0.6304 - auc: 0.7246 - val_loss: 0.2300 - val_accuracy: 0.6762 - val_auc: 0.7590\n",
      "Epoch 6/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.6883 - auc: 0.7599\n",
      "Epoch 6: val_accuracy improved from 0.67621 to 0.72240, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2222 - accuracy: 0.6883 - auc: 0.7599 - val_loss: 0.2064 - val_accuracy: 0.7224 - val_auc: 0.7961\n",
      "Epoch 7/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.7296 - auc: 0.8024\n",
      "Epoch 7: val_accuracy improved from 0.72240 to 0.76536, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1905 - accuracy: 0.7296 - auc: 0.8026 - val_loss: 0.1688 - val_accuracy: 0.7654 - val_auc: 0.8418\n",
      "Epoch 8/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.7681 - auc: 0.8504\n",
      "Epoch 8: val_accuracy improved from 0.76536 to 0.79538, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1596 - accuracy: 0.7683 - auc: 0.8504 - val_loss: 0.1444 - val_accuracy: 0.7954 - val_auc: 0.8772\n",
      "Epoch 9/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1411 - accuracy: 0.7968 - auc: 0.8802\n",
      "Epoch 9: val_accuracy improved from 0.79538 to 0.81386, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1411 - accuracy: 0.7965 - auc: 0.8802 - val_loss: 0.1299 - val_accuracy: 0.8139 - val_auc: 0.8991\n",
      "Epoch 10/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1297 - accuracy: 0.8112 - auc: 0.8982\n",
      "Epoch 10: val_accuracy improved from 0.81386 to 0.82540, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1299 - accuracy: 0.8108 - auc: 0.8977 - val_loss: 0.1219 - val_accuracy: 0.8254 - val_auc: 0.9109\n",
      "Epoch 11/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1221 - accuracy: 0.8244 - auc: 0.9093\n",
      "Epoch 11: val_accuracy improved from 0.82540 to 0.83233, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1221 - accuracy: 0.8246 - auc: 0.9093 - val_loss: 0.1167 - val_accuracy: 0.8323 - val_auc: 0.9177\n",
      "Epoch 12/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1168 - accuracy: 0.8321 - auc: 0.9166\n",
      "Epoch 12: val_accuracy improved from 0.83233 to 0.83880, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.8324 - auc: 0.9170 - val_loss: 0.1116 - val_accuracy: 0.8388 - val_auc: 0.9246\n",
      "Epoch 13/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.8401 - auc: 0.9232\n",
      "Epoch 13: val_accuracy improved from 0.83880 to 0.83926, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.8400 - auc: 0.9232 - val_loss: 0.1086 - val_accuracy: 0.8393 - val_auc: 0.9286\n",
      "Epoch 14/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1087 - accuracy: 0.8447 - auc: 0.9277\n",
      "Epoch 14: val_accuracy improved from 0.83926 to 0.84342, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1084 - accuracy: 0.8451 - auc: 0.9279 - val_loss: 0.1064 - val_accuracy: 0.8434 - val_auc: 0.9327\n",
      "Epoch 15/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1051 - accuracy: 0.8489 - auc: 0.9320\n",
      "Epoch 15: val_accuracy improved from 0.84342 to 0.85312, saving model to \\saved_models2_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1050 - accuracy: 0.8494 - auc: 0.9322 - val_loss: 0.1023 - val_accuracy: 0.8531 - val_auc: 0.9366\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.8531 - auc: 0.9366\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY22 = []\n",
    "VALIDATION_AUC22 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names2].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names2].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names2):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep4')(deep_branch) \n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep5')(deep_branch) # added this!\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model22 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model22.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models2_2/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history22 = model22.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model22.load_weights(\"\\saved_models2_2/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model22.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model22.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY22.append(results['accuracy'])\n",
    "    VALIDATION_AUC22.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history22.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history22.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history22.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history22.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8079409003257751 | 0.8942816257476807 |\n",
      "|  2   | 0.8684210777282715 | 0.9464473128318787 |\n",
      "|  3   | 0.823176383972168  | 0.916935384273529  |\n",
      "|  4   | 0.8264081478118896 | 0.9227609038352966 |\n",
      "|  5   | 0.8504155278205872 | 0.9348542094230652 |\n",
      "|  6   | 0.8444136381149292 | 0.9305239915847778 |\n",
      "|  7   | 0.8578023910522461 | 0.9417527914047241 |\n",
      "|  8   | 0.8545706272125244 | 0.9422078132629395 |\n",
      "|  9   | 0.8387990593910217 | 0.9323523640632629 |\n",
      "|  10  | 0.8531177639961243 | 0.9365938305854797 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY22)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC22)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 2\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY22.index(max(VALIDATION_ACCURACY22))\n",
    "max_fold22 = idx + 1\n",
    "print(\"Best Fold:\", max_fold22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 967us/step - loss: 0.1367 - accuracy: 0.8031 - auc: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13673126697540283, 0.8030573129653931, 0.8909838199615479]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model22.load_weights(\"\\saved_models2_2/model_\"+str(max_fold22)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model22.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 811us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model22.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat22 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Generalization Performance for W/D 2 - McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd2 = pd.DataFrame()\n",
    "wd2['Deep'] = list(chain.from_iterable(yhat2))\n",
    "wd2['Deeper'] = list(chain.from_iterable(yhat21))\n",
    "wd2['Deepest'] = list(chain.from_iterable(yhat22))\n",
    "wd2['Truth'] = list(chain.from_iterable(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    4968\n",
       "D     958\n",
       "B     428\n",
       "C     384\n",
       "Name: Matrix1v2, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd2['Deep'] == wd2['Truth']) & (wd2['Deeper'] == wd2['Truth']), # both models are right (A)\n",
    "    (wd2['Deep'] == wd2['Truth']) & (wd2['Deeper'] != wd2['Truth']), # model 1 is right, model 2 is wrong (B)\n",
    "    (wd2['Deep'] != wd2['Truth']) & (wd2['Deeper'] == wd2['Truth']), # model 1 is wrong, model 2 is right (C)\n",
    "    (wd2['Deep'] != wd2['Truth']) & (wd2['Deeper'] != wd2['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd2['Matrix1v2'] = np.select(conditions, choices, default = '0')\n",
    "wd2.Matrix1v2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.277\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd2['Matrix1v2'] == 'B')\n",
    "C = sum(wd2['Matrix1v2'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2.277 < 3.841 ($\\alpha$ = 0.05 significance level), we fail to reject the null hypothesis that the models are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5002\n",
       "D     933\n",
       "C     409\n",
       "B     394\n",
       "Name: Matrix1v3, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd2['Deep'] == wd2['Truth']) & (wd2['Deepest'] == wd2['Truth']), # both models are right (A)\n",
    "    (wd2['Deep'] == wd2['Truth']) & (wd2['Deepest'] != wd2['Truth']), # model 1 is right, model 2 is wrong (B)\n",
    "    (wd2['Deep'] != wd2['Truth']) & (wd2['Deepest'] == wd2['Truth']), # model 1 is wrong, model 2 is right (C)\n",
    "    (wd2['Deep'] != wd2['Truth']) & (wd2['Deepest'] != wd2['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd2['Matrix1v3'] = np.select(conditions, choices, default = '0')\n",
    "wd2.Matrix1v3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.244\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd2['Matrix1v3'] == 'B')\n",
    "C = sum(wd2['Matrix1v3'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 0.244 < 3.841 ($\\alpha$ = 0.05 significance level), we fail to reject the null hypothesis that the models are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 3 - More Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.5707 - auc: 0.6008\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62465, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.5726 - auc: 0.6038 - val_loss: 0.2394 - val_accuracy: 0.6247 - val_auc: 0.6922\n",
      "Epoch 2/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.2334 - accuracy: 0.6441 - auc: 0.7326\n",
      "Epoch 2: val_accuracy improved from 0.62465 to 0.68560, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2330 - accuracy: 0.6461 - auc: 0.7327 - val_loss: 0.2232 - val_accuracy: 0.6856 - val_auc: 0.7720\n",
      "Epoch 3/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.2132 - accuracy: 0.7028 - auc: 0.7842\n",
      "Epoch 3: val_accuracy improved from 0.68560 to 0.73084, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2125 - accuracy: 0.7034 - auc: 0.7852 - val_loss: 0.1976 - val_accuracy: 0.7308 - val_auc: 0.8142\n",
      "Epoch 4/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1845 - accuracy: 0.7476 - auc: 0.8294\n",
      "Epoch 4: val_accuracy improved from 0.73084 to 0.77516, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.7482 - auc: 0.8299 - val_loss: 0.1677 - val_accuracy: 0.7752 - val_auc: 0.8543\n",
      "Epoch 5/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1573 - accuracy: 0.7875 - auc: 0.8678\n",
      "Epoch 5: val_accuracy improved from 0.77516 to 0.80332, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1561 - accuracy: 0.7893 - auc: 0.8698 - val_loss: 0.1448 - val_accuracy: 0.8033 - val_auc: 0.8831\n",
      "Epoch 6/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.8131 - auc: 0.8936\n",
      "Epoch 6: val_accuracy improved from 0.80332 to 0.82456, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1368 - accuracy: 0.8130 - auc: 0.8937 - val_loss: 0.1318 - val_accuracy: 0.8246 - val_auc: 0.8978\n",
      "Epoch 7/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.8251 - auc: 0.9057\n",
      "Epoch 7: val_accuracy improved from 0.82456 to 0.82641, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.8253 - auc: 0.9056 - val_loss: 0.1250 - val_accuracy: 0.8264 - val_auc: 0.9062\n",
      "Epoch 8/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.8317 - auc: 0.9127\n",
      "Epoch 8: val_accuracy improved from 0.82641 to 0.83287, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.8317 - auc: 0.9126 - val_loss: 0.1197 - val_accuracy: 0.8329 - val_auc: 0.9130\n",
      "Epoch 9/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1168 - accuracy: 0.8358 - auc: 0.9170\n",
      "Epoch 9: val_accuracy improved from 0.83287 to 0.83380, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.8362 - auc: 0.9173 - val_loss: 0.1173 - val_accuracy: 0.8338 - val_auc: 0.9167\n",
      "Epoch 10/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.8404 - auc: 0.9207\n",
      "Epoch 10: val_accuracy improved from 0.83380 to 0.83610, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.8405 - auc: 0.9207 - val_loss: 0.1148 - val_accuracy: 0.8361 - val_auc: 0.9198\n",
      "Epoch 11/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.8433 - auc: 0.9233\n",
      "Epoch 11: val_accuracy improved from 0.83610 to 0.83795, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.8431 - auc: 0.9233 - val_loss: 0.1132 - val_accuracy: 0.8380 - val_auc: 0.9226\n",
      "Epoch 12/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.8453 - auc: 0.9254\n",
      "Epoch 12: val_accuracy improved from 0.83795 to 0.84303, saving model to \\saved_models3_1/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1101 - accuracy: 0.8453 - auc: 0.9254 - val_loss: 0.1111 - val_accuracy: 0.8430 - val_auc: 0.9252\n",
      "Epoch 13/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1083 - accuracy: 0.8481 - auc: 0.9278\n",
      "Epoch 13: val_accuracy did not improve from 0.84303\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1087 - accuracy: 0.8473 - auc: 0.9273 - val_loss: 0.1101 - val_accuracy: 0.8412 - val_auc: 0.9271\n",
      "Epoch 14/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.8486 - auc: 0.9290\n",
      "Epoch 14: val_accuracy did not improve from 0.84303\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.8486 - auc: 0.9290 - val_loss: 0.1093 - val_accuracy: 0.8426 - val_auc: 0.9285\n",
      "Epoch 15/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1062 - accuracy: 0.8501 - auc: 0.9307\n",
      "Epoch 15: val_accuracy did not improve from 0.84303\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.8501 - auc: 0.9305 - val_loss: 0.1080 - val_accuracy: 0.8430 - val_auc: 0.9301\n",
      "68/68 [==============================] - 0s 970us/step - loss: 0.1111 - accuracy: 0.8430 - auc: 0.9252\n",
      "Epoch 1/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.5411 - auc: 0.5574\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55540, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.5415 - auc: 0.5582 - val_loss: 0.2456 - val_accuracy: 0.5554 - val_auc: 0.6668\n",
      "Epoch 2/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2405 - accuracy: 0.5827 - auc: 0.7179\n",
      "Epoch 2: val_accuracy improved from 0.55540 to 0.62281, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2405 - accuracy: 0.5829 - auc: 0.7181 - val_loss: 0.2364 - val_accuracy: 0.6228 - val_auc: 0.7650\n",
      "Epoch 3/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2226 - accuracy: 0.6885 - auc: 0.7773\n",
      "Epoch 3: val_accuracy improved from 0.62281 to 0.70499, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2223 - accuracy: 0.6895 - auc: 0.7778 - val_loss: 0.2049 - val_accuracy: 0.7050 - val_auc: 0.8044\n",
      "Epoch 4/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1834 - accuracy: 0.7473 - auc: 0.8210\n",
      "Epoch 4: val_accuracy improved from 0.70499 to 0.76362, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1825 - accuracy: 0.7482 - auc: 0.8215 - val_loss: 0.1642 - val_accuracy: 0.7636 - val_auc: 0.8516\n",
      "Epoch 5/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1530 - accuracy: 0.7821 - auc: 0.8626\n",
      "Epoch 5: val_accuracy improved from 0.76362 to 0.79778, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1530 - accuracy: 0.7815 - auc: 0.8621 - val_loss: 0.1402 - val_accuracy: 0.7978 - val_auc: 0.8855\n",
      "Epoch 6/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1382 - accuracy: 0.7998 - auc: 0.8847\n",
      "Epoch 6: val_accuracy improved from 0.79778 to 0.81671, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.8004 - auc: 0.8858 - val_loss: 0.1275 - val_accuracy: 0.8167 - val_auc: 0.9037\n",
      "Epoch 7/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.8138 - auc: 0.8992\n",
      "Epoch 7: val_accuracy improved from 0.81671 to 0.82502, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1286 - accuracy: 0.8139 - auc: 0.8995 - val_loss: 0.1201 - val_accuracy: 0.8250 - val_auc: 0.9140\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1223 - accuracy: 0.8236 - auc: 0.9088\n",
      "Epoch 8: val_accuracy improved from 0.82502 to 0.83149, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.8236 - auc: 0.9086 - val_loss: 0.1164 - val_accuracy: 0.8315 - val_auc: 0.9203\n",
      "Epoch 9/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.8298 - auc: 0.9145\n",
      "Epoch 9: val_accuracy improved from 0.83149 to 0.83934, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.8299 - auc: 0.9149 - val_loss: 0.1107 - val_accuracy: 0.8393 - val_auc: 0.9260\n",
      "Epoch 10/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.8345 - auc: 0.9195\n",
      "Epoch 10: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.8348 - auc: 0.9196 - val_loss: 0.1095 - val_accuracy: 0.8380 - val_auc: 0.9290\n",
      "Epoch 11/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.8413 - auc: 0.9233\n",
      "Epoch 11: val_accuracy improved from 0.83934 to 0.84534, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8413 - auc: 0.9233 - val_loss: 0.1058 - val_accuracy: 0.8453 - val_auc: 0.9319\n",
      "Epoch 12/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.8451 - auc: 0.9266\n",
      "Epoch 12: val_accuracy improved from 0.84534 to 0.84718, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.8448 - auc: 0.9265 - val_loss: 0.1048 - val_accuracy: 0.8472 - val_auc: 0.9337\n",
      "Epoch 13/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.8479 - auc: 0.9287\n",
      "Epoch 13: val_accuracy did not improve from 0.84718\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.8487 - auc: 0.9291 - val_loss: 0.1026 - val_accuracy: 0.8467 - val_auc: 0.9358\n",
      "Epoch 14/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1053 - accuracy: 0.8517 - auc: 0.9315\n",
      "Epoch 14: val_accuracy improved from 0.84718 to 0.85319, saving model to \\saved_models3_1/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.8516 - auc: 0.9316 - val_loss: 0.1025 - val_accuracy: 0.8532 - val_auc: 0.9371\n",
      "Epoch 15/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.8551 - auc: 0.9340\n",
      "Epoch 15: val_accuracy did not improve from 0.85319\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.8553 - auc: 0.9341 - val_loss: 0.0996 - val_accuracy: 0.8518 - val_auc: 0.9396\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.8532 - auc: 0.9371\n",
      "Epoch 1/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.2467 - accuracy: 0.5363 - auc: 0.5923\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55494, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2465 - accuracy: 0.5364 - auc: 0.5966 - val_loss: 0.2439 - val_accuracy: 0.5549 - val_auc: 0.6540\n",
      "Epoch 2/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2396 - accuracy: 0.5753 - auc: 0.7312\n",
      "Epoch 2: val_accuracy improved from 0.55494 to 0.61127, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2396 - accuracy: 0.5755 - auc: 0.7312 - val_loss: 0.2356 - val_accuracy: 0.6113 - val_auc: 0.7354\n",
      "Epoch 3/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.2254 - accuracy: 0.6799 - auc: 0.7763\n",
      "Epoch 3: val_accuracy improved from 0.61127 to 0.69067, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2248 - accuracy: 0.6815 - auc: 0.7766 - val_loss: 0.2183 - val_accuracy: 0.6907 - val_auc: 0.7588\n",
      "Epoch 4/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.2012 - accuracy: 0.7254 - auc: 0.8040\n",
      "Epoch 4: val_accuracy improved from 0.69067 to 0.71837, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2004 - accuracy: 0.7266 - auc: 0.8041 - val_loss: 0.1945 - val_accuracy: 0.7184 - val_auc: 0.7940\n",
      "Epoch 5/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1738 - accuracy: 0.7635 - auc: 0.8398\n",
      "Epoch 5: val_accuracy improved from 0.71837 to 0.75854, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1731 - accuracy: 0.7649 - auc: 0.8406 - val_loss: 0.1690 - val_accuracy: 0.7585 - val_auc: 0.8371\n",
      "Epoch 6/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.7980 - auc: 0.8756\n",
      "Epoch 6: val_accuracy improved from 0.75854 to 0.79871, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1486 - accuracy: 0.7977 - auc: 0.8755 - val_loss: 0.1466 - val_accuracy: 0.7987 - val_auc: 0.8740\n",
      "Epoch 7/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1320 - accuracy: 0.8194 - auc: 0.8979\n",
      "Epoch 7: val_accuracy improved from 0.79871 to 0.81440, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1312 - accuracy: 0.8206 - auc: 0.8992 - val_loss: 0.1338 - val_accuracy: 0.8144 - val_auc: 0.8930\n",
      "Epoch 8/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1223 - accuracy: 0.8306 - auc: 0.9100\n",
      "Epoch 8: val_accuracy improved from 0.81440 to 0.81994, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1216 - accuracy: 0.8320 - auc: 0.9109 - val_loss: 0.1267 - val_accuracy: 0.8199 - val_auc: 0.9020\n",
      "Epoch 9/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.8369 - auc: 0.9175\n",
      "Epoch 9: val_accuracy improved from 0.81994 to 0.82364, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.8370 - auc: 0.9175 - val_loss: 0.1226 - val_accuracy: 0.8236 - val_auc: 0.9081\n",
      "Epoch 10/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1127 - accuracy: 0.8420 - auc: 0.9216\n",
      "Epoch 10: val_accuracy improved from 0.82364 to 0.82641, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.8428 - auc: 0.9222 - val_loss: 0.1203 - val_accuracy: 0.8264 - val_auc: 0.9112\n",
      "Epoch 11/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1094 - accuracy: 0.8460 - auc: 0.9261\n",
      "Epoch 11: val_accuracy improved from 0.82641 to 0.83102, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.8461 - auc: 0.9260 - val_loss: 0.1180 - val_accuracy: 0.8310 - val_auc: 0.9145\n",
      "Epoch 12/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.8505 - auc: 0.9291\n",
      "Epoch 12: val_accuracy improved from 0.83102 to 0.83149, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.8503 - auc: 0.9290 - val_loss: 0.1167 - val_accuracy: 0.8315 - val_auc: 0.9177\n",
      "Epoch 13/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1049 - accuracy: 0.8526 - auc: 0.9318\n",
      "Epoch 13: val_accuracy improved from 0.83149 to 0.83333, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.8528 - auc: 0.9319 - val_loss: 0.1143 - val_accuracy: 0.8333 - val_auc: 0.9198\n",
      "Epoch 14/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.8562 - auc: 0.9349\n",
      "Epoch 14: val_accuracy improved from 0.83333 to 0.83795, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.8558 - auc: 0.9347 - val_loss: 0.1124 - val_accuracy: 0.8380 - val_auc: 0.9229\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608/610 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.8587 - auc: 0.9375\n",
      "Epoch 15: val_accuracy improved from 0.83795 to 0.84164, saving model to \\saved_models3_1/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.8586 - auc: 0.9374 - val_loss: 0.1106 - val_accuracy: 0.8416 - val_auc: 0.9253\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8416 - auc: 0.9253\n",
      "Epoch 1/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.2456 - accuracy: 0.5904 - auc: 0.6427\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59695, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2453 - accuracy: 0.5921 - auc: 0.6482 - val_loss: 0.2426 - val_accuracy: 0.5970 - val_auc: 0.7276\n",
      "Epoch 2/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.2363 - accuracy: 0.6342 - auc: 0.7856\n",
      "Epoch 2: val_accuracy improved from 0.59695 to 0.65420, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2362 - accuracy: 0.6356 - auc: 0.7861 - val_loss: 0.2324 - val_accuracy: 0.6542 - val_auc: 0.7874\n",
      "Epoch 3/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.7227 - auc: 0.8150\n",
      "Epoch 3: val_accuracy improved from 0.65420 to 0.72022, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.7233 - auc: 0.8155 - val_loss: 0.2125 - val_accuracy: 0.7202 - val_auc: 0.8079\n",
      "Epoch 4/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1950 - accuracy: 0.7539 - auc: 0.8308\n",
      "Epoch 4: val_accuracy improved from 0.72022 to 0.74885, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1938 - accuracy: 0.7548 - auc: 0.8322 - val_loss: 0.1845 - val_accuracy: 0.7488 - val_auc: 0.8302\n",
      "Epoch 5/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1663 - accuracy: 0.7762 - auc: 0.8571\n",
      "Epoch 5: val_accuracy improved from 0.74885 to 0.77424, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1655 - accuracy: 0.7770 - auc: 0.8583 - val_loss: 0.1597 - val_accuracy: 0.7742 - val_auc: 0.8610\n",
      "Epoch 6/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1434 - accuracy: 0.8077 - auc: 0.8857\n",
      "Epoch 6: val_accuracy improved from 0.77424 to 0.79086, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1426 - accuracy: 0.8087 - auc: 0.8870 - val_loss: 0.1427 - val_accuracy: 0.7909 - val_auc: 0.8835\n",
      "Epoch 7/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.8255 - auc: 0.9048\n",
      "Epoch 7: val_accuracy improved from 0.79086 to 0.80194, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1279 - accuracy: 0.8251 - auc: 0.9047 - val_loss: 0.1340 - val_accuracy: 0.8019 - val_auc: 0.8942\n",
      "Epoch 8/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1201 - accuracy: 0.8332 - auc: 0.9134\n",
      "Epoch 8: val_accuracy improved from 0.80194 to 0.80840, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1199 - accuracy: 0.8335 - auc: 0.9137 - val_loss: 0.1293 - val_accuracy: 0.8084 - val_auc: 0.9003\n",
      "Epoch 9/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1158 - accuracy: 0.8382 - auc: 0.9185\n",
      "Epoch 9: val_accuracy improved from 0.80840 to 0.81487, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.8393 - auc: 0.9191 - val_loss: 0.1267 - val_accuracy: 0.8149 - val_auc: 0.9043\n",
      "Epoch 10/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1130 - accuracy: 0.8419 - auc: 0.9219\n",
      "Epoch 10: val_accuracy improved from 0.81487 to 0.81625, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.8433 - auc: 0.9226 - val_loss: 0.1252 - val_accuracy: 0.8163 - val_auc: 0.9067\n",
      "Epoch 11/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1092 - accuracy: 0.8475 - auc: 0.9267\n",
      "Epoch 11: val_accuracy did not improve from 0.81625\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1101 - accuracy: 0.8459 - auc: 0.9254 - val_loss: 0.1246 - val_accuracy: 0.8153 - val_auc: 0.9082\n",
      "Epoch 12/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1085 - accuracy: 0.8485 - auc: 0.9275\n",
      "Epoch 12: val_accuracy did not improve from 0.81625\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.8484 - auc: 0.9273 - val_loss: 0.1236 - val_accuracy: 0.8158 - val_auc: 0.9101\n",
      "Epoch 13/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1072 - accuracy: 0.8492 - auc: 0.9292\n",
      "Epoch 13: val_accuracy improved from 0.81625 to 0.82087, saving model to \\saved_models3_1/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.8490 - auc: 0.9290 - val_loss: 0.1229 - val_accuracy: 0.8209 - val_auc: 0.9111\n",
      "Epoch 14/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1066 - accuracy: 0.8493 - auc: 0.9304\n",
      "Epoch 14: val_accuracy did not improve from 0.82087\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.8498 - auc: 0.9304 - val_loss: 0.1224 - val_accuracy: 0.8209 - val_auc: 0.9121\n",
      "Epoch 15/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1054 - accuracy: 0.8513 - auc: 0.9316\n",
      "Epoch 15: val_accuracy did not improve from 0.82087\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1055 - accuracy: 0.8509 - auc: 0.9315 - val_loss: 0.1225 - val_accuracy: 0.8195 - val_auc: 0.9125\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.8209 - auc: 0.9111\n",
      "Epoch 1/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.2459 - accuracy: 0.5587 - auc: 0.6055\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56464, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.5586 - auc: 0.6110 - val_loss: 0.2421 - val_accuracy: 0.5646 - val_auc: 0.7287\n",
      "Epoch 2/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.2378 - accuracy: 0.5724 - auc: 0.7731\n",
      "Epoch 2: val_accuracy improved from 0.56464 to 0.66759, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2376 - accuracy: 0.5754 - auc: 0.7752 - val_loss: 0.2327 - val_accuracy: 0.6676 - val_auc: 0.8082\n",
      "Epoch 3/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.7031 - auc: 0.8320\n",
      "Epoch 3: val_accuracy improved from 0.66759 to 0.75392, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2246 - accuracy: 0.7052 - auc: 0.8327 - val_loss: 0.2158 - val_accuracy: 0.7539 - val_auc: 0.8404\n",
      "Epoch 4/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.7762 - auc: 0.8564\n",
      "Epoch 4: val_accuracy improved from 0.75392 to 0.79040, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2032 - accuracy: 0.7763 - auc: 0.8558 - val_loss: 0.1906 - val_accuracy: 0.7904 - val_auc: 0.8566\n",
      "Epoch 5/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1778 - accuracy: 0.8017 - auc: 0.8681\n",
      "Epoch 5: val_accuracy improved from 0.79040 to 0.80656, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1768 - accuracy: 0.8031 - auc: 0.8692 - val_loss: 0.1648 - val_accuracy: 0.8066 - val_auc: 0.8715\n",
      "Epoch 6/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1544 - accuracy: 0.8172 - auc: 0.8827\n",
      "Epoch 6: val_accuracy improved from 0.80656 to 0.82271, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1538 - accuracy: 0.8177 - auc: 0.8836 - val_loss: 0.1455 - val_accuracy: 0.8227 - val_auc: 0.8841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1381 - accuracy: 0.8292 - auc: 0.8946\n",
      "Epoch 7: val_accuracy improved from 0.82271 to 0.83472, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1375 - accuracy: 0.8302 - auc: 0.8952 - val_loss: 0.1327 - val_accuracy: 0.8347 - val_auc: 0.8948\n",
      "Epoch 8/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1272 - accuracy: 0.8374 - auc: 0.9042\n",
      "Epoch 8: val_accuracy improved from 0.83472 to 0.83841, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1271 - accuracy: 0.8374 - auc: 0.9040 - val_loss: 0.1245 - val_accuracy: 0.8384 - val_auc: 0.9030\n",
      "Epoch 9/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.8420 - auc: 0.9104\n",
      "Epoch 9: val_accuracy improved from 0.83841 to 0.83934, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1208 - accuracy: 0.8416 - auc: 0.9100 - val_loss: 0.1196 - val_accuracy: 0.8393 - val_auc: 0.9087\n",
      "Epoch 10/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1168 - accuracy: 0.8431 - auc: 0.9147\n",
      "Epoch 10: val_accuracy improved from 0.83934 to 0.84164, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.8426 - auc: 0.9142 - val_loss: 0.1165 - val_accuracy: 0.8416 - val_auc: 0.9126\n",
      "Epoch 11/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1149 - accuracy: 0.8439 - auc: 0.9171\n",
      "Epoch 11: val_accuracy improved from 0.84164 to 0.84626, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.8448 - auc: 0.9174 - val_loss: 0.1143 - val_accuracy: 0.8463 - val_auc: 0.9158\n",
      "Epoch 12/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.8460 - auc: 0.9201\n",
      "Epoch 12: val_accuracy improved from 0.84626 to 0.84857, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.8456 - auc: 0.9199 - val_loss: 0.1124 - val_accuracy: 0.8486 - val_auc: 0.9189\n",
      "Epoch 13/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1117 - accuracy: 0.8462 - auc: 0.9216\n",
      "Epoch 13: val_accuracy improved from 0.84857 to 0.84995, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1114 - accuracy: 0.8468 - auc: 0.9221 - val_loss: 0.1109 - val_accuracy: 0.8500 - val_auc: 0.9209\n",
      "Epoch 14/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1106 - accuracy: 0.8473 - auc: 0.9234\n",
      "Epoch 14: val_accuracy improved from 0.84995 to 0.85134, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.8482 - auc: 0.9239 - val_loss: 0.1097 - val_accuracy: 0.8513 - val_auc: 0.9231\n",
      "Epoch 15/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1097 - accuracy: 0.8486 - auc: 0.9248\n",
      "Epoch 15: val_accuracy improved from 0.85134 to 0.85272, saving model to \\saved_models3_1/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1092 - accuracy: 0.8491 - auc: 0.9256 - val_loss: 0.1086 - val_accuracy: 0.8527 - val_auc: 0.9248\n",
      "68/68 [==============================] - 0s 966us/step - loss: 0.1086 - accuracy: 0.8527 - auc: 0.9248\n",
      "Epoch 1/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.5772 - auc: 0.6088\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65743, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.5791 - auc: 0.6105 - val_loss: 0.2391 - val_accuracy: 0.6574 - val_auc: 0.7365\n",
      "Epoch 2/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.7037 - auc: 0.7949\n",
      "Epoch 2: val_accuracy improved from 0.65743 to 0.74515, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2305 - accuracy: 0.7050 - auc: 0.7956 - val_loss: 0.2226 - val_accuracy: 0.7452 - val_auc: 0.8229\n",
      "Epoch 3/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2092 - accuracy: 0.7672 - auc: 0.8398\n",
      "Epoch 3: val_accuracy improved from 0.74515 to 0.76870, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2081 - accuracy: 0.7694 - auc: 0.8411 - val_loss: 0.1951 - val_accuracy: 0.7687 - val_auc: 0.8465\n",
      "Epoch 4/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1762 - accuracy: 0.7843 - auc: 0.8586\n",
      "Epoch 4: val_accuracy improved from 0.76870 to 0.78624, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1756 - accuracy: 0.7844 - auc: 0.8587 - val_loss: 0.1631 - val_accuracy: 0.7862 - val_auc: 0.8655\n",
      "Epoch 5/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1491 - accuracy: 0.8020 - auc: 0.8801\n",
      "Epoch 5: val_accuracy improved from 0.78624 to 0.80794, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1484 - accuracy: 0.8030 - auc: 0.8811 - val_loss: 0.1418 - val_accuracy: 0.8079 - val_auc: 0.8855\n",
      "Epoch 6/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1335 - accuracy: 0.8181 - auc: 0.8959\n",
      "Epoch 6: val_accuracy improved from 0.80794 to 0.81394, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1329 - accuracy: 0.8192 - auc: 0.8966 - val_loss: 0.1310 - val_accuracy: 0.8139 - val_auc: 0.8969\n",
      "Epoch 7/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1246 - accuracy: 0.8297 - auc: 0.9062\n",
      "Epoch 7: val_accuracy improved from 0.81394 to 0.82548, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1247 - accuracy: 0.8296 - auc: 0.9058 - val_loss: 0.1255 - val_accuracy: 0.8255 - val_auc: 0.9035\n",
      "Epoch 8/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1197 - accuracy: 0.8349 - auc: 0.9117\n",
      "Epoch 8: val_accuracy improved from 0.82548 to 0.83287, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1199 - accuracy: 0.8346 - auc: 0.9115 - val_loss: 0.1218 - val_accuracy: 0.8329 - val_auc: 0.9084\n",
      "Epoch 9/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.8384 - auc: 0.9158\n",
      "Epoch 9: val_accuracy improved from 0.83287 to 0.83380, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.8386 - auc: 0.9158 - val_loss: 0.1193 - val_accuracy: 0.8338 - val_auc: 0.9115\n",
      "Epoch 10/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1146 - accuracy: 0.8415 - auc: 0.9183\n",
      "Epoch 10: val_accuracy improved from 0.83380 to 0.83934, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1145 - accuracy: 0.8414 - auc: 0.9187 - val_loss: 0.1174 - val_accuracy: 0.8393 - val_auc: 0.9143\n",
      "Epoch 11/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.8436 - auc: 0.9207\n",
      "Epoch 11: val_accuracy improved from 0.83934 to 0.84026, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1126 - accuracy: 0.8443 - auc: 0.9213 - val_loss: 0.1159 - val_accuracy: 0.8403 - val_auc: 0.9165\n",
      "Epoch 12/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1112 - accuracy: 0.8455 - auc: 0.9233\n",
      "Epoch 12: val_accuracy improved from 0.84026 to 0.84211, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1112 - accuracy: 0.8456 - auc: 0.9233 - val_loss: 0.1147 - val_accuracy: 0.8421 - val_auc: 0.9185\n",
      "Epoch 13/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1100 - accuracy: 0.8466 - auc: 0.9250\n",
      "Epoch 13: val_accuracy improved from 0.84211 to 0.84626, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.8463 - auc: 0.9252 - val_loss: 0.1134 - val_accuracy: 0.8463 - val_auc: 0.9202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1097 - accuracy: 0.8477 - auc: 0.9256\n",
      "Epoch 14: val_accuracy improved from 0.84626 to 0.84672, saving model to \\saved_models3_1/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8487 - auc: 0.9266 - val_loss: 0.1126 - val_accuracy: 0.8467 - val_auc: 0.9214\n",
      "Epoch 15/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1083 - accuracy: 0.8481 - auc: 0.9277\n",
      "Epoch 15: val_accuracy did not improve from 0.84672\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.8490 - auc: 0.9281 - val_loss: 0.1121 - val_accuracy: 0.8449 - val_auc: 0.9226\n",
      "68/68 [==============================] - 0s 985us/step - loss: 0.1126 - accuracy: 0.8467 - auc: 0.9214\n",
      "Epoch 1/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.5204 - auc: 0.5147\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55725, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.5206 - auc: 0.5166 - val_loss: 0.2465 - val_accuracy: 0.5572 - val_auc: 0.6002\n",
      "Epoch 2/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.2447 - accuracy: 0.5447 - auc: 0.6854\n",
      "Epoch 2: val_accuracy improved from 0.55725 to 0.57341, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.5447 - auc: 0.6899 - val_loss: 0.2418 - val_accuracy: 0.5734 - val_auc: 0.7573\n",
      "Epoch 3/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.2388 - accuracy: 0.5763 - auc: 0.8175\n",
      "Epoch 3: val_accuracy improved from 0.57341 to 0.62281, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2385 - accuracy: 0.5800 - auc: 0.8197 - val_loss: 0.2339 - val_accuracy: 0.6228 - val_auc: 0.8457\n",
      "Epoch 4/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.6948 - auc: 0.8669\n",
      "Epoch 4: val_accuracy improved from 0.62281 to 0.76916, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2278 - accuracy: 0.6958 - auc: 0.8668 - val_loss: 0.2201 - val_accuracy: 0.7692 - val_auc: 0.8685\n",
      "Epoch 5/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.2106 - accuracy: 0.8039 - auc: 0.8755\n",
      "Epoch 5: val_accuracy improved from 0.76916 to 0.83195, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2103 - accuracy: 0.8044 - auc: 0.8748 - val_loss: 0.1991 - val_accuracy: 0.8319 - val_auc: 0.8737\n",
      "Epoch 6/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.8351 - auc: 0.8770\n",
      "Epoch 6: val_accuracy improved from 0.83195 to 0.84395, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1868 - accuracy: 0.8362 - auc: 0.8781 - val_loss: 0.1747 - val_accuracy: 0.8440 - val_auc: 0.8755\n",
      "Epoch 7/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1644 - accuracy: 0.8445 - auc: 0.8781\n",
      "Epoch 7: val_accuracy improved from 0.84395 to 0.84534, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1637 - accuracy: 0.8449 - auc: 0.8787 - val_loss: 0.1541 - val_accuracy: 0.8453 - val_auc: 0.8768\n",
      "Epoch 8/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1470 - accuracy: 0.8464 - auc: 0.8800\n",
      "Epoch 8: val_accuracy improved from 0.84534 to 0.84626, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1466 - accuracy: 0.8467 - auc: 0.8802 - val_loss: 0.1407 - val_accuracy: 0.8463 - val_auc: 0.8784\n",
      "Epoch 9/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.8477 - auc: 0.8827\n",
      "Epoch 9: val_accuracy did not improve from 0.84626\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1362 - accuracy: 0.8472 - auc: 0.8820 - val_loss: 0.1329 - val_accuracy: 0.8463 - val_auc: 0.8797\n",
      "Epoch 10/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.8470 - auc: 0.8838\n",
      "Epoch 10: val_accuracy did not improve from 0.84626\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1302 - accuracy: 0.8475 - auc: 0.8843 - val_loss: 0.1283 - val_accuracy: 0.8463 - val_auc: 0.8821\n",
      "Epoch 11/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1267 - accuracy: 0.8478 - auc: 0.8864\n",
      "Epoch 11: val_accuracy improved from 0.84626 to 0.84672, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1267 - accuracy: 0.8478 - auc: 0.8864 - val_loss: 0.1256 - val_accuracy: 0.8467 - val_auc: 0.8833\n",
      "Epoch 12/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1242 - accuracy: 0.8486 - auc: 0.8892\n",
      "Epoch 12: val_accuracy improved from 0.84672 to 0.84765, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1246 - accuracy: 0.8480 - auc: 0.8886 - val_loss: 0.1239 - val_accuracy: 0.8476 - val_auc: 0.8853\n",
      "Epoch 13/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.8479 - auc: 0.8904\n",
      "Epoch 13: val_accuracy improved from 0.84765 to 0.84811, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1232 - accuracy: 0.8480 - auc: 0.8905 - val_loss: 0.1228 - val_accuracy: 0.8481 - val_auc: 0.8873\n",
      "Epoch 14/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.8476 - auc: 0.8917\n",
      "Epoch 14: val_accuracy improved from 0.84811 to 0.84949, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.8480 - auc: 0.8923 - val_loss: 0.1220 - val_accuracy: 0.8495 - val_auc: 0.8885\n",
      "Epoch 15/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.8480 - auc: 0.8938\n",
      "Epoch 15: val_accuracy improved from 0.84949 to 0.84995, saving model to \\saved_models3_1/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.8481 - auc: 0.8938 - val_loss: 0.1214 - val_accuracy: 0.8500 - val_auc: 0.8899\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.8500 - auc: 0.8899\n",
      "Epoch 1/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.2469 - accuracy: 0.5679 - auc: 0.6098\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57341, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2467 - accuracy: 0.5700 - auc: 0.6156 - val_loss: 0.2435 - val_accuracy: 0.5734 - val_auc: 0.7414\n",
      "Epoch 2/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.2400 - accuracy: 0.6017 - auc: 0.7808\n",
      "Epoch 2: val_accuracy improved from 0.57341 to 0.63989, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2395 - accuracy: 0.6047 - auc: 0.7852 - val_loss: 0.2345 - val_accuracy: 0.6399 - val_auc: 0.8325\n",
      "Epoch 3/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.7102 - auc: 0.8358\n",
      "Epoch 3: val_accuracy improved from 0.63989 to 0.74931, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2269 - accuracy: 0.7116 - auc: 0.8355 - val_loss: 0.2174 - val_accuracy: 0.7493 - val_auc: 0.8497\n",
      "Epoch 4/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.2059 - accuracy: 0.7696 - auc: 0.8493\n",
      "Epoch 4: val_accuracy improved from 0.74931 to 0.78532, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2048 - accuracy: 0.7707 - auc: 0.8504 - val_loss: 0.1909 - val_accuracy: 0.7853 - val_auc: 0.8567\n",
      "Epoch 5/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1779 - accuracy: 0.7879 - auc: 0.8598\n",
      "Epoch 5: val_accuracy improved from 0.78532 to 0.79548, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1771 - accuracy: 0.7885 - auc: 0.8601 - val_loss: 0.1643 - val_accuracy: 0.7955 - val_auc: 0.8682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1541 - accuracy: 0.8050 - auc: 0.8758\n",
      "Epoch 6: val_accuracy improved from 0.79548 to 0.81025, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1539 - accuracy: 0.8052 - auc: 0.8758 - val_loss: 0.1452 - val_accuracy: 0.8102 - val_auc: 0.8830\n",
      "Epoch 7/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1383 - accuracy: 0.8207 - auc: 0.8908\n",
      "Epoch 7: val_accuracy improved from 0.81025 to 0.82410, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1382 - accuracy: 0.8211 - auc: 0.8904 - val_loss: 0.1322 - val_accuracy: 0.8241 - val_auc: 0.8957\n",
      "Epoch 8/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.8312 - auc: 0.9003\n",
      "Epoch 8: val_accuracy improved from 0.82410 to 0.83518, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1282 - accuracy: 0.8313 - auc: 0.9003 - val_loss: 0.1233 - val_accuracy: 0.8352 - val_auc: 0.9051\n",
      "Epoch 9/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1226 - accuracy: 0.8369 - auc: 0.9069\n",
      "Epoch 9: val_accuracy improved from 0.83518 to 0.84211, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.8376 - auc: 0.9075 - val_loss: 0.1188 - val_accuracy: 0.8421 - val_auc: 0.9108\n",
      "Epoch 10/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 0.8393 - auc: 0.9119\n",
      "Epoch 10: val_accuracy improved from 0.84211 to 0.84857, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.8395 - auc: 0.9123 - val_loss: 0.1147 - val_accuracy: 0.8486 - val_auc: 0.9155\n",
      "Epoch 11/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.1154 - accuracy: 0.8430 - auc: 0.9165\n",
      "Epoch 11: val_accuracy improved from 0.84857 to 0.84995, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8430 - auc: 0.9160 - val_loss: 0.1127 - val_accuracy: 0.8500 - val_auc: 0.9184\n",
      "Epoch 12/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1134 - accuracy: 0.8457 - auc: 0.9193\n",
      "Epoch 12: val_accuracy improved from 0.84995 to 0.85088, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.8451 - auc: 0.9188 - val_loss: 0.1113 - val_accuracy: 0.8509 - val_auc: 0.9209\n",
      "Epoch 13/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1132 - accuracy: 0.8453 - auc: 0.9199\n",
      "Epoch 13: val_accuracy improved from 0.85088 to 0.85365, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.8462 - auc: 0.9210 - val_loss: 0.1095 - val_accuracy: 0.8536 - val_auc: 0.9235\n",
      "Epoch 14/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.8472 - auc: 0.9227\n",
      "Epoch 14: val_accuracy improved from 0.85365 to 0.85688, saving model to \\saved_models3_1/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.8470 - auc: 0.9228 - val_loss: 0.1081 - val_accuracy: 0.8569 - val_auc: 0.9254\n",
      "Epoch 15/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.8472 - auc: 0.9246\n",
      "Epoch 15: val_accuracy did not improve from 0.85688\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.1104 - accuracy: 0.8476 - auc: 0.9243 - val_loss: 0.1076 - val_accuracy: 0.8569 - val_auc: 0.9270\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8569 - auc: 0.9254\n",
      "Epoch 1/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.5539 - auc: 0.6129\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57044, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.5540 - auc: 0.6127 - val_loss: 0.2387 - val_accuracy: 0.5704 - val_auc: 0.6903\n",
      "Epoch 2/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.2326 - accuracy: 0.6198 - auc: 0.7217\n",
      "Epoch 2: val_accuracy improved from 0.57044 to 0.69099, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2321 - accuracy: 0.6222 - auc: 0.7231 - val_loss: 0.2206 - val_accuracy: 0.6910 - val_auc: 0.7638\n",
      "Epoch 3/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.2128 - accuracy: 0.7125 - auc: 0.7831\n",
      "Epoch 3: val_accuracy improved from 0.69099 to 0.73672, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2121 - accuracy: 0.7136 - auc: 0.7838 - val_loss: 0.1984 - val_accuracy: 0.7367 - val_auc: 0.8154\n",
      "Epoch 4/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1896 - accuracy: 0.7513 - auc: 0.8302\n",
      "Epoch 4: val_accuracy improved from 0.73672 to 0.76351, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1891 - accuracy: 0.7520 - auc: 0.8307 - val_loss: 0.1766 - val_accuracy: 0.7635 - val_auc: 0.8492\n",
      "Epoch 5/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1676 - accuracy: 0.7813 - auc: 0.8628\n",
      "Epoch 5: val_accuracy improved from 0.76351 to 0.79307, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1671 - accuracy: 0.7813 - auc: 0.8632 - val_loss: 0.1561 - val_accuracy: 0.7931 - val_auc: 0.8756\n",
      "Epoch 6/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.8050 - auc: 0.8855\n",
      "Epoch 6: val_accuracy improved from 0.79307 to 0.81016, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1489 - accuracy: 0.8052 - auc: 0.8856 - val_loss: 0.1405 - val_accuracy: 0.8102 - val_auc: 0.8938\n",
      "Epoch 7/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1365 - accuracy: 0.8207 - auc: 0.8979\n",
      "Epoch 7: val_accuracy improved from 0.81016 to 0.82125, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1357 - accuracy: 0.8223 - auc: 0.8990 - val_loss: 0.1309 - val_accuracy: 0.8212 - val_auc: 0.9032\n",
      "Epoch 8/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.8315 - auc: 0.9077\n",
      "Epoch 8: val_accuracy improved from 0.82125 to 0.82864, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1273 - accuracy: 0.8312 - auc: 0.9074 - val_loss: 0.1237 - val_accuracy: 0.8286 - val_auc: 0.9107\n",
      "Epoch 9/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.8365 - auc: 0.9126\n",
      "Epoch 9: val_accuracy improved from 0.82864 to 0.83279, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1217 - accuracy: 0.8362 - auc: 0.9126 - val_loss: 0.1194 - val_accuracy: 0.8328 - val_auc: 0.9144\n",
      "Epoch 10/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.8406 - auc: 0.9167\n",
      "Epoch 10: val_accuracy improved from 0.83279 to 0.83926, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.8404 - auc: 0.9167 - val_loss: 0.1169 - val_accuracy: 0.8393 - val_auc: 0.9171\n",
      "Epoch 11/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.8448 - auc: 0.9197\n",
      "Epoch 11: val_accuracy improved from 0.83926 to 0.84665, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.8448 - auc: 0.9195 - val_loss: 0.1139 - val_accuracy: 0.8467 - val_auc: 0.9205\n",
      "Epoch 12/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.1127 - accuracy: 0.8471 - auc: 0.9228\n",
      "Epoch 12: val_accuracy improved from 0.84665 to 0.84942, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.8470 - auc: 0.9225 - val_loss: 0.1122 - val_accuracy: 0.8494 - val_auc: 0.9226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1114 - accuracy: 0.8490 - auc: 0.9243\n",
      "Epoch 13: val_accuracy improved from 0.84942 to 0.85219, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.8495 - auc: 0.9246 - val_loss: 0.1101 - val_accuracy: 0.8522 - val_auc: 0.9262\n",
      "Epoch 14/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1092 - accuracy: 0.8503 - auc: 0.9270\n",
      "Epoch 14: val_accuracy improved from 0.85219 to 0.85589, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1096 - accuracy: 0.8497 - auc: 0.9263 - val_loss: 0.1090 - val_accuracy: 0.8559 - val_auc: 0.9270\n",
      "Epoch 15/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1082 - accuracy: 0.8520 - auc: 0.9283\n",
      "Epoch 15: val_accuracy improved from 0.85589 to 0.85635, saving model to \\saved_models3_1/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1084 - accuracy: 0.8514 - auc: 0.9281 - val_loss: 0.1081 - val_accuracy: 0.8564 - val_auc: 0.9278\n",
      "68/68 [==============================] - 0s 991us/step - loss: 0.1081 - accuracy: 0.8564 - auc: 0.9278\n",
      "Epoch 1/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.2484 - accuracy: 0.5394 - auc: 0.5509\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58476, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.5395 - auc: 0.5512 - val_loss: 0.2448 - val_accuracy: 0.5848 - val_auc: 0.6655\n",
      "Epoch 2/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.2426 - accuracy: 0.5916 - auc: 0.7125\n",
      "Epoch 2: val_accuracy improved from 0.58476 to 0.63233, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.5920 - auc: 0.7159 - val_loss: 0.2377 - val_accuracy: 0.6323 - val_auc: 0.7927\n",
      "Epoch 3/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.2332 - accuracy: 0.6799 - auc: 0.8102\n",
      "Epoch 3: val_accuracy improved from 0.63233 to 0.75566, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2327 - accuracy: 0.6841 - auc: 0.8112 - val_loss: 0.2243 - val_accuracy: 0.7557 - val_auc: 0.8430\n",
      "Epoch 4/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.7668 - auc: 0.8424\n",
      "Epoch 4: val_accuracy improved from 0.75566 to 0.78291, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2141 - accuracy: 0.7668 - auc: 0.8425 - val_loss: 0.1999 - val_accuracy: 0.7829 - val_auc: 0.8599\n",
      "Epoch 5/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1867 - accuracy: 0.7859 - auc: 0.8580\n",
      "Epoch 5: val_accuracy improved from 0.78291 to 0.80554, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1859 - accuracy: 0.7860 - auc: 0.8577 - val_loss: 0.1690 - val_accuracy: 0.8055 - val_auc: 0.8765\n",
      "Epoch 6/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1600 - accuracy: 0.7997 - auc: 0.8727\n",
      "Epoch 6: val_accuracy improved from 0.80554 to 0.81940, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1590 - accuracy: 0.8003 - auc: 0.8738 - val_loss: 0.1458 - val_accuracy: 0.8194 - val_auc: 0.8919\n",
      "Epoch 7/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1416 - accuracy: 0.8174 - auc: 0.8888\n",
      "Epoch 7: val_accuracy improved from 0.81940 to 0.83372, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1412 - accuracy: 0.8178 - auc: 0.8888 - val_loss: 0.1312 - val_accuracy: 0.8337 - val_auc: 0.9029\n",
      "Epoch 8/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.1302 - accuracy: 0.8296 - auc: 0.8998\n",
      "Epoch 8: val_accuracy improved from 0.83372 to 0.84296, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1300 - accuracy: 0.8294 - auc: 0.8997 - val_loss: 0.1223 - val_accuracy: 0.8430 - val_auc: 0.9108\n",
      "Epoch 9/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1229 - accuracy: 0.8357 - auc: 0.9071\n",
      "Epoch 9: val_accuracy improved from 0.84296 to 0.84896, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.8354 - auc: 0.9069 - val_loss: 0.1174 - val_accuracy: 0.8490 - val_auc: 0.9154\n",
      "Epoch 10/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.8412 - auc: 0.9122\n",
      "Epoch 10: val_accuracy improved from 0.84896 to 0.84988, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1186 - accuracy: 0.8411 - auc: 0.9121 - val_loss: 0.1140 - val_accuracy: 0.8499 - val_auc: 0.9185\n",
      "Epoch 11/15\n",
      "564/610 [==========================>...] - ETA: 0s - loss: 0.1156 - accuracy: 0.8439 - auc: 0.9156\n",
      "Epoch 11: val_accuracy improved from 0.84988 to 0.85127, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1158 - accuracy: 0.8432 - auc: 0.9156 - val_loss: 0.1120 - val_accuracy: 0.8513 - val_auc: 0.9207\n",
      "Epoch 12/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.8453 - auc: 0.9186\n",
      "Epoch 12: val_accuracy improved from 0.85127 to 0.85219, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1137 - accuracy: 0.8453 - auc: 0.9186 - val_loss: 0.1110 - val_accuracy: 0.8522 - val_auc: 0.9220\n",
      "Epoch 13/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1120 - accuracy: 0.8477 - auc: 0.9209\n",
      "Epoch 13: val_accuracy did not improve from 0.85219\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.8468 - auc: 0.9207 - val_loss: 0.1101 - val_accuracy: 0.8517 - val_auc: 0.9235\n",
      "Epoch 14/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1113 - accuracy: 0.8472 - auc: 0.9224\n",
      "Epoch 14: val_accuracy improved from 0.85219 to 0.85266, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.8478 - auc: 0.9225 - val_loss: 0.1090 - val_accuracy: 0.8527 - val_auc: 0.9243\n",
      "Epoch 15/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.8487 - auc: 0.9239\n",
      "Epoch 15: val_accuracy improved from 0.85266 to 0.85450, saving model to \\saved_models3_1/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1102 - accuracy: 0.8487 - auc: 0.9239 - val_loss: 0.1083 - val_accuracy: 0.8545 - val_auc: 0.9253\n",
      "68/68 [==============================] - 0s 975us/step - loss: 0.1083 - accuracy: 0.8545 - auc: 0.9253\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY31 = []\n",
    "VALIDATION_AUC31 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names3].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names3].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names3):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep4')(deep_branch) # added this\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model31 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model31.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models3_1/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history31 = model31.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model31.load_weights(\"\\saved_models3_1/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model31.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model31.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY31.append(results['accuracy'])\n",
    "    VALIDATION_AUC31.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history31.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history31.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history31.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history31.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8430286049842834 | 0.9252426624298096 |\n",
      "|  2   | 0.8531855940818787 | 0.9371157884597778 |\n",
      "|  3   | 0.8416435718536377 | 0.925330400466919  |\n",
      "|  4   | 0.8208679556846619 | 0.9110730290412903 |\n",
      "|  5   | 0.8527238965034485 | 0.9248325228691101 |\n",
      "|  6   | 0.8467220664024353 | 0.9214075207710266 |\n",
      "|  7   | 0.849953830242157  | 0.8898619413375854 |\n",
      "|  8   | 0.8568790555000305 | 0.9254499673843384 |\n",
      "|  9   | 0.8563510179519653 | 0.9278494119644165 |\n",
      "|  10  | 0.8545034527778625 | 0.9252508878707886 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY31)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC31)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 8\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY31.index(max(VALIDATION_ACCURACY31))\n",
    "max_fold31 = idx + 1\n",
    "print(\"Best Fold:\", max_fold31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 948us/step - loss: 0.1407 - accuracy: 0.8041 - auc: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14068499207496643, 0.8040961623191833, 0.8801827430725098]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model31.load_weights(\"\\saved_models3_1/model_\"+str(max_fold31)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model31.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 792us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model31.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat31 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep Network 3 - Even More Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.5754 - auc: 0.6172\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59049, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.5756 - auc: 0.6187 - val_loss: 0.2430 - val_accuracy: 0.5905 - val_auc: 0.7519\n",
      "Epoch 2/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.5891 - auc: 0.7963\n",
      "Epoch 2: val_accuracy improved from 0.59049 to 0.64820, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2401 - accuracy: 0.5899 - auc: 0.7974 - val_loss: 0.2348 - val_accuracy: 0.6482 - val_auc: 0.8430\n",
      "Epoch 3/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.2302 - accuracy: 0.6954 - auc: 0.8526\n",
      "Epoch 3: val_accuracy improved from 0.64820 to 0.76408, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2297 - accuracy: 0.6998 - auc: 0.8537 - val_loss: 0.2211 - val_accuracy: 0.7641 - val_auc: 0.8666\n",
      "Epoch 4/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.7753 - auc: 0.8673\n",
      "Epoch 4: val_accuracy improved from 0.76408 to 0.80840, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2128 - accuracy: 0.7760 - auc: 0.8670 - val_loss: 0.2003 - val_accuracy: 0.8084 - val_auc: 0.8729\n",
      "Epoch 5/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.8145 - auc: 0.8722\n",
      "Epoch 5: val_accuracy improved from 0.80840 to 0.83241, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.8144 - auc: 0.8718 - val_loss: 0.1758 - val_accuracy: 0.8324 - val_auc: 0.8750\n",
      "Epoch 6/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1670 - accuracy: 0.8333 - auc: 0.8761\n",
      "Epoch 6: val_accuracy improved from 0.83241 to 0.83841, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1667 - accuracy: 0.8334 - auc: 0.8756 - val_loss: 0.1551 - val_accuracy: 0.8384 - val_auc: 0.8777\n",
      "Epoch 7/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.8426 - auc: 0.8784\n",
      "Epoch 7: val_accuracy improved from 0.83841 to 0.84303, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1493 - accuracy: 0.8429 - auc: 0.8786 - val_loss: 0.1413 - val_accuracy: 0.8430 - val_auc: 0.8796\n",
      "Epoch 8/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.8464 - auc: 0.8806\n",
      "Epoch 8: val_accuracy improved from 0.84303 to 0.84349, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1381 - accuracy: 0.8466 - auc: 0.8809 - val_loss: 0.1331 - val_accuracy: 0.8435 - val_auc: 0.8817\n",
      "Epoch 9/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 0.8475 - auc: 0.8831\n",
      "Epoch 9: val_accuracy improved from 0.84349 to 0.84441, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1315 - accuracy: 0.8473 - auc: 0.8831 - val_loss: 0.1285 - val_accuracy: 0.8444 - val_auc: 0.8840\n",
      "Epoch 10/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1274 - accuracy: 0.8480 - auc: 0.8861\n",
      "Epoch 10: val_accuracy did not improve from 0.84441\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1275 - accuracy: 0.8475 - auc: 0.8860 - val_loss: 0.1258 - val_accuracy: 0.8444 - val_auc: 0.8866\n",
      "Epoch 11/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1255 - accuracy: 0.8471 - auc: 0.8876\n",
      "Epoch 11: val_accuracy did not improve from 0.84441\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.8478 - auc: 0.8885 - val_loss: 0.1242 - val_accuracy: 0.8444 - val_auc: 0.8887\n",
      "Epoch 12/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1234 - accuracy: 0.8481 - auc: 0.8909\n",
      "Epoch 12: val_accuracy did not improve from 0.84441\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.8479 - auc: 0.8908 - val_loss: 0.1231 - val_accuracy: 0.8440 - val_auc: 0.8908\n",
      "Epoch 13/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1221 - accuracy: 0.8486 - auc: 0.8934\n",
      "Epoch 13: val_accuracy did not improve from 0.84441\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1224 - accuracy: 0.8481 - auc: 0.8927 - val_loss: 0.1224 - val_accuracy: 0.8440 - val_auc: 0.8928\n",
      "Epoch 14/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.1219 - accuracy: 0.8476 - auc: 0.8943\n",
      "Epoch 14: val_accuracy did not improve from 0.84441\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1216 - accuracy: 0.8480 - auc: 0.8951 - val_loss: 0.1219 - val_accuracy: 0.8444 - val_auc: 0.8946\n",
      "Epoch 15/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1213 - accuracy: 0.8476 - auc: 0.8967\n",
      "Epoch 15: val_accuracy improved from 0.84441 to 0.84488, saving model to \\saved_models3_2/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1209 - accuracy: 0.8483 - auc: 0.8969 - val_loss: 0.1215 - val_accuracy: 0.8449 - val_auc: 0.8966\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.8449 - auc: 0.8966\n",
      "Epoch 1/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.2487 - accuracy: 0.5290 - auc: 0.5200\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51016, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.5289 - auc: 0.5212 - val_loss: 0.2485 - val_accuracy: 0.5102 - val_auc: 0.5762\n",
      "Epoch 2/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.2445 - accuracy: 0.5422 - auc: 0.6453\n",
      "Epoch 2: val_accuracy improved from 0.51016 to 0.52031, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.5419 - auc: 0.6466 - val_loss: 0.2440 - val_accuracy: 0.5203 - val_auc: 0.6977\n",
      "Epoch 3/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2379 - accuracy: 0.5683 - auc: 0.7433\n",
      "Epoch 3: val_accuracy improved from 0.52031 to 0.59695, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2377 - accuracy: 0.5699 - auc: 0.7447 - val_loss: 0.2349 - val_accuracy: 0.5970 - val_auc: 0.7776\n",
      "Epoch 4/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.2253 - accuracy: 0.6724 - auc: 0.7945\n",
      "Epoch 4: val_accuracy improved from 0.59695 to 0.71930, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2246 - accuracy: 0.6765 - auc: 0.7977 - val_loss: 0.2175 - val_accuracy: 0.7193 - val_auc: 0.8147\n",
      "Epoch 5/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.7503 - auc: 0.8263\n",
      "Epoch 5: val_accuracy improved from 0.71930 to 0.75993, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2031 - accuracy: 0.7507 - auc: 0.8265 - val_loss: 0.1925 - val_accuracy: 0.7599 - val_auc: 0.8410\n",
      "Epoch 6/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.7819 - auc: 0.8505\n",
      "Epoch 6: val_accuracy improved from 0.75993 to 0.79271, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1791 - accuracy: 0.7817 - auc: 0.8504 - val_loss: 0.1683 - val_accuracy: 0.7927 - val_auc: 0.8674\n",
      "Epoch 7/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1586 - accuracy: 0.8050 - auc: 0.8736\n",
      "Epoch 7: val_accuracy improved from 0.79271 to 0.81440, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1582 - accuracy: 0.8056 - auc: 0.8735 - val_loss: 0.1486 - val_accuracy: 0.8144 - val_auc: 0.8879\n",
      "Epoch 8/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.8238 - auc: 0.8899\n",
      "Epoch 8: val_accuracy improved from 0.81440 to 0.83241, saving model to \\saved_models3_2/model_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1421 - accuracy: 0.8233 - auc: 0.8898 - val_loss: 0.1344 - val_accuracy: 0.8324 - val_auc: 0.9009\n",
      "Epoch 9/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1306 - accuracy: 0.8349 - auc: 0.9014\n",
      "Epoch 9: val_accuracy improved from 0.83241 to 0.83795, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1308 - accuracy: 0.8340 - auc: 0.9008 - val_loss: 0.1254 - val_accuracy: 0.8380 - val_auc: 0.9092\n",
      "Epoch 10/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.8401 - auc: 0.9081\n",
      "Epoch 10: val_accuracy improved from 0.83795 to 0.84580, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.8400 - auc: 0.9082 - val_loss: 0.1194 - val_accuracy: 0.8458 - val_auc: 0.9142\n",
      "Epoch 11/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1184 - accuracy: 0.8443 - auc: 0.9139\n",
      "Epoch 11: val_accuracy improved from 0.84580 to 0.84626, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1188 - accuracy: 0.8433 - auc: 0.9136 - val_loss: 0.1154 - val_accuracy: 0.8463 - val_auc: 0.9173\n",
      "Epoch 12/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1154 - accuracy: 0.8458 - auc: 0.9179\n",
      "Epoch 12: val_accuracy improved from 0.84626 to 0.84995, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.8461 - auc: 0.9175 - val_loss: 0.1127 - val_accuracy: 0.8500 - val_auc: 0.9207\n",
      "Epoch 13/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1130 - accuracy: 0.8476 - auc: 0.9208\n",
      "Epoch 13: val_accuracy improved from 0.84995 to 0.85042, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.8478 - auc: 0.9210 - val_loss: 0.1107 - val_accuracy: 0.8504 - val_auc: 0.9240\n",
      "Epoch 14/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.8501 - auc: 0.9243\n",
      "Epoch 14: val_accuracy improved from 0.85042 to 0.85088, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1108 - accuracy: 0.8501 - auc: 0.9243 - val_loss: 0.1088 - val_accuracy: 0.8509 - val_auc: 0.9262\n",
      "Epoch 15/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.8523 - auc: 0.9273\n",
      "Epoch 15: val_accuracy improved from 0.85088 to 0.85272, saving model to \\saved_models3_2/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.8519 - auc: 0.9270 - val_loss: 0.1071 - val_accuracy: 0.8527 - val_auc: 0.9286\n",
      "68/68 [==============================] - 0s 985us/step - loss: 0.1071 - accuracy: 0.8527 - auc: 0.9286\n",
      "Epoch 1/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2500 - accuracy: 0.5029 - auc: 0.4961\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54894, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.5030 - auc: 0.4961 - val_loss: 0.2486 - val_accuracy: 0.5489 - val_auc: 0.5212\n",
      "Epoch 2/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.5347 - auc: 0.5513\n",
      "Epoch 2: val_accuracy did not improve from 0.54894\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2483 - accuracy: 0.5347 - auc: 0.5513 - val_loss: 0.2471 - val_accuracy: 0.5457 - val_auc: 0.5902\n",
      "Epoch 3/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.5346 - auc: 0.6345\n",
      "Epoch 3: val_accuracy did not improve from 0.54894\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2467 - accuracy: 0.5346 - auc: 0.6359 - val_loss: 0.2451 - val_accuracy: 0.5466 - val_auc: 0.6764\n",
      "Epoch 4/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.5421 - auc: 0.7424\n",
      "Epoch 4: val_accuracy improved from 0.54894 to 0.55956, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.5421 - auc: 0.7424 - val_loss: 0.2417 - val_accuracy: 0.5596 - val_auc: 0.7843\n",
      "Epoch 5/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 0.5855 - auc: 0.8320\n",
      "Epoch 5: val_accuracy improved from 0.55956 to 0.65928, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2388 - accuracy: 0.5865 - auc: 0.8323 - val_loss: 0.2349 - val_accuracy: 0.6593 - val_auc: 0.8442\n",
      "Epoch 6/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.7355 - auc: 0.8665\n",
      "Epoch 6: val_accuracy improved from 0.65928 to 0.79548, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2287 - accuracy: 0.7355 - auc: 0.8665 - val_loss: 0.2222 - val_accuracy: 0.7955 - val_auc: 0.8609\n",
      "Epoch 7/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2110 - accuracy: 0.8226 - auc: 0.8747\n",
      "Epoch 7: val_accuracy improved from 0.79548 to 0.82456, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2110 - accuracy: 0.8224 - auc: 0.8745 - val_loss: 0.2019 - val_accuracy: 0.8246 - val_auc: 0.8648\n",
      "Epoch 8/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.8411 - auc: 0.8782\n",
      "Epoch 8: val_accuracy improved from 0.82456 to 0.83195, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1866 - accuracy: 0.8416 - auc: 0.8787 - val_loss: 0.1776 - val_accuracy: 0.8319 - val_auc: 0.8669\n",
      "Epoch 9/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.1631 - accuracy: 0.8449 - auc: 0.8822\n",
      "Epoch 9: val_accuracy improved from 0.83195 to 0.83426, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1623 - accuracy: 0.8452 - auc: 0.8824 - val_loss: 0.1575 - val_accuracy: 0.8343 - val_auc: 0.8706\n",
      "Epoch 10/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.8456 - auc: 0.8856\n",
      "Epoch 10: val_accuracy improved from 0.83426 to 0.83610, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1447 - accuracy: 0.8464 - auc: 0.8863 - val_loss: 0.1443 - val_accuracy: 0.8361 - val_auc: 0.8744\n",
      "Epoch 11/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.8471 - auc: 0.8905\n",
      "Epoch 11: val_accuracy improved from 0.83610 to 0.83703, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.8467 - auc: 0.8903 - val_loss: 0.1365 - val_accuracy: 0.8370 - val_auc: 0.8786\n",
      "Epoch 12/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1272 - accuracy: 0.8476 - auc: 0.8949\n",
      "Epoch 12: val_accuracy improved from 0.83703 to 0.83841, saving model to \\saved_models3_2/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1272 - accuracy: 0.8475 - auc: 0.8948 - val_loss: 0.1317 - val_accuracy: 0.8384 - val_auc: 0.8826\n",
      "Epoch 13/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.1232 - accuracy: 0.8478 - auc: 0.8983\n",
      "Epoch 13: val_accuracy did not improve from 0.83841\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1233 - accuracy: 0.8476 - auc: 0.8981 - val_loss: 0.1288 - val_accuracy: 0.8380 - val_auc: 0.8865\n",
      "Epoch 14/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.8490 - auc: 0.9015\n",
      "Epoch 14: val_accuracy did not improve from 0.83841\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1208 - accuracy: 0.8483 - auc: 0.9012 - val_loss: 0.1270 - val_accuracy: 0.8375 - val_auc: 0.8895\n",
      "Epoch 15/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1190 - accuracy: 0.8488 - auc: 0.9040\n",
      "Epoch 15: val_accuracy did not improve from 0.83841\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.8487 - auc: 0.9040 - val_loss: 0.1258 - val_accuracy: 0.8380 - val_auc: 0.8928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 985us/step - loss: 0.1317 - accuracy: 0.8384 - auc: 0.8826\n",
      "Epoch 1/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.2437 - accuracy: 0.6213 - auc: 0.7158\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59926, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.6196 - auc: 0.7212 - val_loss: 0.2396 - val_accuracy: 0.5993 - val_auc: 0.8164\n",
      "Epoch 2/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.6552 - auc: 0.8543\n",
      "Epoch 2: val_accuracy improved from 0.59926 to 0.68236, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2328 - accuracy: 0.6552 - auc: 0.8545 - val_loss: 0.2280 - val_accuracy: 0.6824 - val_auc: 0.8525\n",
      "Epoch 3/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.7575 - auc: 0.8727\n",
      "Epoch 3: val_accuracy improved from 0.68236 to 0.77701, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2167 - accuracy: 0.7581 - auc: 0.8729 - val_loss: 0.2096 - val_accuracy: 0.7770 - val_auc: 0.8612\n",
      "Epoch 4/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1938 - accuracy: 0.8178 - auc: 0.8781\n",
      "Epoch 4: val_accuracy improved from 0.77701 to 0.80332, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1935 - accuracy: 0.8173 - auc: 0.8774 - val_loss: 0.1858 - val_accuracy: 0.8033 - val_auc: 0.8650\n",
      "Epoch 5/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1684 - accuracy: 0.8350 - auc: 0.8819\n",
      "Epoch 5: val_accuracy improved from 0.80332 to 0.81163, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.8350 - auc: 0.8817 - val_loss: 0.1644 - val_accuracy: 0.8116 - val_auc: 0.8683\n",
      "Epoch 6/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.8421 - auc: 0.8858\n",
      "Epoch 6: val_accuracy improved from 0.81163 to 0.81625, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1482 - accuracy: 0.8419 - auc: 0.8853 - val_loss: 0.1504 - val_accuracy: 0.8163 - val_auc: 0.8719\n",
      "Epoch 7/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.8459 - auc: 0.8902\n",
      "Epoch 7: val_accuracy improved from 0.81625 to 0.81764, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1354 - accuracy: 0.8456 - auc: 0.8899 - val_loss: 0.1427 - val_accuracy: 0.8176 - val_auc: 0.8751\n",
      "Epoch 8/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.8482 - auc: 0.8942\n",
      "Epoch 8: val_accuracy improved from 0.81764 to 0.81994, saving model to \\saved_models3_2/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1279 - accuracy: 0.8475 - auc: 0.8937 - val_loss: 0.1388 - val_accuracy: 0.8199 - val_auc: 0.8780\n",
      "Epoch 9/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1233 - accuracy: 0.8488 - auc: 0.8971\n",
      "Epoch 9: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.8484 - auc: 0.8969 - val_loss: 0.1368 - val_accuracy: 0.8190 - val_auc: 0.8813\n",
      "Epoch 10/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.8480 - auc: 0.9002\n",
      "Epoch 10: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1207 - accuracy: 0.8483 - auc: 0.9003 - val_loss: 0.1357 - val_accuracy: 0.8181 - val_auc: 0.8838\n",
      "Epoch 11/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1190 - accuracy: 0.8489 - auc: 0.9029\n",
      "Epoch 11: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.8490 - auc: 0.9030 - val_loss: 0.1352 - val_accuracy: 0.8176 - val_auc: 0.8860\n",
      "Epoch 12/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1177 - accuracy: 0.8488 - auc: 0.9052\n",
      "Epoch 12: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.8486 - auc: 0.9053 - val_loss: 0.1348 - val_accuracy: 0.8181 - val_auc: 0.8875\n",
      "Epoch 13/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1174 - accuracy: 0.8479 - auc: 0.9067\n",
      "Epoch 13: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.8488 - auc: 0.9072 - val_loss: 0.1345 - val_accuracy: 0.8181 - val_auc: 0.8891\n",
      "Epoch 14/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.8491 - auc: 0.9092\n",
      "Epoch 14: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.8490 - auc: 0.9090 - val_loss: 0.1342 - val_accuracy: 0.8167 - val_auc: 0.8907\n",
      "Epoch 15/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.8499 - auc: 0.9107\n",
      "Epoch 15: val_accuracy did not improve from 0.81994\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.8494 - auc: 0.9106 - val_loss: 0.1341 - val_accuracy: 0.8172 - val_auc: 0.8916\n",
      "68/68 [==============================] - 0s 956us/step - loss: 0.1388 - accuracy: 0.8199 - auc: 0.8780\n",
      "Epoch 1/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.5387 - auc: 0.5535\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55863, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2475 - accuracy: 0.5389 - auc: 0.5536 - val_loss: 0.2443 - val_accuracy: 0.5586 - val_auc: 0.6390\n",
      "Epoch 2/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.2407 - accuracy: 0.5740 - auc: 0.7094\n",
      "Epoch 2: val_accuracy improved from 0.55863 to 0.61450, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2406 - accuracy: 0.5750 - auc: 0.7117 - val_loss: 0.2359 - val_accuracy: 0.6145 - val_auc: 0.7658\n",
      "Epoch 3/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.6617 - auc: 0.7998\n",
      "Epoch 3: val_accuracy improved from 0.61450 to 0.72669, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2297 - accuracy: 0.6622 - auc: 0.8001 - val_loss: 0.2218 - val_accuracy: 0.7267 - val_auc: 0.8257\n",
      "Epoch 4/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.7540 - auc: 0.8393\n",
      "Epoch 4: val_accuracy improved from 0.72669 to 0.79363, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2123 - accuracy: 0.7545 - auc: 0.8394 - val_loss: 0.2007 - val_accuracy: 0.7936 - val_auc: 0.8507\n",
      "Epoch 5/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.8013 - auc: 0.8589\n",
      "Epoch 5: val_accuracy improved from 0.79363 to 0.82410, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1896 - accuracy: 0.8016 - auc: 0.8590 - val_loss: 0.1768 - val_accuracy: 0.8241 - val_auc: 0.8665\n",
      "Epoch 6/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1675 - accuracy: 0.8211 - auc: 0.8723\n",
      "Epoch 6: val_accuracy improved from 0.82410 to 0.83610, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1672 - accuracy: 0.8216 - auc: 0.8729 - val_loss: 0.1562 - val_accuracy: 0.8361 - val_auc: 0.8778\n",
      "Epoch 7/15\n",
      "572/610 [===========================>..] - ETA: 0s - loss: 0.1499 - accuracy: 0.8351 - auc: 0.8815\n",
      "Epoch 7: val_accuracy improved from 0.83610 to 0.84349, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.8351 - auc: 0.8813 - val_loss: 0.1415 - val_accuracy: 0.8435 - val_auc: 0.8851\n",
      "Epoch 8/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1378 - accuracy: 0.8404 - auc: 0.8876\n",
      "Epoch 8: val_accuracy improved from 0.84349 to 0.84672, saving model to \\saved_models3_2/model_5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1377 - accuracy: 0.8400 - auc: 0.8874 - val_loss: 0.1319 - val_accuracy: 0.8467 - val_auc: 0.8903\n",
      "Epoch 9/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.8427 - auc: 0.8912\n",
      "Epoch 9: val_accuracy improved from 0.84672 to 0.84903, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1302 - accuracy: 0.8432 - auc: 0.8917 - val_loss: 0.1258 - val_accuracy: 0.8490 - val_auc: 0.8945\n",
      "Epoch 10/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.8447 - auc: 0.8953\n",
      "Epoch 10: val_accuracy improved from 0.84903 to 0.84995, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1256 - accuracy: 0.8445 - auc: 0.8954 - val_loss: 0.1221 - val_accuracy: 0.8500 - val_auc: 0.8984\n",
      "Epoch 11/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.8452 - auc: 0.8987\n",
      "Epoch 11: val_accuracy did not improve from 0.84995\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1228 - accuracy: 0.8449 - auc: 0.8985 - val_loss: 0.1196 - val_accuracy: 0.8486 - val_auc: 0.9012\n",
      "Epoch 12/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.8453 - auc: 0.9014\n",
      "Epoch 12: val_accuracy did not improve from 0.84995\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1209 - accuracy: 0.8453 - auc: 0.9013 - val_loss: 0.1179 - val_accuracy: 0.8495 - val_auc: 0.9041\n",
      "Epoch 13/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1197 - accuracy: 0.8459 - auc: 0.9037\n",
      "Epoch 13: val_accuracy did not improve from 0.84995\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.8460 - auc: 0.9040 - val_loss: 0.1166 - val_accuracy: 0.8495 - val_auc: 0.9066\n",
      "Epoch 14/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 0.8464 - auc: 0.9060\n",
      "Epoch 14: val_accuracy improved from 0.84995 to 0.85088, saving model to \\saved_models3_2/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.8461 - auc: 0.9062 - val_loss: 0.1157 - val_accuracy: 0.8509 - val_auc: 0.9085\n",
      "Epoch 15/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.8462 - auc: 0.9081\n",
      "Epoch 15: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1179 - accuracy: 0.8462 - auc: 0.9081 - val_loss: 0.1149 - val_accuracy: 0.8504 - val_auc: 0.9103\n",
      "68/68 [==============================] - 0s 994us/step - loss: 0.1157 - accuracy: 0.8509 - auc: 0.9085\n",
      "Epoch 1/15\n",
      "566/610 [==========================>...] - ETA: 0s - loss: 0.2473 - accuracy: 0.5686 - auc: 0.5955\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56464, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.5698 - auc: 0.6002 - val_loss: 0.2451 - val_accuracy: 0.5646 - val_auc: 0.6754\n",
      "Epoch 2/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2419 - accuracy: 0.6005 - auc: 0.7307\n",
      "Epoch 2: val_accuracy improved from 0.56464 to 0.61819, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2419 - accuracy: 0.6008 - auc: 0.7311 - val_loss: 0.2392 - val_accuracy: 0.6182 - val_auc: 0.7760\n",
      "Epoch 3/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.2335 - accuracy: 0.6774 - auc: 0.8091\n",
      "Epoch 3: val_accuracy improved from 0.61819 to 0.73084, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2332 - accuracy: 0.6797 - auc: 0.8106 - val_loss: 0.2276 - val_accuracy: 0.7308 - val_auc: 0.8321\n",
      "Epoch 4/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.7661 - auc: 0.8468\n",
      "Epoch 4: val_accuracy improved from 0.73084 to 0.77239, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2165 - accuracy: 0.7662 - auc: 0.8472 - val_loss: 0.2055 - val_accuracy: 0.7724 - val_auc: 0.8559\n",
      "Epoch 5/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.7873 - auc: 0.8625\n",
      "Epoch 5: val_accuracy improved from 0.77239 to 0.79732, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1877 - accuracy: 0.7873 - auc: 0.8622 - val_loss: 0.1721 - val_accuracy: 0.7973 - val_auc: 0.8696\n",
      "Epoch 6/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1560 - accuracy: 0.8009 - auc: 0.8786\n",
      "Epoch 6: val_accuracy improved from 0.79732 to 0.81487, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1556 - accuracy: 0.8014 - auc: 0.8790 - val_loss: 0.1444 - val_accuracy: 0.8149 - val_auc: 0.8861\n",
      "Epoch 7/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.8190 - auc: 0.8955\n",
      "Epoch 7: val_accuracy improved from 0.81487 to 0.83426, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1350 - accuracy: 0.8192 - auc: 0.8955 - val_loss: 0.1294 - val_accuracy: 0.8343 - val_auc: 0.8997\n",
      "Epoch 8/15\n",
      "590/610 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.8307 - auc: 0.9073\n",
      "Epoch 8: val_accuracy improved from 0.83426 to 0.84303, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.8300 - auc: 0.9066 - val_loss: 0.1215 - val_accuracy: 0.8430 - val_auc: 0.9081\n",
      "Epoch 9/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.8385 - auc: 0.9137\n",
      "Epoch 9: val_accuracy improved from 0.84303 to 0.84718, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.8382 - auc: 0.9138 - val_loss: 0.1172 - val_accuracy: 0.8472 - val_auc: 0.9137\n",
      "Epoch 10/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.1141 - accuracy: 0.8425 - auc: 0.9186\n",
      "Epoch 10: val_accuracy did not improve from 0.84718\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.8427 - auc: 0.9185 - val_loss: 0.1145 - val_accuracy: 0.8453 - val_auc: 0.9173\n",
      "Epoch 11/15\n",
      "576/610 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.8441 - auc: 0.9213\n",
      "Epoch 11: val_accuracy did not improve from 0.84718\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8452 - auc: 0.9222 - val_loss: 0.1124 - val_accuracy: 0.8467 - val_auc: 0.9203\n",
      "Epoch 12/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1095 - accuracy: 0.8489 - auc: 0.9249\n",
      "Epoch 12: val_accuracy improved from 0.84718 to 0.84811, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.8485 - auc: 0.9246 - val_loss: 0.1113 - val_accuracy: 0.8481 - val_auc: 0.9222\n",
      "Epoch 13/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1085 - accuracy: 0.8498 - auc: 0.9266\n",
      "Epoch 13: val_accuracy did not improve from 0.84811\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.8498 - auc: 0.9266 - val_loss: 0.1103 - val_accuracy: 0.8476 - val_auc: 0.9240\n",
      "Epoch 14/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.8506 - auc: 0.9282\n",
      "Epoch 14: val_accuracy improved from 0.84811 to 0.84903, saving model to \\saved_models3_2/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1073 - accuracy: 0.8506 - auc: 0.9282 - val_loss: 0.1095 - val_accuracy: 0.8490 - val_auc: 0.9246\n",
      "Epoch 15/15\n",
      "587/610 [===========================>..] - ETA: 0s - loss: 0.1064 - accuracy: 0.8519 - auc: 0.9290\n",
      "Epoch 15: val_accuracy did not improve from 0.84903\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.8521 - auc: 0.9293 - val_loss: 0.1087 - val_accuracy: 0.8481 - val_auc: 0.9265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8490 - auc: 0.9246\n",
      "Epoch 1/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.2465 - accuracy: 0.5480 - auc: 0.6092\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57618, saving model to \\saved_models3_2/model_7.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2464 - accuracy: 0.5480 - auc: 0.6136 - val_loss: 0.2418 - val_accuracy: 0.5762 - val_auc: 0.7484\n",
      "Epoch 2/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.2377 - accuracy: 0.6209 - auc: 0.8204\n",
      "Epoch 2: val_accuracy improved from 0.57618 to 0.67267, saving model to \\saved_models3_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2375 - accuracy: 0.6234 - auc: 0.8215 - val_loss: 0.2313 - val_accuracy: 0.6727 - val_auc: 0.8560\n",
      "Epoch 3/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.7489 - auc: 0.8664\n",
      "Epoch 3: val_accuracy improved from 0.67267 to 0.80886, saving model to \\saved_models3_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2243 - accuracy: 0.7496 - auc: 0.8662 - val_loss: 0.2148 - val_accuracy: 0.8089 - val_auc: 0.8721\n",
      "Epoch 4/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.2050 - accuracy: 0.8310 - auc: 0.8708\n",
      "Epoch 4: val_accuracy improved from 0.80886 to 0.84857, saving model to \\saved_models3_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2043 - accuracy: 0.8323 - auc: 0.8717 - val_loss: 0.1917 - val_accuracy: 0.8486 - val_auc: 0.8751\n",
      "Epoch 5/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1802 - accuracy: 0.8463 - auc: 0.8726\n",
      "Epoch 5: val_accuracy improved from 0.84857 to 0.85134, saving model to \\saved_models3_2/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1801 - accuracy: 0.8466 - auc: 0.8727 - val_loss: 0.1674 - val_accuracy: 0.8513 - val_auc: 0.8759\n",
      "Epoch 6/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.8468 - auc: 0.8731\n",
      "Epoch 6: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1584 - accuracy: 0.8471 - auc: 0.8735 - val_loss: 0.1489 - val_accuracy: 0.8509 - val_auc: 0.8763\n",
      "Epoch 7/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.8471 - auc: 0.8749\n",
      "Epoch 7: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1437 - accuracy: 0.8470 - auc: 0.8746 - val_loss: 0.1376 - val_accuracy: 0.8504 - val_auc: 0.8772\n",
      "Epoch 8/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.8470 - auc: 0.8756\n",
      "Epoch 8: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1351 - accuracy: 0.8471 - auc: 0.8753 - val_loss: 0.1312 - val_accuracy: 0.8500 - val_auc: 0.8783\n",
      "Epoch 9/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.8473 - auc: 0.8768\n",
      "Epoch 9: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1303 - accuracy: 0.8472 - auc: 0.8768 - val_loss: 0.1277 - val_accuracy: 0.8495 - val_auc: 0.8799\n",
      "Epoch 10/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.8467 - auc: 0.8780\n",
      "Epoch 10: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1276 - accuracy: 0.8470 - auc: 0.8786 - val_loss: 0.1256 - val_accuracy: 0.8495 - val_auc: 0.8811\n",
      "Epoch 11/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.8473 - auc: 0.8803\n",
      "Epoch 11: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1260 - accuracy: 0.8472 - auc: 0.8799 - val_loss: 0.1243 - val_accuracy: 0.8495 - val_auc: 0.8821\n",
      "Epoch 12/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1249 - accuracy: 0.8474 - auc: 0.8808\n",
      "Epoch 12: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1249 - accuracy: 0.8473 - auc: 0.8809 - val_loss: 0.1235 - val_accuracy: 0.8495 - val_auc: 0.8830\n",
      "Epoch 13/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1244 - accuracy: 0.8475 - auc: 0.8824\n",
      "Epoch 13: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1243 - accuracy: 0.8477 - auc: 0.8825 - val_loss: 0.1230 - val_accuracy: 0.8486 - val_auc: 0.8841\n",
      "Epoch 14/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.8482 - auc: 0.8839\n",
      "Epoch 14: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1238 - accuracy: 0.8478 - auc: 0.8833 - val_loss: 0.1227 - val_accuracy: 0.8486 - val_auc: 0.8848\n",
      "Epoch 15/15\n",
      "595/610 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.8474 - auc: 0.8836\n",
      "Epoch 15: val_accuracy did not improve from 0.85134\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.8479 - auc: 0.8839 - val_loss: 0.1224 - val_accuracy: 0.8481 - val_auc: 0.8852\n",
      "68/68 [==============================] - 0s 974us/step - loss: 0.1674 - accuracy: 0.8513 - auc: 0.8759\n",
      "Epoch 1/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2441 - accuracy: 0.5500 - auc: 0.6418\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54801, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.5496 - auc: 0.6422 - val_loss: 0.2401 - val_accuracy: 0.5480 - val_auc: 0.7222\n",
      "Epoch 2/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.6057 - auc: 0.7498\n",
      "Epoch 2: val_accuracy improved from 0.54801 to 0.66851, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2323 - accuracy: 0.6069 - auc: 0.7500 - val_loss: 0.2250 - val_accuracy: 0.6685 - val_auc: 0.7791\n",
      "Epoch 3/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.7095 - auc: 0.7970\n",
      "Epoch 3: val_accuracy improved from 0.66851 to 0.74146, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2122 - accuracy: 0.7101 - auc: 0.7977 - val_loss: 0.2002 - val_accuracy: 0.7415 - val_auc: 0.8217\n",
      "Epoch 4/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1864 - accuracy: 0.7568 - auc: 0.8348\n",
      "Epoch 4: val_accuracy improved from 0.74146 to 0.77285, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1855 - accuracy: 0.7575 - auc: 0.8357 - val_loss: 0.1722 - val_accuracy: 0.7729 - val_auc: 0.8547\n",
      "Epoch 5/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.7848 - auc: 0.8675\n",
      "Epoch 5: val_accuracy improved from 0.77285 to 0.79501, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1587 - accuracy: 0.7852 - auc: 0.8677 - val_loss: 0.1469 - val_accuracy: 0.7950 - val_auc: 0.8845\n",
      "Epoch 6/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1392 - accuracy: 0.8070 - auc: 0.8901\n",
      "Epoch 6: val_accuracy improved from 0.79501 to 0.81671, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1389 - accuracy: 0.8074 - auc: 0.8903 - val_loss: 0.1295 - val_accuracy: 0.8167 - val_auc: 0.9046\n",
      "Epoch 7/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1275 - accuracy: 0.8216 - auc: 0.9041\n",
      "Epoch 7: val_accuracy improved from 0.81671 to 0.83195, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1275 - accuracy: 0.8210 - auc: 0.9041 - val_loss: 0.1204 - val_accuracy: 0.8319 - val_auc: 0.9161\n",
      "Epoch 8/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.8296 - auc: 0.9129\n",
      "Epoch 8: val_accuracy improved from 0.83195 to 0.83610, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1205 - accuracy: 0.8296 - auc: 0.9129 - val_loss: 0.1135 - val_accuracy: 0.8361 - val_auc: 0.9236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.8346 - auc: 0.9188\n",
      "Epoch 9: val_accuracy improved from 0.83610 to 0.84580, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1159 - accuracy: 0.8346 - auc: 0.9188 - val_loss: 0.1092 - val_accuracy: 0.8458 - val_auc: 0.9287\n",
      "Epoch 10/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.8405 - auc: 0.9235\n",
      "Epoch 10: val_accuracy improved from 0.84580 to 0.85134, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1124 - accuracy: 0.8399 - auc: 0.9232 - val_loss: 0.1062 - val_accuracy: 0.8513 - val_auc: 0.9330\n",
      "Epoch 11/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.8441 - auc: 0.9268\n",
      "Epoch 11: val_accuracy improved from 0.85134 to 0.85319, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.8447 - auc: 0.9269 - val_loss: 0.1037 - val_accuracy: 0.8532 - val_auc: 0.9358\n",
      "Epoch 12/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.8477 - auc: 0.9302\n",
      "Epoch 12: val_accuracy did not improve from 0.85319\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.8477 - auc: 0.9302 - val_loss: 0.1014 - val_accuracy: 0.8509 - val_auc: 0.9387\n",
      "Epoch 13/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.8520 - auc: 0.9333\n",
      "Epoch 13: val_accuracy did not improve from 0.85319\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.8520 - auc: 0.9333 - val_loss: 0.0988 - val_accuracy: 0.8532 - val_auc: 0.9413\n",
      "Epoch 14/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 0.8542 - auc: 0.9366\n",
      "Epoch 14: val_accuracy improved from 0.85319 to 0.85457, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.8540 - auc: 0.9365 - val_loss: 0.0972 - val_accuracy: 0.8546 - val_auc: 0.9439\n",
      "Epoch 15/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.8585 - auc: 0.9400\n",
      "Epoch 15: val_accuracy improved from 0.85457 to 0.85549, saving model to \\saved_models3_2/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.8586 - auc: 0.9400 - val_loss: 0.0965 - val_accuracy: 0.8555 - val_auc: 0.9468\n",
      "68/68 [==============================] - 0s 982us/step - loss: 0.0965 - accuracy: 0.8555 - auc: 0.9468\n",
      "Epoch 1/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.5299 - auc: 0.5328\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58476, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 2s 2ms/step - loss: 0.2491 - accuracy: 0.5295 - auc: 0.5329 - val_loss: 0.2469 - val_accuracy: 0.5848 - val_auc: 0.6254\n",
      "Epoch 2/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2446 - accuracy: 0.5814 - auc: 0.7343\n",
      "Epoch 2: val_accuracy improved from 0.58476 to 0.59954, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.5808 - auc: 0.7349 - val_loss: 0.2417 - val_accuracy: 0.5995 - val_auc: 0.7989\n",
      "Epoch 3/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.6364 - auc: 0.8448\n",
      "Epoch 3: val_accuracy improved from 0.59954 to 0.69561, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2384 - accuracy: 0.6389 - auc: 0.8462 - val_loss: 0.2335 - val_accuracy: 0.6956 - val_auc: 0.8696\n",
      "Epoch 4/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.7649 - auc: 0.8722\n",
      "Epoch 4: val_accuracy improved from 0.69561 to 0.80739, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2276 - accuracy: 0.7667 - auc: 0.8731 - val_loss: 0.2191 - val_accuracy: 0.8074 - val_auc: 0.8852\n",
      "Epoch 5/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.8285 - auc: 0.8783\n",
      "Epoch 5: val_accuracy improved from 0.80739 to 0.84203, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2094 - accuracy: 0.8286 - auc: 0.8780 - val_loss: 0.1963 - val_accuracy: 0.8420 - val_auc: 0.8887\n",
      "Epoch 6/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1845 - accuracy: 0.8439 - auc: 0.8837\n",
      "Epoch 6: val_accuracy improved from 0.84203 to 0.84527, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1843 - accuracy: 0.8426 - auc: 0.8816 - val_loss: 0.1693 - val_accuracy: 0.8453 - val_auc: 0.8914\n",
      "Epoch 7/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.8416 - auc: 0.8845\n",
      "Epoch 7: val_accuracy did not improve from 0.84527\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1598 - accuracy: 0.8421 - auc: 0.8848 - val_loss: 0.1474 - val_accuracy: 0.8443 - val_auc: 0.8953\n",
      "Epoch 8/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.8423 - auc: 0.8903\n",
      "Epoch 8: val_accuracy improved from 0.84527 to 0.84850, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1424 - accuracy: 0.8427 - auc: 0.8905 - val_loss: 0.1333 - val_accuracy: 0.8485 - val_auc: 0.8997\n",
      "Epoch 9/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.8440 - auc: 0.8949\n",
      "Epoch 9: val_accuracy improved from 0.84850 to 0.84988, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1320 - accuracy: 0.8441 - auc: 0.8952 - val_loss: 0.1250 - val_accuracy: 0.8499 - val_auc: 0.9039\n",
      "Epoch 10/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.8450 - auc: 0.8996\n",
      "Epoch 10: val_accuracy improved from 0.84988 to 0.85081, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1259 - accuracy: 0.8446 - auc: 0.8990 - val_loss: 0.1200 - val_accuracy: 0.8508 - val_auc: 0.9079\n",
      "Epoch 11/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.8451 - auc: 0.9029\n",
      "Epoch 11: val_accuracy improved from 0.85081 to 0.85219, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.8449 - auc: 0.9027 - val_loss: 0.1169 - val_accuracy: 0.8522 - val_auc: 0.9108\n",
      "Epoch 12/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.8449 - auc: 0.9055\n",
      "Epoch 12: val_accuracy improved from 0.85219 to 0.85312, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.8452 - auc: 0.9058 - val_loss: 0.1150 - val_accuracy: 0.8531 - val_auc: 0.9133\n",
      "Epoch 13/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1180 - accuracy: 0.8457 - auc: 0.9092\n",
      "Epoch 13: val_accuracy improved from 0.85312 to 0.85358, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.8456 - auc: 0.9085 - val_loss: 0.1132 - val_accuracy: 0.8536 - val_auc: 0.9152\n",
      "Epoch 14/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.8458 - auc: 0.9107\n",
      "Epoch 14: val_accuracy did not improve from 0.85358\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.8458 - auc: 0.9105 - val_loss: 0.1125 - val_accuracy: 0.8531 - val_auc: 0.9170\n",
      "Epoch 15/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.8457 - auc: 0.9122\n",
      "Epoch 15: val_accuracy improved from 0.85358 to 0.85404, saving model to \\saved_models3_2/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.8460 - auc: 0.9123 - val_loss: 0.1114 - val_accuracy: 0.8540 - val_auc: 0.9185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.8540 - auc: 0.9185\n",
      "Epoch 1/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.5259 - auc: 0.4752\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53995, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.5259 - auc: 0.4753 - val_loss: 0.2480 - val_accuracy: 0.5400 - val_auc: 0.5287\n",
      "Epoch 2/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.5388 - auc: 0.5891\n",
      "Epoch 2: val_accuracy improved from 0.53995 to 0.54688, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2470 - accuracy: 0.5392 - auc: 0.5908 - val_loss: 0.2449 - val_accuracy: 0.5469 - val_auc: 0.6480\n",
      "Epoch 3/15\n",
      "584/610 [===========================>..] - ETA: 0s - loss: 0.2435 - accuracy: 0.5469 - auc: 0.7108\n",
      "Epoch 3: val_accuracy improved from 0.54688 to 0.57413, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.5483 - auc: 0.7138 - val_loss: 0.2403 - val_accuracy: 0.5741 - val_auc: 0.7711\n",
      "Epoch 4/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2371 - accuracy: 0.6070 - auc: 0.8119\n",
      "Epoch 4: val_accuracy improved from 0.57413 to 0.66882, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2370 - accuracy: 0.6080 - auc: 0.8131 - val_loss: 0.2318 - val_accuracy: 0.6688 - val_auc: 0.8474\n",
      "Epoch 5/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.7212 - auc: 0.8587\n",
      "Epoch 5: val_accuracy improved from 0.66882 to 0.76028, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2257 - accuracy: 0.7222 - auc: 0.8592 - val_loss: 0.2170 - val_accuracy: 0.7603 - val_auc: 0.8734\n",
      "Epoch 6/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.7812 - auc: 0.8730\n",
      "Epoch 6: val_accuracy improved from 0.76028 to 0.81848, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2075 - accuracy: 0.7813 - auc: 0.8730 - val_loss: 0.1951 - val_accuracy: 0.8185 - val_auc: 0.8819\n",
      "Epoch 7/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1848 - accuracy: 0.8211 - auc: 0.8767\n",
      "Epoch 7: val_accuracy improved from 0.81848 to 0.84249, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1839 - accuracy: 0.8224 - auc: 0.8779 - val_loss: 0.1704 - val_accuracy: 0.8425 - val_auc: 0.8858\n",
      "Epoch 8/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.8385 - auc: 0.8818\n",
      "Epoch 8: val_accuracy improved from 0.84249 to 0.84711, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1615 - accuracy: 0.8388 - auc: 0.8816 - val_loss: 0.1501 - val_accuracy: 0.8471 - val_auc: 0.8893\n",
      "Epoch 9/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.8425 - auc: 0.8838\n",
      "Epoch 9: val_accuracy improved from 0.84711 to 0.85081, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.8429 - auc: 0.8840 - val_loss: 0.1365 - val_accuracy: 0.8508 - val_auc: 0.8922\n",
      "Epoch 10/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.8452 - auc: 0.8879\n",
      "Epoch 10: val_accuracy improved from 0.85081 to 0.85127, saving model to \\saved_models3_2/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1349 - accuracy: 0.8452 - auc: 0.8879 - val_loss: 0.1283 - val_accuracy: 0.8513 - val_auc: 0.8953\n",
      "Epoch 11/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.8459 - auc: 0.8909\n",
      "Epoch 11: val_accuracy did not improve from 0.85127\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1289 - accuracy: 0.8457 - auc: 0.8911 - val_loss: 0.1233 - val_accuracy: 0.8503 - val_auc: 0.8983\n",
      "Epoch 12/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 0.8465 - auc: 0.8939\n",
      "Epoch 12: val_accuracy did not improve from 0.85127\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1253 - accuracy: 0.8464 - auc: 0.8938 - val_loss: 0.1203 - val_accuracy: 0.8499 - val_auc: 0.9007\n",
      "Epoch 13/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.8464 - auc: 0.8963\n",
      "Epoch 13: val_accuracy did not improve from 0.85127\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1231 - accuracy: 0.8466 - auc: 0.8964 - val_loss: 0.1183 - val_accuracy: 0.8499 - val_auc: 0.9032\n",
      "Epoch 14/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 0.8463 - auc: 0.8991\n",
      "Epoch 14: val_accuracy did not improve from 0.85127\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1216 - accuracy: 0.8465 - auc: 0.8992 - val_loss: 0.1170 - val_accuracy: 0.8508 - val_auc: 0.9054\n",
      "Epoch 15/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1203 - accuracy: 0.8467 - auc: 0.9016\n",
      "Epoch 15: val_accuracy did not improve from 0.85127\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1206 - accuracy: 0.8464 - auc: 0.9010 - val_loss: 0.1159 - val_accuracy: 0.8499 - val_auc: 0.9072\n",
      "68/68 [==============================] - 0s 928us/step - loss: 0.1283 - accuracy: 0.8513 - auc: 0.8953\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY32 = []\n",
    "VALIDATION_AUC32 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "    \n",
    "    # get crossed columns\n",
    "    X_train_crossed = training_data[cross_col_df_names3].to_numpy()\n",
    "    X_test_crossed = validation_data[cross_col_df_names3].to_numpy()\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "    \n",
    "    # we need to create separate lists for each branch\n",
    "    crossed_outputs = []\n",
    "\n",
    "    # CROSSED DATA INPUT\n",
    "    input_crossed = Input(shape=(X_train_crossed.shape[1],), dtype='int64', name='wide_inputs')\n",
    "    for idx,col in enumerate(cross_col_df_names3):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_crossed, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        crossed_outputs.append(x)\n",
    "    \n",
    "\n",
    "    # now concatenate the outputs and add a fully connected layer\n",
    "    wide_branch = concatenate(crossed_outputs, name='wide_concat')\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep4')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep5')(deep_branch) # added this\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([wide_branch, deep_branch], name='concat_deep_wide')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model32 = Model(inputs=[input_crossed,input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model32.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models3_2/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history32 = model32.fit([X_train_crossed,X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_crossed,X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model32.load_weights(\"\\saved_models3_2/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model32.evaluate([X_test_crossed,X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model32.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY32.append(results['accuracy'])\n",
    "    VALIDATION_AUC32.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history32.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history32.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history32.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history32.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8448753356933594 | 0.8965986967086792 |\n",
      "|  2   | 0.8527238965034485 | 0.9286008477210999 |\n",
      "|  3   | 0.838411808013916  | 0.8826268315315247 |\n",
      "|  4   | 0.8199446201324463 | 0.8779594302177429 |\n",
      "|  5   | 0.8508771657943726 | 0.9084621667861938 |\n",
      "|  6   | 0.8490304946899414 | 0.9246453046798706 |\n",
      "|  7   | 0.8513388633728027 | 0.8759147524833679 |\n",
      "|  8   | 0.8554940223693848 | 0.9467926025390625 |\n",
      "|  9   | 0.854041576385498  | 0.9185490608215332 |\n",
      "|  10  | 0.8512701988220215 | 0.8952521085739136 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY32)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC32)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 8\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY32.index(max(VALIDATION_ACCURACY32))\n",
    "max_fold32 = idx + 1\n",
    "print(\"Best Fold:\", max_fold32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.7933 - auc: 0.8885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13892950117588043, 0.7932621240615845, 0.8885258436203003]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model32.load_weights(\"\\saved_models3_2/model_\"+str(max_fold32)+\".h5\")\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model32.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 901us/step\n",
      "[[2265  847]\n",
      " [ 546 3080]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3080"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_proba = model32.predict([X_test_crossed, X_test_cat, X_test_num])\n",
    "yhat32 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Generalization Performance for W/D 3 - McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd3 = pd.DataFrame()\n",
    "wd3['Deep'] = list(chain.from_iterable(yhat3))\n",
    "wd3['Deeper'] = list(chain.from_iterable(yhat31))\n",
    "wd3['Deepest'] = list(chain.from_iterable(yhat32))\n",
    "wd3['Truth'] = list(chain.from_iterable(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5098\n",
       "D     954\n",
       "B     366\n",
       "C     320\n",
       "Name: Matrix1v2, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd3['Deep'] == wd3['Truth']) & (wd3['Deeper'] == wd3['Truth']), # both models are right (A)\n",
    "    (wd3['Deep'] == wd3['Truth']) & (wd3['Deeper'] != wd3['Truth']), # model 1 is right, model 2 is wrong (B)\n",
    "    (wd3['Deep'] != wd3['Truth']) & (wd3['Deeper'] == wd3['Truth']), # model 1 is wrong, model 2 is right (C)\n",
    "    (wd3['Deep'] != wd3['Truth']) & (wd3['Deeper'] != wd3['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd3['Matrix1v2'] = np.select(conditions, choices, default = '0')\n",
    "wd3.Matrix1v2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.952\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd3['Matrix1v2'] == 'B')\n",
    "C = sum(wd3['Matrix1v2'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2.952 < 3.841 ($\\alpha$ = 0.05 significance level), we fail to reject the null hypothesis that the models are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5035\n",
       "D     964\n",
       "B     429\n",
       "C     310\n",
       "Name: Matrix1v3, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd3['Deep'] == wd3['Truth']) & (wd3['Deepest'] == wd3['Truth']), # both models are right (A)\n",
    "    (wd3['Deep'] == wd3['Truth']) & (wd3['Deepest'] != wd3['Truth']), # model 1 is right, model 2 is wrong (B)\n",
    "    (wd3['Deep'] != wd3['Truth']) & (wd3['Deepest'] == wd3['Truth']), # model 1 is wrong, model 2 is right (C)\n",
    "    (wd3['Deep'] != wd3['Truth']) & (wd3['Deepest'] != wd3['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd3['Matrix1v3'] = np.select(conditions, choices, default = '0')\n",
    "wd3.Matrix1v3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.842\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd3['Matrix1v3'] == 'B')\n",
    "C = sum(wd3['Matrix1v3'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 18.842 > 3.841 ($\\alpha$ = 0.05 significance level), there is sufficient evidence to reject the null hypothesis that the models are the same and conclude that the Deep and Deepest Models of Network 3 are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      3112\n",
      "           1       0.82      0.82      0.82      3626\n",
      "\n",
      "    accuracy                           0.81      6738\n",
      "   macro avg       0.81      0.81      0.81      6738\n",
      "weighted avg       0.81      0.81      0.81      6738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.76      3112\n",
      "           1       0.78      0.85      0.82      3626\n",
      "\n",
      "    accuracy                           0.79      6738\n",
      "   macro avg       0.80      0.79      0.79      6738\n",
      "weighted avg       0.79      0.79      0.79      6738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mt.classification_report(y_test,yhat3))\n",
    "print(mt.classification_report(y_test,yhat32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of accuracy, the more shallow model (WD 3) is better than the model with two additional deep layers (WD 3.2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Best Wide and Deep Network\n",
    "\n",
    "#### (According to McNemar's Test)\n",
    "\n",
    "Since the networks with the least layers performed the best in cases 1 and 3, we will compare the original 3 against each other to determine which one is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd = pd.DataFrame()\n",
    "wd['Model 1'] = list(chain.from_iterable(yhat1))\n",
    "wd['Model 2'] = list(chain.from_iterable(yhat2))\n",
    "wd['Model 3'] = list(chain.from_iterable(yhat3))\n",
    "wd['Truth'] = list(chain.from_iterable(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1 vs. Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5055\n",
       "D     934\n",
       "B     408\n",
       "C     341\n",
       "Name: Matrix1v2, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd['Model 1'] == wd['Truth']) & (wd['Model 2'] == wd['Truth']), # both models are right (A)\n",
    "    (wd['Model 1'] == wd['Truth']) & (wd['Model 2'] != wd['Truth']), # model 1 is right, model 2 is wrong (B)\n",
    "    (wd['Model 1'] != wd['Truth']) & (wd['Model 2'] == wd['Truth']), # model 1 is wrong, model 2 is right (C)\n",
    "    (wd['Model 1'] != wd['Truth']) & (wd['Model 2'] != wd['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd['Matrix1v2'] = np.select(conditions, choices, default = '0')\n",
    "wd.Matrix1v2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.816\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd['Matrix1v2'] == 'B')\n",
    "C = sum(wd['Matrix1v2'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 5.816 > 3.841 ($\\alpha$ = 0.05 significance level), there is sufficient evidence to reject the null hypothesis that the models are the same and conclude that Network 1 and Network 2 are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1 vs. Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5152\n",
       "D     793\n",
       "C     312\n",
       "B     311\n",
       "0     170\n",
       "Name: Matrix1v3, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd['Model 1'] == wd['Truth']) & (wd['Model 3'] == wd['Truth']), # both models are right (A)\n",
    "    (wd['Model 1'] == wd['Truth']) & (wd['Model 3'] != wd['Truth']), # model 1 is right, model 3 is wrong (B)\n",
    "    (wd['Model 1'] != wd['Truth']) & (wd['Model 3'] == wd['Truth']), # model 1 is wrong, model 3 is right (C)\n",
    "    (wd['Model 1'] != wd['Truth']) & (wd['Model 2'] != wd['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd['Matrix1v3'] = np.select(conditions, choices, default = '0')\n",
    "wd.Matrix1v3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd['Matrix1v3'] == 'B')\n",
    "C = sum(wd['Matrix1v3'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 0.0 < 3.841 ($\\alpha$ = 0.05 significance level), we fail to reject the null hypothesis that the models are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    5152\n",
       "D     793\n",
       "C     312\n",
       "B     311\n",
       "0     170\n",
       "Name: Matrix1v3, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (wd['Model 2'] == wd['Truth']) & (wd['Model 3'] == wd['Truth']), # both models are right (A)\n",
    "    (wd['Model 2'] == wd['Truth']) & (wd['Model 3'] != wd['Truth']), # model 2 is right, model 3 is wrong (B)\n",
    "    (wd['Model 2'] != wd['Truth']) & (wd['Model 3'] == wd['Truth']), # model 2 is wrong, model 3 is right (C)\n",
    "    (wd['Model 2'] != wd['Truth']) & (wd['Model 2'] != wd['Truth'])] # both models are wrong (D)\n",
    "choices = ['A', 'B', 'C', 'D'] \n",
    "\n",
    "wd['Matrix2v3'] = np.select(conditions, choices, default = '0')\n",
    "wd.Matrix1v3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.985\n"
     ]
    }
   ],
   "source": [
    "B = sum(wd['Matrix2v3'] == 'B')\n",
    "C = sum(wd['Matrix2v3'] == 'C')\n",
    "chisq = (abs(B - C) - 1)**2 / (B + C)\n",
    "print(round(chisq, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 5.985 > 3.841 ($\\alpha$ = 0.05 significance level), there is sufficient evidence to reject the null hypothesis that the models are the same and conclude that Network 2 and Network 3 are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      3112\n",
      "           1       0.82      0.83      0.82      3626\n",
      "\n",
      "    accuracy                           0.81      6738\n",
      "   macro avg       0.81      0.81      0.81      6738\n",
      "weighted avg       0.81      0.81      0.81      6738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      3112\n",
      "           1       0.80      0.85      0.82      3626\n",
      "\n",
      "    accuracy                           0.80      6738\n",
      "   macro avg       0.80      0.80      0.80      6738\n",
      "weighted avg       0.80      0.80      0.80      6738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      3112\n",
      "           1       0.82      0.82      0.82      3626\n",
      "\n",
      "    accuracy                           0.81      6738\n",
      "   macro avg       0.81      0.81      0.81      6738\n",
      "weighted avg       0.81      0.81      0.81      6738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mt.classification_report(y_test,yhat1))\n",
    "print(mt.classification_report(y_test,yhat2))\n",
    "print(mt.classification_report(y_test,yhat3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks 1 and 3 are better than Network 2, but are *almost* the same as each other. The recall score predicting a team to make playoffs (1) is slightly higher for Network 1 vs. Network 3. The f1-score for predicting a team to not make playoffs (0) is slightly higher for Network 3 vs. Network 1. Since we don't have to worry about class imbalance (as mentioned earlier), it seems to make sense to utilize Wide and Deep Network 1 since it yielded a slightly higher recall score and because the crossed categories seem more sensible. If you recall, the crossed categories for Model 1 were **game location - outcome** (home/away - win/loss) and **average ppg compared to league - momentum sign** (`ppg5` above or below league avg at given point in the season - negative/zero/positive momentum). \n",
    "\n",
    "Therefore, **Wide and Deep Network 1** will be considered the best and most accurate model going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Multi-Layer Perceptron / Deep Network Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2427 - accuracy: 0.5872 - auc: 0.6218\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64958, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2427 - accuracy: 0.5874 - auc: 0.6223 - val_loss: 0.2338 - val_accuracy: 0.6496 - val_auc: 0.7065\n",
      "Epoch 2/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.6880 - auc: 0.7535\n",
      "Epoch 2: val_accuracy improved from 0.64958 to 0.71837, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2193 - accuracy: 0.6883 - auc: 0.7538 - val_loss: 0.2004 - val_accuracy: 0.7184 - val_auc: 0.7877\n",
      "Epoch 3/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.7413 - auc: 0.8186\n",
      "Epoch 3: val_accuracy improved from 0.71837 to 0.76131, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1812 - accuracy: 0.7425 - auc: 0.8197 - val_loss: 0.1658 - val_accuracy: 0.7613 - val_auc: 0.8410\n",
      "Epoch 4/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.7761 - auc: 0.8611\n",
      "Epoch 4: val_accuracy improved from 0.76131 to 0.79178, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1536 - accuracy: 0.7761 - auc: 0.8618 - val_loss: 0.1448 - val_accuracy: 0.7918 - val_auc: 0.8744\n",
      "Epoch 5/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1382 - accuracy: 0.7968 - auc: 0.8859\n",
      "Epoch 5: val_accuracy improved from 0.79178 to 0.80332, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1382 - accuracy: 0.7971 - auc: 0.8860 - val_loss: 0.1331 - val_accuracy: 0.8033 - val_auc: 0.8918\n",
      "Epoch 6/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1292 - accuracy: 0.8098 - auc: 0.8996\n",
      "Epoch 6: val_accuracy improved from 0.80332 to 0.80886, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1288 - accuracy: 0.8104 - auc: 0.9001 - val_loss: 0.1263 - val_accuracy: 0.8089 - val_auc: 0.9019\n",
      "Epoch 7/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.8185 - auc: 0.9092\n",
      "Epoch 7: val_accuracy improved from 0.80886 to 0.82179, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.8184 - auc: 0.9093 - val_loss: 0.1207 - val_accuracy: 0.8218 - val_auc: 0.9105\n",
      "Epoch 8/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.8279 - auc: 0.9158\n",
      "Epoch 8: val_accuracy improved from 0.82179 to 0.82779, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1178 - accuracy: 0.8279 - auc: 0.9157 - val_loss: 0.1173 - val_accuracy: 0.8278 - val_auc: 0.9167\n",
      "Epoch 9/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.8308 - auc: 0.9201\n",
      "Epoch 9: val_accuracy improved from 0.82779 to 0.83010, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.8317 - auc: 0.9207 - val_loss: 0.1135 - val_accuracy: 0.8301 - val_auc: 0.9209\n",
      "Epoch 10/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.8362 - auc: 0.9248\n",
      "Epoch 10: val_accuracy improved from 0.83010 to 0.83795, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.8362 - auc: 0.9246 - val_loss: 0.1110 - val_accuracy: 0.8380 - val_auc: 0.9248\n",
      "Epoch 11/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1084 - accuracy: 0.8397 - auc: 0.9284\n",
      "Epoch 11: val_accuracy improved from 0.83795 to 0.84164, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.8391 - auc: 0.9278 - val_loss: 0.1091 - val_accuracy: 0.8416 - val_auc: 0.9278\n",
      "Epoch 12/15\n",
      "560/610 [==========================>...] - ETA: 0s - loss: 0.1071 - accuracy: 0.8421 - auc: 0.9299\n",
      "Epoch 12: val_accuracy improved from 0.84164 to 0.84303, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1069 - accuracy: 0.8432 - auc: 0.9302 - val_loss: 0.1066 - val_accuracy: 0.8430 - val_auc: 0.9305\n",
      "Epoch 13/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1048 - accuracy: 0.8470 - auc: 0.9327\n",
      "Epoch 13: val_accuracy improved from 0.84303 to 0.84441, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.8465 - auc: 0.9328 - val_loss: 0.1053 - val_accuracy: 0.8444 - val_auc: 0.9322\n",
      "Epoch 14/15\n",
      "586/610 [===========================>..] - ETA: 0s - loss: 0.1026 - accuracy: 0.8511 - auc: 0.9354\n",
      "Epoch 14: val_accuracy improved from 0.84441 to 0.85365, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1029 - accuracy: 0.8506 - auc: 0.9351 - val_loss: 0.1030 - val_accuracy: 0.8536 - val_auc: 0.9350\n",
      "Epoch 15/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.8542 - auc: 0.9373\n",
      "Epoch 15: val_accuracy improved from 0.85365 to 0.85503, saving model to \\saved_models4/model_1.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1011 - accuracy: 0.8541 - auc: 0.9372 - val_loss: 0.1014 - val_accuracy: 0.8550 - val_auc: 0.9371\n",
      "68/68 [==============================] - 0s 983us/step - loss: 0.1014 - accuracy: 0.8550 - auc: 0.9371\n",
      "Epoch 1/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.2366 - accuracy: 0.6045 - auc: 0.6409\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66620, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2355 - accuracy: 0.6081 - auc: 0.6470 - val_loss: 0.2200 - val_accuracy: 0.6662 - val_auc: 0.7281\n",
      "Epoch 2/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1981 - accuracy: 0.7104 - auc: 0.7775\n",
      "Epoch 2: val_accuracy improved from 0.66620 to 0.74238, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1979 - accuracy: 0.7109 - auc: 0.7780 - val_loss: 0.1781 - val_accuracy: 0.7424 - val_auc: 0.8231\n",
      "Epoch 3/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.7607 - auc: 0.8413\n",
      "Epoch 3: val_accuracy improved from 0.74238 to 0.78670, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1643 - accuracy: 0.7610 - auc: 0.8412 - val_loss: 0.1499 - val_accuracy: 0.7867 - val_auc: 0.8702\n",
      "Epoch 4/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1448 - accuracy: 0.7892 - auc: 0.8737\n",
      "Epoch 4: val_accuracy improved from 0.78670 to 0.81256, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1443 - accuracy: 0.7899 - auc: 0.8745 - val_loss: 0.1329 - val_accuracy: 0.8126 - val_auc: 0.8948\n",
      "Epoch 5/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.1324 - accuracy: 0.8083 - auc: 0.8936\n",
      "Epoch 5: val_accuracy improved from 0.81256 to 0.82595, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1323 - accuracy: 0.8082 - auc: 0.8938 - val_loss: 0.1235 - val_accuracy: 0.8259 - val_auc: 0.9083\n",
      "Epoch 6/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.8194 - auc: 0.9058\n",
      "Epoch 6: val_accuracy improved from 0.82595 to 0.83564, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1243 - accuracy: 0.8194 - auc: 0.9058 - val_loss: 0.1169 - val_accuracy: 0.8356 - val_auc: 0.9174\n",
      "Epoch 7/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.8279 - auc: 0.9140\n",
      "Epoch 7: val_accuracy improved from 0.83564 to 0.84580, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1186 - accuracy: 0.8281 - auc: 0.9140 - val_loss: 0.1126 - val_accuracy: 0.8458 - val_auc: 0.9230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.8338 - auc: 0.9198\n",
      "Epoch 8: val_accuracy did not improve from 0.84580\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.8337 - auc: 0.9195 - val_loss: 0.1092 - val_accuracy: 0.8430 - val_auc: 0.9278\n",
      "Epoch 9/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.8401 - auc: 0.9239\n",
      "Epoch 9: val_accuracy did not improve from 0.84580\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.8401 - auc: 0.9240 - val_loss: 0.1078 - val_accuracy: 0.8421 - val_auc: 0.9298\n",
      "Epoch 10/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 0.8433 - auc: 0.9277\n",
      "Epoch 10: val_accuracy improved from 0.84580 to 0.85088, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1086 - accuracy: 0.8433 - auc: 0.9277 - val_loss: 0.1050 - val_accuracy: 0.8509 - val_auc: 0.9328\n",
      "Epoch 11/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1057 - accuracy: 0.8471 - auc: 0.9315\n",
      "Epoch 11: val_accuracy did not improve from 0.85088\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.8467 - auc: 0.9311 - val_loss: 0.1034 - val_accuracy: 0.8500 - val_auc: 0.9355\n",
      "Epoch 12/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1036 - accuracy: 0.8518 - auc: 0.9340\n",
      "Epoch 12: val_accuracy improved from 0.85088 to 0.85319, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.8521 - auc: 0.9343 - val_loss: 0.1009 - val_accuracy: 0.8532 - val_auc: 0.9379\n",
      "Epoch 13/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.8550 - auc: 0.9376\n",
      "Epoch 13: val_accuracy did not improve from 0.85319\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.8551 - auc: 0.9375 - val_loss: 0.0989 - val_accuracy: 0.8523 - val_auc: 0.9406\n",
      "Epoch 14/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.8596 - auc: 0.9410\n",
      "Epoch 14: val_accuracy improved from 0.85319 to 0.86380, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.8595 - auc: 0.9409 - val_loss: 0.0954 - val_accuracy: 0.8638 - val_auc: 0.9441\n",
      "Epoch 15/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.8655 - auc: 0.9444\n",
      "Epoch 15: val_accuracy improved from 0.86380 to 0.86473, saving model to \\saved_models4/model_2.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.8654 - auc: 0.9445 - val_loss: 0.0932 - val_accuracy: 0.8647 - val_auc: 0.9469\n",
      "68/68 [==============================] - 0s 941us/step - loss: 0.0932 - accuracy: 0.8647 - auc: 0.9469\n",
      "Epoch 1/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.6288 - auc: 0.6895\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68375, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2274 - accuracy: 0.6296 - auc: 0.6902 - val_loss: 0.2084 - val_accuracy: 0.6837 - val_auc: 0.7500\n",
      "Epoch 2/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1850 - accuracy: 0.7258 - auc: 0.8053\n",
      "Epoch 2: val_accuracy improved from 0.68375 to 0.74007, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1840 - accuracy: 0.7275 - auc: 0.8073 - val_loss: 0.1754 - val_accuracy: 0.7401 - val_auc: 0.8178\n",
      "Epoch 3/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.7750 - auc: 0.8639\n",
      "Epoch 3: val_accuracy improved from 0.74007 to 0.77378, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1533 - accuracy: 0.7750 - auc: 0.8633 - val_loss: 0.1508 - val_accuracy: 0.7738 - val_auc: 0.8639\n",
      "Epoch 4/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.8023 - auc: 0.8928\n",
      "Epoch 4: val_accuracy improved from 0.77378 to 0.78809, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1343 - accuracy: 0.8025 - auc: 0.8931 - val_loss: 0.1387 - val_accuracy: 0.7881 - val_auc: 0.8854\n",
      "Epoch 5/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1240 - accuracy: 0.8170 - auc: 0.9077\n",
      "Epoch 5: val_accuracy improved from 0.78809 to 0.80471, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1239 - accuracy: 0.8174 - auc: 0.9078 - val_loss: 0.1310 - val_accuracy: 0.8047 - val_auc: 0.8962\n",
      "Epoch 6/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.8258 - auc: 0.9163\n",
      "Epoch 6: val_accuracy improved from 0.80471 to 0.81071, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.8264 - auc: 0.9165 - val_loss: 0.1271 - val_accuracy: 0.8107 - val_auc: 0.9020\n",
      "Epoch 7/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.8345 - auc: 0.9222\n",
      "Epoch 7: val_accuracy improved from 0.81071 to 0.81533, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1131 - accuracy: 0.8344 - auc: 0.9223 - val_loss: 0.1236 - val_accuracy: 0.8153 - val_auc: 0.9080\n",
      "Epoch 8/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.8383 - auc: 0.9263\n",
      "Epoch 8: val_accuracy improved from 0.81533 to 0.82179, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1099 - accuracy: 0.8383 - auc: 0.9263 - val_loss: 0.1203 - val_accuracy: 0.8218 - val_auc: 0.9127\n",
      "Epoch 9/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.8451 - auc: 0.9299\n",
      "Epoch 9: val_accuracy improved from 0.82179 to 0.83287, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.8451 - auc: 0.9298 - val_loss: 0.1173 - val_accuracy: 0.8329 - val_auc: 0.9158\n",
      "Epoch 10/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.8507 - auc: 0.9326\n",
      "Epoch 10: val_accuracy did not improve from 0.83287\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.8506 - auc: 0.9328 - val_loss: 0.1156 - val_accuracy: 0.8310 - val_auc: 0.9189\n",
      "Epoch 11/15\n",
      "562/610 [==========================>...] - ETA: 0s - loss: 0.1026 - accuracy: 0.8555 - auc: 0.9353\n",
      "Epoch 11: val_accuracy improved from 0.83287 to 0.83934, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1023 - accuracy: 0.8561 - auc: 0.9357 - val_loss: 0.1138 - val_accuracy: 0.8393 - val_auc: 0.9209\n",
      "Epoch 12/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1002 - accuracy: 0.8586 - auc: 0.9381\n",
      "Epoch 12: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.8585 - auc: 0.9382 - val_loss: 0.1107 - val_accuracy: 0.8389 - val_auc: 0.9250\n",
      "Epoch 13/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.8631 - auc: 0.9415\n",
      "Epoch 13: val_accuracy improved from 0.83934 to 0.84164, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0975 - accuracy: 0.8630 - auc: 0.9413 - val_loss: 0.1083 - val_accuracy: 0.8416 - val_auc: 0.9284\n",
      "Epoch 14/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.8681 - auc: 0.9439\n",
      "Epoch 14: val_accuracy improved from 0.84164 to 0.84903, saving model to \\saved_models4/model_3.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0950 - accuracy: 0.8681 - auc: 0.9440 - val_loss: 0.1051 - val_accuracy: 0.8490 - val_auc: 0.9318\n",
      "Epoch 15/15\n",
      "570/610 [===========================>..] - ETA: 0s - loss: 0.0926 - accuracy: 0.8694 - auc: 0.9469\n",
      "Epoch 15: val_accuracy improved from 0.84903 to 0.85365, saving model to \\saved_models4/model_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.8699 - auc: 0.9472 - val_loss: 0.1024 - val_accuracy: 0.8536 - val_auc: 0.9369\n",
      "68/68 [==============================] - 0s 955us/step - loss: 0.1024 - accuracy: 0.8536 - auc: 0.9369\n",
      "Epoch 1/15\n",
      "561/610 [==========================>...] - ETA: 0s - loss: 0.2376 - accuracy: 0.6258 - auc: 0.6669\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68837, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2368 - accuracy: 0.6288 - auc: 0.6702 - val_loss: 0.2229 - val_accuracy: 0.6884 - val_auc: 0.7495\n",
      "Epoch 2/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.2060 - accuracy: 0.7099 - auc: 0.7744\n",
      "Epoch 2: val_accuracy improved from 0.68837 to 0.72899, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2055 - accuracy: 0.7107 - auc: 0.7753 - val_loss: 0.1865 - val_accuracy: 0.7290 - val_auc: 0.8128\n",
      "Epoch 3/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.7588 - auc: 0.8360\n",
      "Epoch 3: val_accuracy improved from 0.72899 to 0.76454, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1699 - accuracy: 0.7587 - auc: 0.8356 - val_loss: 0.1602 - val_accuracy: 0.7645 - val_auc: 0.8505\n",
      "Epoch 4/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.7889 - auc: 0.8723\n",
      "Epoch 4: val_accuracy improved from 0.76454 to 0.78163, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1465 - accuracy: 0.7891 - auc: 0.8725 - val_loss: 0.1450 - val_accuracy: 0.7816 - val_auc: 0.8736\n",
      "Epoch 5/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.8083 - auc: 0.8932\n",
      "Epoch 5: val_accuracy improved from 0.78163 to 0.79548, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1324 - accuracy: 0.8089 - auc: 0.8938 - val_loss: 0.1376 - val_accuracy: 0.7955 - val_auc: 0.8852\n",
      "Epoch 6/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.8200 - auc: 0.9069\n",
      "Epoch 6: val_accuracy improved from 0.79548 to 0.80517, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.8199 - auc: 0.9069 - val_loss: 0.1318 - val_accuracy: 0.8052 - val_auc: 0.8943\n",
      "Epoch 7/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1173 - accuracy: 0.8292 - auc: 0.9158\n",
      "Epoch 7: val_accuracy improved from 0.80517 to 0.81117, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.8292 - auc: 0.9157 - val_loss: 0.1278 - val_accuracy: 0.8112 - val_auc: 0.9005\n",
      "Epoch 8/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1130 - accuracy: 0.8360 - auc: 0.9217\n",
      "Epoch 8: val_accuracy improved from 0.81117 to 0.81810, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1130 - accuracy: 0.8357 - auc: 0.9217 - val_loss: 0.1260 - val_accuracy: 0.8181 - val_auc: 0.9036\n",
      "Epoch 9/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.8423 - auc: 0.9264\n",
      "Epoch 9: val_accuracy improved from 0.81810 to 0.82179, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.8421 - auc: 0.9264 - val_loss: 0.1230 - val_accuracy: 0.8218 - val_auc: 0.9087\n",
      "Epoch 10/15\n",
      "579/610 [===========================>..] - ETA: 0s - loss: 0.1068 - accuracy: 0.8464 - auc: 0.9299\n",
      "Epoch 10: val_accuracy improved from 0.82179 to 0.82271, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.8467 - auc: 0.9301 - val_loss: 0.1207 - val_accuracy: 0.8227 - val_auc: 0.9121\n",
      "Epoch 11/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 0.8496 - auc: 0.9332\n",
      "Epoch 11: val_accuracy improved from 0.82271 to 0.82595, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.8496 - auc: 0.9332 - val_loss: 0.1187 - val_accuracy: 0.8259 - val_auc: 0.9158\n",
      "Epoch 12/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.8538 - auc: 0.9366\n",
      "Epoch 12: val_accuracy improved from 0.82595 to 0.82918, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.8535 - auc: 0.9361 - val_loss: 0.1167 - val_accuracy: 0.8292 - val_auc: 0.9179\n",
      "Epoch 13/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1000 - accuracy: 0.8569 - auc: 0.9381\n",
      "Epoch 13: val_accuracy improved from 0.82918 to 0.83102, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.8577 - auc: 0.9388 - val_loss: 0.1146 - val_accuracy: 0.8310 - val_auc: 0.9208\n",
      "Epoch 14/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.8599 - auc: 0.9415\n",
      "Epoch 14: val_accuracy improved from 0.83102 to 0.83380, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.8600 - auc: 0.9416 - val_loss: 0.1123 - val_accuracy: 0.8338 - val_auc: 0.9239\n",
      "Epoch 15/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.8657 - auc: 0.9441\n",
      "Epoch 15: val_accuracy improved from 0.83380 to 0.83795, saving model to \\saved_models4/model_4.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.8663 - auc: 0.9445 - val_loss: 0.1101 - val_accuracy: 0.8380 - val_auc: 0.9270\n",
      "68/68 [==============================] - 0s 965us/step - loss: 0.1101 - accuracy: 0.8380 - auc: 0.9270\n",
      "Epoch 1/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.5751 - auc: 0.5779\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64266, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.5753 - auc: 0.5787 - val_loss: 0.2375 - val_accuracy: 0.6427 - val_auc: 0.6829\n",
      "Epoch 2/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.6810 - auc: 0.7390\n",
      "Epoch 2: val_accuracy improved from 0.64266 to 0.72392, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2232 - accuracy: 0.6809 - auc: 0.7389 - val_loss: 0.2039 - val_accuracy: 0.7239 - val_auc: 0.7875\n",
      "Epoch 3/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1861 - accuracy: 0.7414 - auc: 0.8132\n",
      "Epoch 3: val_accuracy improved from 0.72392 to 0.76547, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1859 - accuracy: 0.7417 - auc: 0.8137 - val_loss: 0.1668 - val_accuracy: 0.7655 - val_auc: 0.8405\n",
      "Epoch 4/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.7795 - auc: 0.8612\n",
      "Epoch 4: val_accuracy improved from 0.76547 to 0.78994, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1548 - accuracy: 0.7797 - auc: 0.8614 - val_loss: 0.1440 - val_accuracy: 0.7899 - val_auc: 0.8756\n",
      "Epoch 5/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.8042 - auc: 0.8895\n",
      "Epoch 5: val_accuracy improved from 0.78994 to 0.81256, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1359 - accuracy: 0.8042 - auc: 0.8895 - val_loss: 0.1310 - val_accuracy: 0.8126 - val_auc: 0.8946\n",
      "Epoch 6/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1254 - accuracy: 0.8189 - auc: 0.9043\n",
      "Epoch 6: val_accuracy improved from 0.81256 to 0.82641, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1248 - accuracy: 0.8201 - auc: 0.9054 - val_loss: 0.1212 - val_accuracy: 0.8264 - val_auc: 0.9110\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/610 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 0.8320 - auc: 0.9168\n",
      "Epoch 7: val_accuracy improved from 0.82641 to 0.83380, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.8315 - auc: 0.9165 - val_loss: 0.1153 - val_accuracy: 0.8338 - val_auc: 0.9201\n",
      "Epoch 8/15\n",
      "567/610 [==========================>...] - ETA: 0s - loss: 0.1109 - accuracy: 0.8411 - auc: 0.9247\n",
      "Epoch 8: val_accuracy improved from 0.83380 to 0.84765, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.8401 - auc: 0.9247 - val_loss: 0.1088 - val_accuracy: 0.8476 - val_auc: 0.9288\n",
      "Epoch 9/15\n",
      "605/610 [============================>.] - ETA: 0s - loss: 0.1057 - accuracy: 0.8496 - auc: 0.9313\n",
      "Epoch 9: val_accuracy improved from 0.84765 to 0.85503, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1058 - accuracy: 0.8494 - auc: 0.9312 - val_loss: 0.1030 - val_accuracy: 0.8550 - val_auc: 0.9353\n",
      "Epoch 10/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.8556 - auc: 0.9368\n",
      "Epoch 10: val_accuracy improved from 0.85503 to 0.86288, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.8560 - auc: 0.9369 - val_loss: 0.0982 - val_accuracy: 0.8629 - val_auc: 0.9409\n",
      "Epoch 11/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.8643 - auc: 0.9418\n",
      "Epoch 11: val_accuracy improved from 0.86288 to 0.87073, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0968 - accuracy: 0.8646 - auc: 0.9421 - val_loss: 0.0944 - val_accuracy: 0.8707 - val_auc: 0.9456\n",
      "Epoch 12/15\n",
      "565/610 [==========================>...] - ETA: 0s - loss: 0.0923 - accuracy: 0.8706 - auc: 0.9471\n",
      "Epoch 12: val_accuracy improved from 0.87073 to 0.87535, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0929 - accuracy: 0.8695 - auc: 0.9466 - val_loss: 0.0904 - val_accuracy: 0.8753 - val_auc: 0.9496\n",
      "Epoch 13/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.8749 - auc: 0.9506\n",
      "Epoch 13: val_accuracy improved from 0.87535 to 0.88042, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.8749 - auc: 0.9505 - val_loss: 0.0867 - val_accuracy: 0.8804 - val_auc: 0.9538\n",
      "Epoch 14/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.0868 - accuracy: 0.8785 - auc: 0.9530\n",
      "Epoch 14: val_accuracy improved from 0.88042 to 0.88135, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0862 - accuracy: 0.8798 - auc: 0.9535 - val_loss: 0.0843 - val_accuracy: 0.8813 - val_auc: 0.9560\n",
      "Epoch 15/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.0833 - accuracy: 0.8834 - auc: 0.9561\n",
      "Epoch 15: val_accuracy improved from 0.88135 to 0.88366, saving model to \\saved_models4/model_5.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0837 - accuracy: 0.8830 - auc: 0.9557 - val_loss: 0.0820 - val_accuracy: 0.8837 - val_auc: 0.9581\n",
      "68/68 [==============================] - 0s 930us/step - loss: 0.0820 - accuracy: 0.8837 - auc: 0.9581\n",
      "Epoch 1/15\n",
      "578/610 [===========================>..] - ETA: 0s - loss: 0.2444 - accuracy: 0.5797 - auc: 0.6153\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61542, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 2ms/step - loss: 0.2438 - accuracy: 0.5830 - auc: 0.6199 - val_loss: 0.2371 - val_accuracy: 0.6154 - val_auc: 0.6716\n",
      "Epoch 2/15\n",
      "593/610 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.6656 - auc: 0.7221\n",
      "Epoch 2: val_accuracy improved from 0.61542 to 0.69021, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2247 - accuracy: 0.6656 - auc: 0.7227 - val_loss: 0.2134 - val_accuracy: 0.6902 - val_auc: 0.7588\n",
      "Epoch 3/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1970 - accuracy: 0.7235 - auc: 0.7890\n",
      "Epoch 3: val_accuracy improved from 0.69021 to 0.74746, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1970 - accuracy: 0.7236 - auc: 0.7890 - val_loss: 0.1824 - val_accuracy: 0.7475 - val_auc: 0.8218\n",
      "Epoch 4/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.7625 - auc: 0.8382\n",
      "Epoch 4: val_accuracy improved from 0.74746 to 0.78670, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1678 - accuracy: 0.7633 - auc: 0.8391 - val_loss: 0.1553 - val_accuracy: 0.7867 - val_auc: 0.8626\n",
      "Epoch 5/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.7909 - auc: 0.8742\n",
      "Epoch 5: val_accuracy improved from 0.78670 to 0.80379, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1454 - accuracy: 0.7912 - auc: 0.8745 - val_loss: 0.1378 - val_accuracy: 0.8038 - val_auc: 0.8873\n",
      "Epoch 6/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1313 - accuracy: 0.8105 - auc: 0.8959\n",
      "Epoch 6: val_accuracy improved from 0.80379 to 0.81579, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1313 - accuracy: 0.8105 - auc: 0.8959 - val_loss: 0.1287 - val_accuracy: 0.8158 - val_auc: 0.9006\n",
      "Epoch 7/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.8218 - auc: 0.9081\n",
      "Epoch 7: val_accuracy improved from 0.81579 to 0.81856, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.8220 - auc: 0.9082 - val_loss: 0.1233 - val_accuracy: 0.8186 - val_auc: 0.9081\n",
      "Epoch 8/15\n",
      "575/610 [===========================>..] - ETA: 0s - loss: 0.1174 - accuracy: 0.8313 - auc: 0.9159\n",
      "Epoch 8: val_accuracy improved from 0.81856 to 0.82595, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1179 - accuracy: 0.8299 - auc: 0.9152 - val_loss: 0.1200 - val_accuracy: 0.8259 - val_auc: 0.9131\n",
      "Epoch 9/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.8330 - auc: 0.9199\n",
      "Epoch 9: val_accuracy improved from 0.82595 to 0.83056, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1143 - accuracy: 0.8334 - auc: 0.9203 - val_loss: 0.1179 - val_accuracy: 0.8306 - val_auc: 0.9162\n",
      "Epoch 10/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1116 - accuracy: 0.8398 - auc: 0.9236\n",
      "Epoch 10: val_accuracy improved from 0.83056 to 0.83241, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1114 - accuracy: 0.8400 - auc: 0.9239 - val_loss: 0.1154 - val_accuracy: 0.8324 - val_auc: 0.9198\n",
      "Epoch 11/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.8433 - auc: 0.9271\n",
      "Epoch 11: val_accuracy improved from 0.83241 to 0.83426, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8429 - auc: 0.9270 - val_loss: 0.1132 - val_accuracy: 0.8343 - val_auc: 0.9229\n",
      "Epoch 12/15\n",
      "606/610 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.8462 - auc: 0.9292\n",
      "Epoch 12: val_accuracy improved from 0.83426 to 0.83610, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1072 - accuracy: 0.8462 - auc: 0.9292 - val_loss: 0.1117 - val_accuracy: 0.8361 - val_auc: 0.9252\n",
      "Epoch 13/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.8488 - auc: 0.9313\n",
      "Epoch 13: val_accuracy improved from 0.83610 to 0.83841, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1056 - accuracy: 0.8486 - auc: 0.9312 - val_loss: 0.1098 - val_accuracy: 0.8384 - val_auc: 0.9268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.8504 - auc: 0.9330\n",
      "Epoch 14: val_accuracy improved from 0.83841 to 0.83934, saving model to \\saved_models4/model_6.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.8506 - auc: 0.9332 - val_loss: 0.1093 - val_accuracy: 0.8393 - val_auc: 0.9279\n",
      "Epoch 15/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.8528 - auc: 0.9349\n",
      "Epoch 15: val_accuracy did not improve from 0.83934\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.8528 - auc: 0.9349 - val_loss: 0.1077 - val_accuracy: 0.8389 - val_auc: 0.9298\n",
      "68/68 [==============================] - 0s 977us/step - loss: 0.1093 - accuracy: 0.8393 - auc: 0.9279\n",
      "Epoch 1/15\n",
      "561/610 [==========================>...] - ETA: 0s - loss: 0.2402 - accuracy: 0.5696 - auc: 0.6097\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64451, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2387 - accuracy: 0.5764 - auc: 0.6206 - val_loss: 0.2233 - val_accuracy: 0.6445 - val_auc: 0.7118\n",
      "Epoch 2/15\n",
      "585/610 [===========================>..] - ETA: 0s - loss: 0.1969 - accuracy: 0.7161 - auc: 0.7974\n",
      "Epoch 2: val_accuracy improved from 0.64451 to 0.76131, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1959 - accuracy: 0.7176 - auc: 0.7988 - val_loss: 0.1721 - val_accuracy: 0.7613 - val_auc: 0.8386\n",
      "Epoch 3/15\n",
      "600/610 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.7873 - auc: 0.8714\n",
      "Epoch 3: val_accuracy improved from 0.76131 to 0.80332, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1513 - accuracy: 0.7878 - auc: 0.8719 - val_loss: 0.1396 - val_accuracy: 0.8033 - val_auc: 0.8854\n",
      "Epoch 4/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.8150 - auc: 0.9002\n",
      "Epoch 4: val_accuracy improved from 0.80332 to 0.81671, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.8147 - auc: 0.9000 - val_loss: 0.1281 - val_accuracy: 0.8167 - val_auc: 0.9010\n",
      "Epoch 5/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.8270 - auc: 0.9125\n",
      "Epoch 5: val_accuracy improved from 0.81671 to 0.82825, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.8269 - auc: 0.9124 - val_loss: 0.1223 - val_accuracy: 0.8283 - val_auc: 0.9083\n",
      "Epoch 6/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.8332 - auc: 0.9188\n",
      "Epoch 6: val_accuracy improved from 0.82825 to 0.82872, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1151 - accuracy: 0.8341 - auc: 0.9194 - val_loss: 0.1184 - val_accuracy: 0.8287 - val_auc: 0.9136\n",
      "Epoch 7/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1113 - accuracy: 0.8395 - auc: 0.9244\n",
      "Epoch 7: val_accuracy improved from 0.82872 to 0.83380, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.8395 - auc: 0.9242 - val_loss: 0.1162 - val_accuracy: 0.8338 - val_auc: 0.9164\n",
      "Epoch 8/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.8445 - auc: 0.9276\n",
      "Epoch 8: val_accuracy did not improve from 0.83380\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.8448 - auc: 0.9278 - val_loss: 0.1149 - val_accuracy: 0.8338 - val_auc: 0.9196\n",
      "Epoch 9/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1065 - accuracy: 0.8480 - auc: 0.9304\n",
      "Epoch 9: val_accuracy improved from 0.83380 to 0.83841, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1062 - accuracy: 0.8487 - auc: 0.9308 - val_loss: 0.1117 - val_accuracy: 0.8384 - val_auc: 0.9227\n",
      "Epoch 10/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.8510 - auc: 0.9338\n",
      "Epoch 10: val_accuracy improved from 0.83841 to 0.83980, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.8508 - auc: 0.9335 - val_loss: 0.1099 - val_accuracy: 0.8398 - val_auc: 0.9250\n",
      "Epoch 11/15\n",
      "580/610 [===========================>..] - ETA: 0s - loss: 0.1019 - accuracy: 0.8546 - auc: 0.9362\n",
      "Epoch 11: val_accuracy improved from 0.83980 to 0.84072, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.8547 - auc: 0.9361 - val_loss: 0.1090 - val_accuracy: 0.8407 - val_auc: 0.9270\n",
      "Epoch 12/15\n",
      "582/610 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.8571 - auc: 0.9389\n",
      "Epoch 12: val_accuracy improved from 0.84072 to 0.84765, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.8572 - auc: 0.9389 - val_loss: 0.1057 - val_accuracy: 0.8476 - val_auc: 0.9303\n",
      "Epoch 13/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.8611 - auc: 0.9411\n",
      "Epoch 13: val_accuracy improved from 0.84765 to 0.85272, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0972 - accuracy: 0.8619 - auc: 0.9416 - val_loss: 0.1038 - val_accuracy: 0.8527 - val_auc: 0.9334\n",
      "Epoch 14/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.8677 - auc: 0.9446\n",
      "Epoch 14: val_accuracy improved from 0.85272 to 0.85826, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.8676 - auc: 0.9446 - val_loss: 0.1020 - val_accuracy: 0.8583 - val_auc: 0.9355\n",
      "Epoch 15/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.8717 - auc: 0.9476\n",
      "Epoch 15: val_accuracy improved from 0.85826 to 0.85965, saving model to \\saved_models4/model_7.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.8716 - auc: 0.9476 - val_loss: 0.0991 - val_accuracy: 0.8596 - val_auc: 0.9391\n",
      "68/68 [==============================] - 0s 942us/step - loss: 0.0991 - accuracy: 0.8596 - auc: 0.9391\n",
      "Epoch 1/15\n",
      "581/610 [===========================>..] - ETA: 0s - loss: 0.2450 - accuracy: 0.5508 - auc: 0.5736\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61311, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.5539 - auc: 0.5787 - val_loss: 0.2344 - val_accuracy: 0.6131 - val_auc: 0.6728\n",
      "Epoch 2/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.2226 - accuracy: 0.6526 - auc: 0.7078\n",
      "Epoch 2: val_accuracy improved from 0.61311 to 0.69114, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2223 - accuracy: 0.6534 - auc: 0.7086 - val_loss: 0.2102 - val_accuracy: 0.6911 - val_auc: 0.7465\n",
      "Epoch 3/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1978 - accuracy: 0.7041 - auc: 0.7734\n",
      "Epoch 3: val_accuracy improved from 0.69114 to 0.73546, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1968 - accuracy: 0.7054 - auc: 0.7758 - val_loss: 0.1815 - val_accuracy: 0.7355 - val_auc: 0.8104\n",
      "Epoch 4/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1676 - accuracy: 0.7578 - auc: 0.8376\n",
      "Epoch 4: val_accuracy improved from 0.73546 to 0.78393, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1671 - accuracy: 0.7582 - auc: 0.8382 - val_loss: 0.1533 - val_accuracy: 0.7839 - val_auc: 0.8626\n",
      "Epoch 5/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.7931 - auc: 0.8775\n",
      "Epoch 5: val_accuracy improved from 0.78393 to 0.80379, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1440 - accuracy: 0.7930 - auc: 0.8774 - val_loss: 0.1362 - val_accuracy: 0.8038 - val_auc: 0.8895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "604/610 [============================>.] - ETA: 0s - loss: 0.1314 - accuracy: 0.8100 - auc: 0.8961\n",
      "Epoch 6: val_accuracy improved from 0.80379 to 0.81810, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1314 - accuracy: 0.8101 - auc: 0.8961 - val_loss: 0.1266 - val_accuracy: 0.8181 - val_auc: 0.9045\n",
      "Epoch 7/15\n",
      "609/610 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.8203 - auc: 0.9072\n",
      "Epoch 7: val_accuracy improved from 0.81810 to 0.83010, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1238 - accuracy: 0.8203 - auc: 0.9072 - val_loss: 0.1192 - val_accuracy: 0.8301 - val_auc: 0.9140\n",
      "Epoch 8/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 0.8292 - auc: 0.9150\n",
      "Epoch 8: val_accuracy improved from 0.83010 to 0.83426, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1186 - accuracy: 0.8285 - auc: 0.9147 - val_loss: 0.1170 - val_accuracy: 0.8343 - val_auc: 0.9200\n",
      "Epoch 9/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.8340 - auc: 0.9199\n",
      "Epoch 9: val_accuracy improved from 0.83426 to 0.84257, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.8340 - auc: 0.9198 - val_loss: 0.1107 - val_accuracy: 0.8426 - val_auc: 0.9256\n",
      "Epoch 10/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.8381 - auc: 0.9237\n",
      "Epoch 10: val_accuracy improved from 0.84257 to 0.84349, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.8385 - auc: 0.9240 - val_loss: 0.1074 - val_accuracy: 0.8435 - val_auc: 0.9293\n",
      "Epoch 11/15\n",
      "563/610 [==========================>...] - ETA: 0s - loss: 0.1086 - accuracy: 0.8425 - auc: 0.9278\n",
      "Epoch 11: val_accuracy improved from 0.84349 to 0.84995, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1088 - accuracy: 0.8418 - auc: 0.9275 - val_loss: 0.1051 - val_accuracy: 0.8500 - val_auc: 0.9328\n",
      "Epoch 12/15\n",
      "607/610 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.8453 - auc: 0.9303\n",
      "Epoch 12: val_accuracy improved from 0.84995 to 0.85226, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.8455 - auc: 0.9304 - val_loss: 0.1022 - val_accuracy: 0.8523 - val_auc: 0.9358\n",
      "Epoch 13/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.8490 - auc: 0.9333\n",
      "Epoch 13: val_accuracy improved from 0.85226 to 0.85503, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.8493 - auc: 0.9333 - val_loss: 0.1003 - val_accuracy: 0.8550 - val_auc: 0.9389\n",
      "Epoch 14/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 0.8532 - auc: 0.9362\n",
      "Epoch 14: val_accuracy improved from 0.85503 to 0.86196, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.8533 - auc: 0.9362 - val_loss: 0.0978 - val_accuracy: 0.8620 - val_auc: 0.9409\n",
      "Epoch 15/15\n",
      "583/610 [===========================>..] - ETA: 0s - loss: 0.0992 - accuracy: 0.8573 - auc: 0.9395\n",
      "Epoch 15: val_accuracy improved from 0.86196 to 0.86334, saving model to \\saved_models4/model_8.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.8571 - auc: 0.9392 - val_loss: 0.0978 - val_accuracy: 0.8633 - val_auc: 0.9440\n",
      "68/68 [==============================] - 0s 937us/step - loss: 0.0978 - accuracy: 0.8633 - auc: 0.9440\n",
      "Epoch 1/15\n",
      "561/610 [==========================>...] - ETA: 0s - loss: 0.2369 - accuracy: 0.5891 - auc: 0.6277\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66559, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2357 - accuracy: 0.5941 - auc: 0.6342 - val_loss: 0.2144 - val_accuracy: 0.6656 - val_auc: 0.7317\n",
      "Epoch 2/15\n",
      "596/610 [============================>.] - ETA: 0s - loss: 0.2006 - accuracy: 0.6939 - auc: 0.7658\n",
      "Epoch 2: val_accuracy improved from 0.66559 to 0.73718, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2003 - accuracy: 0.6946 - auc: 0.7662 - val_loss: 0.1784 - val_accuracy: 0.7372 - val_auc: 0.8171\n",
      "Epoch 3/15\n",
      "603/610 [============================>.] - ETA: 0s - loss: 0.1684 - accuracy: 0.7501 - auc: 0.8347\n",
      "Epoch 3: val_accuracy improved from 0.73718 to 0.78060, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1682 - accuracy: 0.7503 - auc: 0.8350 - val_loss: 0.1500 - val_accuracy: 0.7806 - val_auc: 0.8678\n",
      "Epoch 4/15\n",
      "594/610 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.7842 - auc: 0.8731\n",
      "Epoch 4: val_accuracy improved from 0.78060 to 0.80554, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1460 - accuracy: 0.7844 - auc: 0.8736 - val_loss: 0.1335 - val_accuracy: 0.8055 - val_auc: 0.8933\n",
      "Epoch 5/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.8068 - auc: 0.8944\n",
      "Epoch 5: val_accuracy improved from 0.80554 to 0.82587, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1325 - accuracy: 0.8068 - auc: 0.8945 - val_loss: 0.1230 - val_accuracy: 0.8259 - val_auc: 0.9084\n",
      "Epoch 6/15\n",
      "589/610 [===========================>..] - ETA: 0s - loss: 0.1235 - accuracy: 0.8181 - auc: 0.9078\n",
      "Epoch 6: val_accuracy improved from 0.82587 to 0.83788, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.8174 - auc: 0.9076 - val_loss: 0.1161 - val_accuracy: 0.8379 - val_auc: 0.9180\n",
      "Epoch 7/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.8271 - auc: 0.9160\n",
      "Epoch 7: val_accuracy improved from 0.83788 to 0.84203, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1177 - accuracy: 0.8269 - auc: 0.9159 - val_loss: 0.1122 - val_accuracy: 0.8420 - val_auc: 0.9238\n",
      "Epoch 8/15\n",
      "602/610 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.8358 - auc: 0.9223\n",
      "Epoch 8: val_accuracy improved from 0.84203 to 0.84804, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.8360 - auc: 0.9223 - val_loss: 0.1081 - val_accuracy: 0.8480 - val_auc: 0.9281\n",
      "Epoch 9/15\n",
      "571/610 [===========================>..] - ETA: 0s - loss: 0.1093 - accuracy: 0.8412 - auc: 0.9270\n",
      "Epoch 9: val_accuracy improved from 0.84804 to 0.85589, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1090 - accuracy: 0.8417 - auc: 0.9274 - val_loss: 0.1056 - val_accuracy: 0.8559 - val_auc: 0.9314\n",
      "Epoch 10/15\n",
      "592/610 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.8469 - auc: 0.9308\n",
      "Epoch 10: val_accuracy did not improve from 0.85589\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1059 - accuracy: 0.8477 - auc: 0.9312 - val_loss: 0.1032 - val_accuracy: 0.8559 - val_auc: 0.9345\n",
      "Epoch 11/15\n",
      "574/610 [===========================>..] - ETA: 0s - loss: 0.1029 - accuracy: 0.8518 - auc: 0.9349\n",
      "Epoch 11: val_accuracy did not improve from 0.85589\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1027 - accuracy: 0.8522 - auc: 0.9352 - val_loss: 0.1014 - val_accuracy: 0.8554 - val_auc: 0.9370\n",
      "Epoch 12/15\n",
      "577/610 [===========================>..] - ETA: 0s - loss: 0.1004 - accuracy: 0.8579 - auc: 0.9378\n",
      "Epoch 12: val_accuracy improved from 0.85589 to 0.86097, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.8586 - auc: 0.9384 - val_loss: 0.0991 - val_accuracy: 0.8610 - val_auc: 0.9397\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/610 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.8623 - auc: 0.9417\n",
      "Epoch 13: val_accuracy improved from 0.86097 to 0.86651, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0967 - accuracy: 0.8630 - auc: 0.9421 - val_loss: 0.0958 - val_accuracy: 0.8665 - val_auc: 0.9431\n",
      "Epoch 14/15\n",
      "563/610 [==========================>...] - ETA: 0s - loss: 0.0933 - accuracy: 0.8692 - auc: 0.9459\n",
      "Epoch 14: val_accuracy improved from 0.86651 to 0.86975, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.8685 - auc: 0.9456 - val_loss: 0.0938 - val_accuracy: 0.8697 - val_auc: 0.9453\n",
      "Epoch 15/15\n",
      "588/610 [===========================>..] - ETA: 0s - loss: 0.0901 - accuracy: 0.8747 - auc: 0.9494\n",
      "Epoch 15: val_accuracy improved from 0.86975 to 0.87667, saving model to \\saved_models4/model_9.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.8745 - auc: 0.9492 - val_loss: 0.0906 - val_accuracy: 0.8767 - val_auc: 0.9490\n",
      "68/68 [==============================] - 0s 979us/step - loss: 0.0906 - accuracy: 0.8767 - auc: 0.9490\n",
      "Epoch 1/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.2484 - accuracy: 0.5350 - auc: 0.5554\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59261, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2482 - accuracy: 0.5364 - auc: 0.5577 - val_loss: 0.2413 - val_accuracy: 0.5926 - val_auc: 0.6547\n",
      "Epoch 2/15\n",
      "608/610 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.6179 - auc: 0.7020\n",
      "Epoch 2: val_accuracy improved from 0.59261 to 0.67252, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2333 - accuracy: 0.6179 - auc: 0.7020 - val_loss: 0.2209 - val_accuracy: 0.6725 - val_auc: 0.7439\n",
      "Epoch 3/15\n",
      "563/610 [==========================>...] - ETA: 0s - loss: 0.2060 - accuracy: 0.6958 - auc: 0.7696\n",
      "Epoch 3: val_accuracy improved from 0.67252 to 0.72748, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.2045 - accuracy: 0.6990 - auc: 0.7730 - val_loss: 0.1871 - val_accuracy: 0.7275 - val_auc: 0.8031\n",
      "Epoch 4/15\n",
      "597/610 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.7493 - auc: 0.8305\n",
      "Epoch 4: val_accuracy improved from 0.72748 to 0.77182, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1719 - accuracy: 0.7490 - auc: 0.8306 - val_loss: 0.1594 - val_accuracy: 0.7718 - val_auc: 0.8528\n",
      "Epoch 5/15\n",
      "569/610 [==========================>...] - ETA: 0s - loss: 0.1493 - accuracy: 0.7815 - auc: 0.8691\n",
      "Epoch 5: val_accuracy improved from 0.77182 to 0.80046, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1482 - accuracy: 0.7832 - auc: 0.8711 - val_loss: 0.1398 - val_accuracy: 0.8005 - val_auc: 0.8842\n",
      "Epoch 6/15\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.8012 - auc: 0.8930\n",
      "Epoch 6: val_accuracy improved from 0.80046 to 0.80878, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1340 - accuracy: 0.8012 - auc: 0.8930 - val_loss: 0.1287 - val_accuracy: 0.8088 - val_auc: 0.9013\n",
      "Epoch 7/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.8136 - auc: 0.9049\n",
      "Epoch 7: val_accuracy improved from 0.80878 to 0.81940, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1255 - accuracy: 0.8144 - auc: 0.9053 - val_loss: 0.1222 - val_accuracy: 0.8194 - val_auc: 0.9103\n",
      "Epoch 8/15\n",
      "591/610 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.8224 - auc: 0.9131\n",
      "Epoch 8: val_accuracy improved from 0.81940 to 0.83141, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.8223 - auc: 0.9133 - val_loss: 0.1168 - val_accuracy: 0.8314 - val_auc: 0.9176\n",
      "Epoch 9/15\n",
      "573/610 [===========================>..] - ETA: 0s - loss: 0.1159 - accuracy: 0.8301 - auc: 0.9187\n",
      "Epoch 9: val_accuracy improved from 0.83141 to 0.83326, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.8307 - auc: 0.9191 - val_loss: 0.1141 - val_accuracy: 0.8333 - val_auc: 0.9217\n",
      "Epoch 10/15\n",
      "601/610 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.8358 - auc: 0.9233\n",
      "Epoch 10: val_accuracy improved from 0.83326 to 0.83926, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.8363 - auc: 0.9235 - val_loss: 0.1113 - val_accuracy: 0.8393 - val_auc: 0.9251\n",
      "Epoch 11/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.8406 - auc: 0.9270\n",
      "Epoch 11: val_accuracy improved from 0.83926 to 0.83972, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.8410 - auc: 0.9272 - val_loss: 0.1092 - val_accuracy: 0.8397 - val_auc: 0.9278\n",
      "Epoch 12/15\n",
      "599/610 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.8444 - auc: 0.9306\n",
      "Epoch 12: val_accuracy improved from 0.83972 to 0.84850, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.8441 - auc: 0.9304 - val_loss: 0.1068 - val_accuracy: 0.8485 - val_auc: 0.9306\n",
      "Epoch 13/15\n",
      "560/610 [==========================>...] - ETA: 0s - loss: 0.1047 - accuracy: 0.8480 - auc: 0.9330\n",
      "Epoch 13: val_accuracy did not improve from 0.84850\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.8486 - auc: 0.9336 - val_loss: 0.1051 - val_accuracy: 0.8476 - val_auc: 0.9334\n",
      "Epoch 14/15\n",
      "568/610 [==========================>...] - ETA: 0s - loss: 0.1016 - accuracy: 0.8537 - auc: 0.9368\n",
      "Epoch 14: val_accuracy improved from 0.84850 to 0.85543, saving model to \\saved_models4/model_10.h5\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.8535 - auc: 0.9365 - val_loss: 0.1023 - val_accuracy: 0.8554 - val_auc: 0.9361\n",
      "Epoch 15/15\n",
      "598/610 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.8575 - auc: 0.9397\n",
      "Epoch 15: val_accuracy did not improve from 0.85543\n",
      "610/610 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.8576 - auc: 0.9398 - val_loss: 0.1004 - val_accuracy: 0.8531 - val_auc: 0.9390\n",
      "68/68 [==============================] - 0s 902us/step - loss: 0.1023 - accuracy: 0.8554 - auc: 0.9361\n"
     ]
    }
   ],
   "source": [
    "kfold = 1\n",
    "#kf = KFold(n_splits = 10, shuffle = True, random_state = 24)\n",
    "\n",
    "VALIDATION_ACCURACY4 = []\n",
    "VALIDATION_AUC4 = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    training_data = X_train.iloc[train_index]\n",
    "    validation_data = X_train.iloc[val_index]\n",
    "    y_train1 = y_train[[train_index]].reshape(-1,1)\n",
    "    y_val = y_train[[val_index]].reshape(-1,1)\n",
    "\n",
    "    # save categorical features\n",
    "    X_train_cat = training_data[categorical_headers].to_numpy() \n",
    "    X_test_cat = validation_data[categorical_headers].to_numpy() \n",
    "\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  training_data[numeric_headers].to_numpy()\n",
    "    X_test_num = validation_data[numeric_headers].to_numpy()\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "\n",
    "    # CATEGORICAL DATA INPUT\n",
    "    input_cat = Input(shape=(X_train_cat.shape[1],), dtype='int64', name='categorical_input')\n",
    "    for idx,col in enumerate(categorical_headers):\n",
    "    \n",
    "        # track what the maximum integer value will be for this variable\n",
    "        # which is the same as the number of categories\n",
    "        N = max(X_train[col].max(),X_test[col].max())+1\n",
    "    \n",
    "        # this line of code does this: input_branch[:,idx]\n",
    "        x = tf.gather(input_cat, idx, axis=1)\n",
    "    \n",
    "        # now use an embedding to deal with integers as if they were one hot encoded\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1, name=col+'_embed')(x)\n",
    "    \n",
    "        # save these outputs to concatenate later\n",
    "        all_deep_branch_outputs.append(x)\n",
    "    \n",
    "    # NUMERIC DATA INPUT\n",
    "    # create dense input branch for numeric\n",
    "    input_num = Input(shape=(X_train_num.shape[1],), name='numeric')\n",
    "    x_dense = Dense(units=22, activation='relu',name='num_1')(input_num)\n",
    "    \n",
    "    all_deep_branch_outputs.append(x_dense)\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(deep_branch)\n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(deep_branch)\n",
    "    \n",
    "    # merge the deep and wide branch\n",
    "    final_branch = concatenate([deep_branch], name='concat_deep')\n",
    "    final_branch = Dense(units=1,activation='sigmoid', name='combined')(final_branch)\n",
    "    \n",
    "    model4 = Model(inputs=[input_cat,input_num], outputs=final_branch)\n",
    "    \n",
    "    model4.compile(loss = \"mean_squared_error\",\n",
    "                 optimizer = 'sgd', metrics = ['accuracy', 'AUC'])\n",
    "    \n",
    "    save_dir = '\\saved_models4/'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(kfold), \n",
    "                                                    monitor='val_accuracy', verbose=1, \n",
    "                                                    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    history4 = model4.fit([X_train_cat,X_train_num], y_train1, epochs=15, batch_size=32, verbose=1,\n",
    "                        callbacks = [callbacks_list],\n",
    "                        validation_data = ([X_test_cat,X_test_num], y_val))\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model4.load_weights(\"\\saved_models4/model_\"+str(kfold)+\".h5\")\n",
    "\n",
    "    results = model4.evaluate([X_test_cat,X_test_num], y_val)\n",
    "    results = dict(zip(model4.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY4.append(results['accuracy'])\n",
    "    VALIDATION_AUC4.append(results['auc'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    kfold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history4.history['accuracy'])\n",
    "\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history4.history['val_accuracy'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history4.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history4.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "| Fold |      Accuracy      |        AUC         |\n",
      "+------+--------------------+--------------------+\n",
      "|  1   | 0.8550323247909546 | 0.9370723962783813 |\n",
      "|  2   | 0.8647276163101196 | 0.9468874931335449 |\n",
      "|  3   | 0.8536472916603088 | 0.9368804097175598 |\n",
      "|  4   | 0.8379501104354858 | 0.9270048141479492 |\n",
      "|  5   | 0.8836565017700195 | 0.958097517490387  |\n",
      "|  6   | 0.8393352031707764 | 0.9278656244277954 |\n",
      "|  7   | 0.859649121761322  | 0.9390863180160522 |\n",
      "|  8   | 0.8633425831794739 | 0.9439509510993958 |\n",
      "|  9   | 0.8766743540763855 | 0.9489799737930298 |\n",
      "|  10  | 0.8554272651672363 | 0.9360637068748474 |\n",
      "+------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.add_column(\"Fold\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "results.add_column(\"Accuracy\", VALIDATION_ACCURACY4)\n",
    "results.add_column(\"AUC\", VALIDATION_AUC4)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fold: 5\n"
     ]
    }
   ],
   "source": [
    "idx = VALIDATION_ACCURACY4.index(max(VALIDATION_ACCURACY4))\n",
    "max_fold4 = idx + 1\n",
    "print(\"Best Fold:\", max_fold4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 915us/step - loss: 0.1392 - accuracy: 0.7998 - auc: 0.8901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1391681581735611, 0.7997922301292419, 0.8900622129440308]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.load_weights(\"\\saved_models4/model_\"+str(max_fold4)+\".h5\")\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model4.evaluate([X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 880us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_proba = model4.predict([X_test_cat, X_test_num])\n",
    "yhat4 = np.round(yhat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare W/D 1 to MLP via AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.8108 - auc: 0.8962\n",
      "211/211 [==============================] - 0s 875us/step - loss: 0.1392 - accuracy: 0.7998 - auc: 0.8901\n"
     ]
    }
   ],
   "source": [
    "results1 = model1.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)\n",
    "results4 = model4.evaluate([X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131323</td>\n",
       "      <td>0.810775</td>\n",
       "      <td>0.896181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139168</td>\n",
       "      <td>0.799792</td>\n",
       "      <td>0.890062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy       auc\n",
       "0  0.131323  0.810775  0.896181\n",
       "1  0.139168  0.799792  0.890062"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = pd.DataFrame(columns = model4.metrics_names)\n",
    "comp.loc[len(comp)] = results1\n",
    "comp.loc[len(comp)] = results4\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W/D Network 1 vs. MLP (Deep Only) CI: -0.016551298489762327 0.004313511243058227\n"
     ]
    }
   ],
   "source": [
    "auc_wd = comp.loc[0]['auc']\n",
    "auc_mlp = comp.loc[1]['auc']\n",
    "\n",
    "e1 = 1 - auc_wd\n",
    "e2 = 1 - auc_mlp\n",
    "\n",
    "z_stat = 1.96 #95% CI\n",
    "\n",
    "# e1 and e2\n",
    "d12 = e1 - e2\n",
    "var12 = (e1*(1 - e1) + e2*(1 - e2))/len(y_test)\n",
    "print('W/D Network 1 vs. MLP (Deep Only) CI:', d12 - z_stat*np.sqrt(var12), d12 + z_stat*np.sqrt(var12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the area under the curve for the best Wide and Deep Network to the Multi-Layer Perceptron, the 95% confidence interval above includes 0, which means that the models are not significantly different from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulating Models in Terms of Accuracy and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx1 = VALIDATION_ACCURACY1.index(max(VALIDATION_ACCURACY1))\n",
    "idx11 = VALIDATION_ACCURACY11.index(max(VALIDATION_ACCURACY11))\n",
    "idx12 = VALIDATION_ACCURACY12.index(max(VALIDATION_ACCURACY12))\n",
    "idx2 = VALIDATION_ACCURACY2.index(max(VALIDATION_ACCURACY2))\n",
    "idx21 = VALIDATION_ACCURACY21.index(max(VALIDATION_ACCURACY21))\n",
    "idx22 = VALIDATION_ACCURACY22.index(max(VALIDATION_ACCURACY22))\n",
    "idx3 = VALIDATION_ACCURACY3.index(max(VALIDATION_ACCURACY3))\n",
    "idx31 = VALIDATION_ACCURACY31.index(max(VALIDATION_ACCURACY31))\n",
    "idx32 = VALIDATION_ACCURACY32.index(max(VALIDATION_ACCURACY32))\n",
    "idx4 = VALIDATION_ACCURACY4.index(max(VALIDATION_ACCURACY4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+\n",
      "|     Model      |      Accuracy      |        AUC         |\n",
      "+----------------+--------------------+--------------------+\n",
      "|  Wide Deep 1   | 0.8716528415679932 | 0.9496077299118042 |\n",
      "| Wide Deeper 1  | 0.8651893138885498 | 0.9351232051849365 |\n",
      "| Wide Deepest 1 | 0.8587257862091064 | 0.9061406254768372 |\n",
      "|  Wide Deep 2   | 0.8794457316398621 | 0.9516303539276123 |\n",
      "| Wide Deeper 2  | 0.8715935349464417 | 0.9421837329864502 |\n",
      "| Wide Deepest 2 | 0.8684210777282715 | 0.9464473128318787 |\n",
      "|  Wide Deep 3   | 0.8692840933799744 | 0.9483535885810852 |\n",
      "| Wide Deeper 3  | 0.8568790555000305 | 0.9254499673843384 |\n",
      "| Wide Deepest 3 | 0.8554940223693848 | 0.9467926025390625 |\n",
      "| ML Perceptron  | 0.8836565017700195 | 0.958097517490387  |\n",
      "+----------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.field_names = ['Model', 'Accuracy', 'AUC']\n",
    "results.add_row(['Wide Deep 1', VALIDATION_ACCURACY1[idx1], VALIDATION_AUC1[idx1]])\n",
    "results.add_row(['Wide Deeper 1', VALIDATION_ACCURACY11[idx11], VALIDATION_AUC11[idx11]])\n",
    "results.add_row(['Wide Deepest 1', VALIDATION_ACCURACY12[idx12], VALIDATION_AUC12[idx12]])\n",
    "results.add_row(['Wide Deep 2', VALIDATION_ACCURACY2[idx2], VALIDATION_AUC2[idx2]])\n",
    "results.add_row(['Wide Deeper 2', VALIDATION_ACCURACY21[idx21], VALIDATION_AUC21[idx21]])\n",
    "results.add_row(['Wide Deepest 2', VALIDATION_ACCURACY22[idx22], VALIDATION_AUC22[idx22]])\n",
    "results.add_row(['Wide Deep 3', VALIDATION_ACCURACY3[idx3], VALIDATION_AUC3[idx3]])\n",
    "results.add_row(['Wide Deeper 3', VALIDATION_ACCURACY31[idx31], VALIDATION_AUC31[idx31]])\n",
    "results.add_row(['Wide Deepest 3', VALIDATION_ACCURACY32[idx32], VALIDATION_AUC32[idx32]])\n",
    "results.add_row(['ML Perceptron', VALIDATION_ACCURACY4[idx4], VALIDATION_AUC4[idx4]])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx1 = VALIDATION_AUC1.index(max(VALIDATION_AUC1))\n",
    "idx11 = VALIDATION_AUC11.index(max(VALIDATION_AUC11))\n",
    "idx12 = VALIDATION_AUC12.index(max(VALIDATION_AUC12))\n",
    "idx2 = VALIDATION_AUC2.index(max(VALIDATION_AUC2))\n",
    "idx21 = VALIDATION_AUC21.index(max(VALIDATION_AUC21))\n",
    "idx22 = VALIDATION_AUC22.index(max(VALIDATION_AUC22))\n",
    "idx3 = VALIDATION_AUC3.index(max(VALIDATION_AUC3))\n",
    "idx31 = VALIDATION_AUC31.index(max(VALIDATION_AUC31))\n",
    "idx32 = VALIDATION_AUC32.index(max(VALIDATION_AUC32))\n",
    "idx4 = VALIDATION_AUC4.index(max(VALIDATION_AUC4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+\n",
      "|     Model      |      Accuracy      |        AUC         |\n",
      "+----------------+--------------------+--------------------+\n",
      "|  Wide Deep 1   | 0.8716528415679932 | 0.9496077299118042 |\n",
      "| Wide Deeper 1  | 0.8651893138885498 | 0.9351232051849365 |\n",
      "| Wide Deepest 1 | 0.8559556603431702 | 0.933461606502533  |\n",
      "|  Wide Deep 2   | 0.8748846054077148 | 0.9543370008468628 |\n",
      "| Wide Deeper 2  | 0.8715935349464417 | 0.9421837329864502 |\n",
      "| Wide Deepest 2 | 0.8684210777282715 | 0.9464473128318787 |\n",
      "|  Wide Deep 3   | 0.8692840933799744 | 0.9483535885810852 |\n",
      "| Wide Deeper 3  | 0.8531855940818787 | 0.9371157884597778 |\n",
      "| Wide Deepest 3 | 0.8554940223693848 | 0.9467926025390625 |\n",
      "| ML Perceptron  | 0.8836565017700195 | 0.958097517490387  |\n",
      "+----------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable()\n",
    "results.field_names = ['Model', 'Accuracy', 'AUC']\n",
    "results.add_row(['Wide Deep 1', VALIDATION_ACCURACY1[idx1], VALIDATION_AUC1[idx1]])\n",
    "results.add_row(['Wide Deeper 1', VALIDATION_ACCURACY11[idx11], VALIDATION_AUC11[idx11]])\n",
    "results.add_row(['Wide Deepest 1', VALIDATION_ACCURACY12[idx12], VALIDATION_AUC12[idx12]])\n",
    "results.add_row(['Wide Deep 2', VALIDATION_ACCURACY2[idx2], VALIDATION_AUC2[idx2]])\n",
    "results.add_row(['Wide Deeper 2', VALIDATION_ACCURACY21[idx21], VALIDATION_AUC21[idx21]])\n",
    "results.add_row(['Wide Deepest 2', VALIDATION_ACCURACY22[idx22], VALIDATION_AUC22[idx22]])\n",
    "results.add_row(['Wide Deep 3', VALIDATION_ACCURACY3[idx3], VALIDATION_AUC3[idx3]])\n",
    "results.add_row(['Wide Deeper 3', VALIDATION_ACCURACY31[idx31], VALIDATION_AUC31[idx31]])\n",
    "results.add_row(['Wide Deepest 3', VALIDATION_ACCURACY32[idx32], VALIDATION_AUC32[idx32]])\n",
    "results.add_row(['ML Perceptron', VALIDATION_ACCURACY4[idx4], VALIDATION_AUC4[idx4]])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was included to summarize the results of training each of the models via cross validation and choosing the best model to fit on the test set. It is interesting that the Multi-Layer Perceptron yielded the highest validation accuracy and AUC in the training process, but in the above comparison of Wide and Deep Network 1 and the Multi-Layer Perceptron, the comparison table shows that the Wide and Deep Network actually slightly (not significantly) outperformed the Multi-Layer Perceptron in terms of both measures. The dropoff from training metrics to testing metrics suggest that the MLP may be overfitting to the training data, leading to poorer relative performance on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (1 points total)\n",
    "\n",
    "One idea (required for 7000 level students): Capture the embedding weights from the deep network and (if needed) perform dimensionality reduction on the output of these embedding layers (only if needed). That is, pass the observations into the network, save the embedded weights (called embeddings), and then perform  dimensionality reduction in order to visualize results. Visualize and explain any clusters in the data.\n",
    "\n",
    "Although there was no significant difference between WD 1 and the MLP, we elected to move forward with WD 1 as our best model since it yielded slightly better metrics on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.8108 - auc: 0.8962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13132330775260925, 0.8107746839523315, 0.8961811065673828]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_weights(\"\\saved_models1/model_\"+str(max_fold1)+\".h5\")\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "    \n",
    "# get crossed columns\n",
    "X_test_crossed = X_test[cross_col_df_names1].to_numpy()\n",
    "\n",
    "# save categorical features\n",
    "X_test_cat = X_test[categorical_headers].to_numpy() \n",
    "\n",
    "# and save off the numeric features\n",
    "X_test_num = X_test[numeric_headers].to_numpy()\n",
    "\n",
    "model1.evaluate([X_test_crossed,X_test_cat,X_test_num], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirstinpruitt/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 32 nearest neighbors...\n",
      "[t-SNE] Indexed 33 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 33 samples in 0.003s...\n",
      "[t-SNE] Computed conditional probabilities for sample 33 / 33\n",
      "[t-SNE] Mean sigma: 0.096154\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 44.813271\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.476044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirstinpruitt/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:996: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02014561,  0.03297092, -0.02997809,  0.01213219, -0.03398019],\n",
       "       [-0.03040902, -0.02834615, -0.01151936, -0.02793972,  0.03797956],\n",
       "       [ 0.03350912,  0.04813427, -0.00423335, -0.04868061, -0.0022204 ],\n",
       "       [ 0.02963015,  0.04146936,  0.01080802,  0.04057513, -0.03049114],\n",
       "       [ 0.02898294, -0.03535194,  0.03255196,  0.02503607, -0.00862897],\n",
       "       [ 0.04315138,  0.01258979, -0.01565821, -0.00746944,  0.04414979],\n",
       "       [-0.01266565,  0.0055846 , -0.01247183, -0.00753132, -0.02020855],\n",
       "       [-0.00817852,  0.02491612,  0.03744063,  0.01120474,  0.03291049],\n",
       "       [-0.00599928,  0.01932077,  0.04533894,  0.0274847 ,  0.01999759],\n",
       "       [ 0.01204183,  0.03171245,  0.04183075,  0.02129509,  0.02776867],\n",
       "       [-0.01717252, -0.03425907,  0.03376386,  0.02116618, -0.04160946],\n",
       "       [-0.01471838, -0.00748398,  0.03727069,  0.03725231,  0.04085338],\n",
       "       [-0.00077312, -0.01182045,  0.02148054, -0.01146497,  0.02910047],\n",
       "       [ 0.00554908, -0.01933683,  0.03195726, -0.0464641 , -0.00108325],\n",
       "       [-0.03631136, -0.00962014, -0.03635209, -0.01643459, -0.03984924],\n",
       "       [-0.04325346,  0.00831783, -0.03900465,  0.00796925, -0.01710325],\n",
       "       [-0.03214368,  0.04446568,  0.02931817,  0.01634512, -0.01550024],\n",
       "       [ 0.02850603, -0.04931232, -0.03590658,  0.02149045, -0.03515209],\n",
       "       [ 0.04331751,  0.00618433, -0.02941272,  0.04319946,  0.03610114],\n",
       "       [ 0.01869426, -0.04229881, -0.00132213, -0.02994726, -0.0305063 ],\n",
       "       [ 0.00768348, -0.01701434, -0.00979635, -0.01698335,  0.00760422],\n",
       "       [ 0.01046264, -0.00522604, -0.0229534 , -0.00840704,  0.02338958],\n",
       "       [ 0.01793523,  0.04540831, -0.01071417, -0.00055737, -0.0321013 ],\n",
       "       [ 0.01074323,  0.03840073, -0.02837262, -0.03162807,  0.00427742],\n",
       "       [-0.02136001,  0.03137835,  0.0305342 ,  0.00226169, -0.03975971],\n",
       "       [ 0.00826435,  0.00692514,  0.01040849,  0.0511976 ,  0.03388112],\n",
       "       [-0.00446564,  0.0028985 ,  0.04657311, -0.0305016 , -0.02206935],\n",
       "       [-0.04576072, -0.0100071 , -0.02574548, -0.03984107, -0.0124899 ],\n",
       "       [ 0.03716796,  0.04079651, -0.04257236,  0.0417307 ,  0.02618564],\n",
       "       [ 0.00028886,  0.01013361,  0.02244375,  0.0308795 , -0.01213256],\n",
       "       [-0.0107131 , -0.03151188, -0.02189613, -0.00946401, -0.00241206],\n",
       "       [-0.04664661,  0.033175  ,  0.0049295 ,  0.02392867, -0.02654252],\n",
       "       [-0.04086293,  0.01798056,  0.03957945, -0.00814732,  0.0391304 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "M_range_int_embed = []\n",
    "M_range_weight = model1.get_layer(\"opp_int_embed\").get_weights()[0]\n",
    "np.set_printoptions(suppress=True) # stop using scientific notation\n",
    "M_range = encoders[\"opp\"].classes_\n",
    "\n",
    "\n",
    "# extract the x and y\n",
    "tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=0, verbose=1)\n",
    "df_tsne = pd.DataFrame(data=tsne.fit_transform(M_range_weight))\n",
    "\n",
    "x_opp_list = df_tsne[0]\n",
    "y_opp_list = df_tsne[1]\n",
    "M_range_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`opp` (opponent) categorical feature has 5 weights, so we used dimensionality reduction to reduce it to two dimensions that can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "for x,y in zip(x_opp_list, y_opp_list):\n",
    "    ar = M_range[index]\n",
    "    plt.annotate(ar,xy=(x,y), textcoords='offset points',xytext=(10,10),ha='center')\n",
    "    index += 1\n",
    "    \n",
    "plt.scatter(x_opp_list, y_opp_list, s=150)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('OPPONENT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that Dimension 1 has strong, positive weight on the opponents:\n",
    "* Brooklyn Nets\n",
    "* Memphis Grizzlies\n",
    "* Milwaukee Bucks\n",
    "* Washington Wizards\n",
    "* Utah Jazz*\n",
    "* Miami Heat\n",
    "\n",
    "And Dimension 2 has strong, positive weight on the opponents:\n",
    "* Los Angeles Lakers\n",
    "* Atlanta Hawks\n",
    "* Portland Trail Blazers\n",
    "* Toronto Raptors\n",
    "* Utah Jazz* \n",
    "\n",
    "*The Utah Jazz have relatively strong, positive pull in both dimensions as an `opp`onent in the model. \n",
    "\n",
    "The three opponents toward the top right corner (Utah Jazz, Brooklyn Nets, and Miami Heat) made the playoffs in all 3 seasons captured by the test set, which is interesting. But also toward the bottom right corner is the Denver Nuggets, Philadelpha 76ers, and Milwaukee Bucks, all of which also made playoffs in all 3 seasons captured by the set. This leads us to believe that positive values in dimension 1 are associated with opponents that consistently make the playoffs. \n",
    "The opponents toward the top of the plot (higher in D2) are the Toronto Raptors, Portland Trail Blazers, Los Angeles Lakers, Atlanta Hawks, and Phoenix Suns, which have all made the playoffs in 2 out of the 3 seasons captured by the test set. It seems dimension 2 is drawn toward opponents with slightly less consistent playoff appearances. \n",
    "\n",
    "When these teams are considered as `opp`onents of playoff contending teams in the data (`team`), they tend to all show up around 3 times per season with respect to making the playoffs, which stands to reason why, while patterns can be found if you really look for them, no overly straightforward clusters exist in the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirstinpruitt/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/kirstinpruitt/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:996: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 32 nearest neighbors...\n",
      "[t-SNE] Indexed 33 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 33 samples in 0.002s...\n",
      "[t-SNE] Computed conditional probabilities for sample 33 / 33\n",
      "[t-SNE] Mean sigma: 0.290177\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 45.886536\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.485992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.13619524, -0.05463667, -0.02835846,  0.01547332,  0.05135334],\n",
       "       [-0.18305793, -0.15432209, -0.04512396,  0.03827106,  0.08188966],\n",
       "       [-0.08833788, -0.13188176, -0.05110819,  0.01518409,  0.10438135],\n",
       "       [-0.05376689,  0.00540017, -0.03633734,  0.0216775 ,  0.02990292],\n",
       "       [-0.05312058, -0.07436866,  0.03635632,  0.05757541,  0.00846354],\n",
       "       [ 0.10563949,  0.10392869,  0.01462496, -0.01559461, -0.05752672],\n",
       "       [ 0.0542198 , -0.02770237,  0.01040779, -0.00716587, -0.01685554],\n",
       "       [ 0.01862507,  0.01421726, -0.00885912, -0.04453662, -0.00664289],\n",
       "       [ 0.10798551,  0.03915451,  0.04790034, -0.05873429, -0.00489335],\n",
       "       [ 0.06885544,  0.0426164 ,  0.00972028, -0.03002984, -0.05703871],\n",
       "       [-0.04412824, -0.05309712,  0.02167544,  0.01307528, -0.04848194],\n",
       "       [-0.02325713,  0.01334699, -0.02089662, -0.02593241,  0.02687943],\n",
       "       [-0.21367806, -0.16620047, -0.00950234,  0.07042745,  0.03202091],\n",
       "       [-0.02667118, -0.05960885,  0.01215726,  0.03339954,  0.03904338],\n",
       "       [ 0.02099023,  0.05913674,  0.039367  , -0.02583716,  0.02575094],\n",
       "       [-0.12325364, -0.04297199, -0.00995318,  0.00550845,  0.01963687],\n",
       "       [ 0.03070933, -0.00154684,  0.03435392, -0.07041372, -0.01678603],\n",
       "       [-0.10930496, -0.08525579, -0.03332652,  0.0177265 ,  0.07397744],\n",
       "       [ 0.22855566,  0.1598607 , -0.01039234, -0.04271871, -0.03827317],\n",
       "       [ 0.06701636,  0.00405236,  0.01745424, -0.03937015,  0.01485822],\n",
       "       [ 0.05015201,  0.05215366,  0.02371643,  0.00996488, -0.02712398],\n",
       "       [ 0.04309763,  0.00608312, -0.02214368, -0.04459154, -0.03332849],\n",
       "       [ 0.10206895,  0.02384217,  0.01262527,  0.00453165,  0.00683025],\n",
       "       [-0.04419376, -0.07024041, -0.02987285,  0.01045525,  0.04565905],\n",
       "       [ 0.07372209,  0.06725259,  0.01532421,  0.02749053, -0.07177266],\n",
       "       [-0.09392616, -0.02268053, -0.02326359,  0.00340336,  0.00189103],\n",
       "       [ 0.25987116,  0.18294293, -0.00862341, -0.07656083, -0.06690664],\n",
       "       [-0.12406898, -0.11554858, -0.02549508, -0.00644432,  0.03445652],\n",
       "       [ 0.1848526 ,  0.15135843,  0.05411311, -0.06918032, -0.02159163],\n",
       "       [-0.14253251, -0.04257837, -0.00967249,  0.02931519,  0.03139807],\n",
       "       [-0.02199759, -0.03101947,  0.00915267, -0.00362697,  0.01242287],\n",
       "       [ 0.09950669,  0.05310589,  0.03824211,  0.00596112, -0.00029053],\n",
       "       [-0.03803522, -0.05370496,  0.01657007,  0.044489  , -0.00577068]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_range_int_embed = []\n",
    "M_range_weight = model1.get_layer(\"team_int_embed\").get_weights()[0]\n",
    "np.set_printoptions(suppress=True) # stop using scientific notation\n",
    "M_range = encoders[\"team\"].classes_\n",
    "\n",
    "# extract the x and y\n",
    "tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=0, verbose=1)\n",
    "df_tsne = pd.DataFrame(data=tsne.fit_transform(M_range_weight))\n",
    "\n",
    "x_team_list = df_tsne[0]\n",
    "y_team_list = df_tsne[1]\n",
    "M_range_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`team` also has 5 categorical feature weights, so we again used dimensionality reduction to reduce it to two dimensions that can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "for x,y in zip(x_team_list, y_team_list):\n",
    "    ar = M_range[index]\n",
    "    plt.annotate(ar,xy=(x,y), textcoords='offset points',xytext=(10,10),ha='center')\n",
    "    index += 1\n",
    "    \n",
    "\n",
    "plt.scatter(x_team_list, y_team_list, s=150)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('TEAM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that Dimension 1 has strong, positive weight on the teams:\n",
    "* Minnesota Timberwolves\n",
    "* Sacramento Kings \n",
    "* Phoenix Suns\n",
    "* Los Angeles Lakers\n",
    "* Indiana Pacers*\n",
    "\n",
    "And Dimension 2 has strong, positive weight on the opponents:\n",
    "* Portland Trail Blazers\n",
    "* New Jersey Nets (became Brooklyn Nets in 2013 Season)\n",
    "* Milwaukee Bucks\n",
    "* Indiana Pacers* \n",
    "* Orlando Magic\n",
    "\n",
    "*The Indiana Pacers have relatively strong, positive pull in both dimensions as a `team` in the model. \n",
    "\n",
    "Toward the left side of the plot, we see some fairly consistent playoff contenders from the test set: \n",
    "* Brooklyn Nets (3/3 seasons)\n",
    "* Boston Celtics (3/3 seasons)\n",
    "* Dallas Mavericks (3/3 seasons)\n",
    "* Utah Jazz (3/3 seasons)\n",
    "* Miami Head (3/3 seasons)\n",
    "* Atlanta Hawks (2/3 seasons)\n",
    "* Toronto Raptors (2/3 seasons)\n",
    "* Los Angeles Clippers (2/3 seasons) \n",
    "\n",
    "It is interesting that these teams pull strong, negative weight in dimension 1. \n",
    "\n",
    "The Milwaukee Bucks (3/3) and Portland Trail Blazers (2/3) pull strong, positive weight for dimension 2.\n",
    "\n",
    "Again it seems that while patterns can be hunted down in the plot, there is not convincing evidence that straightforward, interpretable clusters exist for the `team` variable either, which may mean that `team` and `opp` don't heavily influence the whether or not a game will result in a positive or negative playoff prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources\n",
    "\n",
    "[k-fold model example 1](https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md)\n",
    "\n",
    "[k-fold model example 2 (used)](https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
